{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-02-03T20:53:58.248984Z","iopub.status.busy":"2024-02-03T20:53:58.248610Z","iopub.status.idle":"2024-02-03T20:53:58.256780Z","shell.execute_reply":"2024-02-03T20:53:58.255880Z","shell.execute_reply.started":"2024-02-03T20:53:58.248956Z"},"id":"UIqpm34x2rms","outputId":"b0205d19-dff1-4967-d003-990c3c5c8164","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import time\n","import datetime\n","import random\n","from transformers import AutoConfig\n","import random\n","seed_val = 42  # Define a seed value for random number generation\n","random.seed(seed_val)  # Set the seed for Python's built-in random module\n","np.random.seed(seed_val)  # Set the seed for NumPy's random module\n","torch.manual_seed(seed_val)  # Set the seed for PyTorch's random number generator\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed_val)  # Set the seed for all GPUs if CUDA is available"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-03T20:54:06.096249Z","iopub.status.busy":"2024-02-03T20:54:06.095905Z","iopub.status.idle":"2024-02-03T20:54:08.749701Z","shell.execute_reply":"2024-02-03T20:54:08.748862Z","shell.execute_reply.started":"2024-02-03T20:54:06.096222Z"},"trusted":true},"outputs":[],"source":["import json\n","data_list = []\n","file_path = \"/kaggle/input/subtaskB_train.jsonl\"\n","with open(file_path, 'r') as file:\n","    for line in file:\n","        json_object = json.loads(line)\n","        data_list.append(json_object)\n","\n","test_list = []\n","file_path_test = \"/kaggle/input/subtaskB_dev.jsonl\"\n","with open(file_path_test, 'r') as file:\n","    for line in file:\n","        json_object = json.loads(line)\n","        test_list.append(json_object)\n","\n","random.shuffle(data_list)\n","random.shuffle(test_list)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-02-03T20:54:08.751501Z","iopub.status.busy":"2024-02-03T20:54:08.751195Z","iopub.status.idle":"2024-02-03T20:54:08.776080Z","shell.execute_reply":"2024-02-03T20:54:08.775198Z","shell.execute_reply.started":"2024-02-03T20:54:08.751477Z"},"id":"LeZgRup520II","outputId":"5b8d1039-e1e6-4712-e77b-e1e9f1b9fbcb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}],"source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-03T20:54:15.552940Z","iopub.status.busy":"2024-02-03T20:54:15.552038Z","iopub.status.idle":"2024-02-03T20:54:16.160940Z","shell.execute_reply":"2024-02-03T20:54:16.159940Z","shell.execute_reply.started":"2024-02-03T20:54:15.552909Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>bloomz</td>\n","      <td>11998</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>chatGPT</td>\n","      <td>11995</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cohere</td>\n","      <td>11336</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>davinci</td>\n","      <td>11999</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dolly</td>\n","      <td>11702</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>human</td>\n","      <td>11997</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     model  Count\n","0   bloomz  11998\n","1  chatGPT  11995\n","2   cohere  11336\n","3  davinci  11999\n","4    dolly  11702\n","5    human  11997"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","\n","df = pd.DataFrame(data_list)\n","model_counts = df.groupby('model').size().reset_index(name='Count')\n","del df\n","label_map = {}\n","label_list = list(model_counts.model)\n","label_list.append(\"Fake\")\n","for (i, label) in enumerate(label_list):\n","    label_map[label] = i\n","inverted_label_map = {value: key for key, value in label_map.items()}\n","display(model_counts)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-03T20:54:18.698456Z","iopub.status.busy":"2024-02-03T20:54:18.697950Z","iopub.status.idle":"2024-02-03T20:54:18.712347Z","shell.execute_reply":"2024-02-03T20:54:18.711425Z","shell.execute_reply.started":"2024-02-03T20:54:18.698422Z"},"trusted":true},"outputs":[],"source":["labeled_examples = []\n","unlabeled_examples = []\n","test_examples = []\n","\n","for expl in data_list[: int(len(data_list) * 0.01)]:\n","    labeled_examples.append((expl['text'], expl[\"model\"]))\n","\n","for expl in data_list[int(len(data_list) * 0.01): int(len(data_list) * 0.05)]:\n","    unlabeled_examples.append((expl['text'], 'Fake'))\n","\n","for expl in test_list:\n","    test_examples.append((expl['text'], expl[\"model\"]))\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-03T20:54:19.605127Z","iopub.status.busy":"2024-02-03T20:54:19.604748Z","iopub.status.idle":"2024-02-03T20:54:24.181302Z","shell.execute_reply":"2024-02-03T20:54:24.180200Z","shell.execute_reply.started":"2024-02-03T20:54:19.605098Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81d16b6862bb4f68901e6cad9a7cba72","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ef3f3eab2f946e8830a7be2d48f8f62","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertWithAdapters were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['bert.adapters.0.down_project.bias', 'bert.adapters.0.down_project.weight', 'bert.adapters.0.up_project.bias', 'bert.adapters.0.up_project.weight', 'bert.adapters.1.down_project.bias', 'bert.adapters.1.down_project.weight', 'bert.adapters.1.up_project.bias', 'bert.adapters.1.up_project.weight', 'bert.adapters.10.down_project.bias', 'bert.adapters.10.down_project.weight', 'bert.adapters.10.up_project.bias', 'bert.adapters.10.up_project.weight', 'bert.adapters.11.down_project.bias', 'bert.adapters.11.down_project.weight', 'bert.adapters.11.up_project.bias', 'bert.adapters.11.up_project.weight', 'bert.adapters.2.down_project.bias', 'bert.adapters.2.down_project.weight', 'bert.adapters.2.up_project.bias', 'bert.adapters.2.up_project.weight', 'bert.adapters.3.down_project.bias', 'bert.adapters.3.down_project.weight', 'bert.adapters.3.up_project.bias', 'bert.adapters.3.up_project.weight', 'bert.adapters.4.down_project.bias', 'bert.adapters.4.down_project.weight', 'bert.adapters.4.up_project.bias', 'bert.adapters.4.up_project.weight', 'bert.adapters.5.down_project.bias', 'bert.adapters.5.down_project.weight', 'bert.adapters.5.up_project.bias', 'bert.adapters.5.up_project.weight', 'bert.adapters.6.down_project.bias', 'bert.adapters.6.down_project.weight', 'bert.adapters.6.up_project.bias', 'bert.adapters.6.up_project.weight', 'bert.adapters.7.down_project.bias', 'bert.adapters.7.down_project.weight', 'bert.adapters.7.up_project.bias', 'bert.adapters.7.up_project.weight', 'bert.adapters.8.down_project.bias', 'bert.adapters.8.down_project.weight', 'bert.adapters.8.up_project.bias', 'bert.adapters.8.up_project.weight', 'bert.adapters.9.down_project.bias', 'bert.adapters.9.down_project.weight', 'bert.adapters.9.up_project.bias', 'bert.adapters.9.up_project.weight', 'bert.logit.bias', 'bert.logit.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d9fe12221914047990e9c408d8d9bce","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d07ce31a2da645c3b87ff0a911818d12","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d147577029841f2bb4d32c031056459","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import BertModel, BertTokenizer\n","\n","class AdapterLayer(nn.Module):\n","    def __init__(self, input_size, adapter_size):\n","        super(AdapterLayer, self).__init__()\n","        self.down_project = nn.Linear(input_size, adapter_size)\n","        self.up_project = nn.Linear(adapter_size, input_size)\n","\n","    def forward(self, x):\n","        down_projected = self.down_project(x)\n","        activated = nn.functional.relu(down_projected)\n","        up_projected = self.up_project(activated)\n","        return x + up_projected\n","\n","class BertWithAdapters(BertModel):\n","    def __init__(self, config):\n","        super(BertWithAdapters, self).__init__(config)\n","        self.adapters = nn.ModuleList([AdapterLayer(config.hidden_size, adapter_size=64) for _ in range(config.num_hidden_layers)])\n","        self.logit = nn.Linear(768, 6)\n","        self.softmax = nn.Softmax(dim=-1)\n","        \n","    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n","        outputs = super().forward(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        sequence_output = outputs.last_hidden_state\n","\n","        for adapter_layer in self.adapters:\n","            sequence_output = adapter_layer(sequence_output)\n","        output = sequence_output.mean(dim=1)\n","        return output\n","\n","model_name = \"bert-base-cased\"\n","transformer = BertWithAdapters.from_pretrained(model_name)\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-03T20:54:24.183433Z","iopub.status.busy":"2024-02-03T20:54:24.182981Z","iopub.status.idle":"2024-02-03T20:54:24.198490Z","shell.execute_reply":"2024-02-03T20:54:24.197711Z","shell.execute_reply.started":"2024-02-03T20:54:24.183408Z"},"id":"fmKL5AD7I4Zg","trusted":true},"outputs":[],"source":["import math\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch\n","\n","def generate_data_loader(input_examples, label_masks, label_map, do_shuffle=False, balance_label_examples=False, batch_size=16):\n","    '''\n","    Generate a DataLoader given the input examples, optionally masked if they are not labeled.\n","\n","    Args:\n","        input_examples (list): List of input examples.\n","        label_masks (list): List of label masks.\n","        label_map (dict): Mapping of labels to IDs.\n","        do_shuffle (bool, optional): Whether to shuffle the data. Defaults to False.\n","        balance_label_examples (bool, optional): Whether to balance labeled examples. Defaults to False.\n","        batch_size (int, optional): Batch size for DataLoader. Defaults to 16.\n","\n","    Returns:\n","        DataLoader: DataLoader object for training or validation.\n","    '''\n","    examples = []\n","\n","    # Count the percentage of labeled examples\n","    num_labeled_examples = sum(label_masks)\n","    label_mask_rate = num_labeled_examples / len(input_examples)\n","\n","    # Apply balance if required\n","    for index, ex in enumerate(input_examples):\n","        if label_mask_rate == 1 or not balance_label_examples:\n","            examples.append((ex, label_masks[index]))\n","        else:\n","            if label_masks[index]:\n","                balance = int(1 / label_mask_rate)\n","                balance = int(math.log(balance, 2))\n","                balance = max(balance, 1)\n","                for _ in range(balance):\n","                    examples.append((ex, label_masks[index]))\n","            else:\n","                examples.append((ex, label_masks[index]))\n","\n","    # Tokenization\n","    input_ids = []\n","    input_mask_array = []\n","    label_mask_array = []\n","    label_id_array = []\n","\n","    for text, label_mask in examples:\n","        encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=256, padding=\"max_length\", truncation=True)\n","        input_ids.append(encoded_sent)\n","        label_id_array.append(label_map[text[1]])\n","        label_mask_array.append(label_mask)\n","\n","    # Attention masks (to ignore padded input wordpieces)\n","    for sent in input_ids:\n","        att_mask = [int(token_id > 0) for token_id in sent]\n","        input_mask_array.append(att_mask)\n","\n","    # Conversion to Tensor\n","    input_ids = torch.tensor(input_ids)\n","    input_mask_array = torch.tensor(input_mask_array)\n","    label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n","    label_mask_array = torch.tensor(label_mask_array)\n","\n","    # Build the TensorDataset\n","    dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n","\n","    # Define the sampler based on shuffle option\n","    sampler = RandomSampler(dataset) if do_shuffle else SequentialSampler(dataset)\n","\n","    # Build the DataLoader\n","    return DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a formatted string in the format hh:mm:ss.\n","\n","    Args:\n","        elapsed (float): Time in seconds.\n","\n","    Returns:\n","        str: Formatted time string.\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round(elapsed))\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-03T20:54:24.199956Z","iopub.status.busy":"2024-02-03T20:54:24.199668Z","iopub.status.idle":"2024-02-03T20:55:35.716599Z","shell.execute_reply":"2024-02-03T20:55:35.715568Z","shell.execute_reply.started":"2024-02-03T20:54:24.199933Z"},"id":"4c-nsMXlKX-D","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/1784941527.py:54: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n","  label_mask_array = torch.tensor(label_mask_array)\n"]}],"source":["# Load the train dataset\n","train_examples = labeled_examples\n","# The labeled (train) dataset is assigned with a mask set to True\n","train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n","\n","# If unlabeled examples are available\n","if unlabeled_examples:\n","    train_examples = train_examples + unlabeled_examples\n","    # The unlabeled (train) dataset is assigned with a mask set to False\n","    tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n","    train_label_masks = np.concatenate([train_label_masks, tmp_masks])\n","\n","# Generate the training DataLoader\n","train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle=True, balance_label_examples=True)\n","\n","# Load the test dataset\n","# The labeled (test) dataset is assigned with a mask set to True\n","test_label_masks = np.ones(len(test_examples), dtype=bool)\n","\n","# Generate the test DataLoader\n","test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-03T20:55:35.718748Z","iopub.status.busy":"2024-02-03T20:55:35.718461Z","iopub.status.idle":"2024-02-03T20:55:36.145609Z","shell.execute_reply":"2024-02-03T20:55:36.144735Z","shell.execute_reply.started":"2024-02-03T20:55:35.718724Z"},"id":"18kY64-n3I6y","trusted":true},"outputs":[],"source":["# Generator class for generating data\n","class Generator(nn.Module):\n","    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n","        super(Generator, self).__init__()\n","        layers = []\n","        hidden_sizes = [noise_size] + hidden_sizes\n","        for i in range(len(hidden_sizes) - 1):\n","            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n","\n","        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, noise):\n","        output_rep = self.layers(noise)\n","        return output_rep\n","\n","# Discriminator class for discriminating generated data\n","class Discriminator(nn.Module):\n","    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=6, dropout_rate=0.1):\n","        super(Discriminator, self).__init__()\n","        self.input_dropout = nn.Dropout(p=dropout_rate)\n","        layers = []\n","        hidden_sizes = [input_size] + hidden_sizes\n","        for i in range(len(hidden_sizes) - 1):\n","            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n","\n","        self.layers = nn.Sequential(*layers)  # Flattening\n","        self.logit = nn.Linear(hidden_sizes[-1], num_labels + 1)  # +1 for the probability of this sample being fake/real.\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, input_rep):\n","        input_rep = self.input_dropout(input_rep)\n","        last_rep = self.layers(input_rep)\n","        logits = self.logit(last_rep)\n","        probs = self.softmax(logits)\n","        return last_rep, logits, probs\n","\n","# Define Discriminator and Generator\n","config = AutoConfig.from_pretrained(model_name)\n","hidden_size = int(config.hidden_size)\n","hidden_levels_g = [hidden_size]\n","hidden_levels_d = [hidden_size]\n","\n","dropout_rate = 0.2\n","generator = Generator(output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=dropout_rate)\n","discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=dropout_rate)\n","\n","# transfer models to GPU\n","generator.cuda()\n","discriminator.cuda()\n","transformer.cuda()\n","transformer = torch.nn.DataParallel(transformer)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-02-03T20:55:36.147186Z","iopub.status.busy":"2024-02-03T20:55:36.146900Z","iopub.status.idle":"2024-02-03T21:27:40.301531Z","shell.execute_reply":"2024-02-03T21:27:40.300635Z","shell.execute_reply.started":"2024-02-03T20:55:36.147162Z"},"id":"NhqylHGK3Va4","outputId":"726efd06-d8de-4a45-a7bb-f186994a6b2a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Epoch = 1\n","  Batch    10  of    267.    Elapsed: 0:00:07.\n","  Batch    20  of    267.    Elapsed: 0:00:14.\n","  Batch    30  of    267.    Elapsed: 0:00:20.\n","  Batch    40  of    267.    Elapsed: 0:00:26.\n","  Batch    50  of    267.    Elapsed: 0:00:33.\n","  Batch    60  of    267.    Elapsed: 0:00:39.\n","  Batch    70  of    267.    Elapsed: 0:00:45.\n","  Batch    80  of    267.    Elapsed: 0:00:52.\n","  Batch    90  of    267.    Elapsed: 0:00:58.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:11.\n","  Batch   120  of    267.    Elapsed: 0:01:17.\n","  Batch   130  of    267.    Elapsed: 0:01:24.\n","  Batch   140  of    267.    Elapsed: 0:01:30.\n","  Batch   150  of    267.    Elapsed: 0:01:36.\n","  Batch   160  of    267.    Elapsed: 0:01:43.\n","  Batch   170  of    267.    Elapsed: 0:01:49.\n","  Batch   180  of    267.    Elapsed: 0:01:55.\n","  Batch   190  of    267.    Elapsed: 0:02:02.\n","  Batch   200  of    267.    Elapsed: 0:02:08.\n","  Batch   210  of    267.    Elapsed: 0:02:14.\n","  Batch   220  of    267.    Elapsed: 0:02:21.\n","  Batch   230  of    267.    Elapsed: 0:02:27.\n","  Batch   240  of    267.    Elapsed: 0:02:33.\n","  Batch   250  of    267.    Elapsed: 0:02:40.\n","  Batch   260  of    267.    Elapsed: 0:02:46.\n","Training\n","  Average training loss generetor: 0.525\n","  Average training loss discriminator: 2.802\n","  Training epcoh took: 0:02:50\n","Validation\n","  Accuracy: 0.399\n","  Test Loss: 1.450\n","  Test took: 0:00:23\n","\n"," Epoch = 2\n","  Batch    10  of    267.    Elapsed: 0:00:06.\n","  Batch    20  of    267.    Elapsed: 0:00:13.\n","  Batch    30  of    267.    Elapsed: 0:00:19.\n","  Batch    40  of    267.    Elapsed: 0:00:25.\n","  Batch    50  of    267.    Elapsed: 0:00:32.\n","  Batch    60  of    267.    Elapsed: 0:00:38.\n","  Batch    70  of    267.    Elapsed: 0:00:44.\n","  Batch    80  of    267.    Elapsed: 0:00:51.\n","  Batch    90  of    267.    Elapsed: 0:00:57.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:10.\n","  Batch   120  of    267.    Elapsed: 0:01:16.\n","  Batch   130  of    267.    Elapsed: 0:01:23.\n","  Batch   140  of    267.    Elapsed: 0:01:29.\n","  Batch   150  of    267.    Elapsed: 0:01:35.\n","  Batch   160  of    267.    Elapsed: 0:01:42.\n","  Batch   170  of    267.    Elapsed: 0:01:48.\n","  Batch   180  of    267.    Elapsed: 0:01:54.\n","  Batch   190  of    267.    Elapsed: 0:02:01.\n","  Batch   200  of    267.    Elapsed: 0:02:07.\n","  Batch   210  of    267.    Elapsed: 0:02:13.\n","  Batch   220  of    267.    Elapsed: 0:02:20.\n","  Batch   230  of    267.    Elapsed: 0:02:26.\n","  Batch   240  of    267.    Elapsed: 0:02:33.\n","  Batch   250  of    267.    Elapsed: 0:02:39.\n","  Batch   260  of    267.    Elapsed: 0:02:45.\n","Training\n","  Average training loss generetor: 0.747\n","  Average training loss discriminator: 1.558\n","  Training epcoh took: 0:02:49\n","Validation\n","  Accuracy: 0.445\n","  Test Loss: 1.410\n","  Test took: 0:00:23\n","\n"," Epoch = 3\n","  Batch    10  of    267.    Elapsed: 0:00:06.\n","  Batch    20  of    267.    Elapsed: 0:00:13.\n","  Batch    30  of    267.    Elapsed: 0:00:19.\n","  Batch    40  of    267.    Elapsed: 0:00:25.\n","  Batch    50  of    267.    Elapsed: 0:00:32.\n","  Batch    60  of    267.    Elapsed: 0:00:38.\n","  Batch    70  of    267.    Elapsed: 0:00:44.\n","  Batch    80  of    267.    Elapsed: 0:00:51.\n","  Batch    90  of    267.    Elapsed: 0:00:57.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:10.\n","  Batch   120  of    267.    Elapsed: 0:01:16.\n","  Batch   130  of    267.    Elapsed: 0:01:23.\n","  Batch   140  of    267.    Elapsed: 0:01:29.\n","  Batch   150  of    267.    Elapsed: 0:01:35.\n","  Batch   160  of    267.    Elapsed: 0:01:42.\n","  Batch   170  of    267.    Elapsed: 0:01:48.\n","  Batch   180  of    267.    Elapsed: 0:01:54.\n","  Batch   190  of    267.    Elapsed: 0:02:01.\n","  Batch   200  of    267.    Elapsed: 0:02:07.\n","  Batch   210  of    267.    Elapsed: 0:02:13.\n","  Batch   220  of    267.    Elapsed: 0:02:20.\n","  Batch   230  of    267.    Elapsed: 0:02:26.\n","  Batch   240  of    267.    Elapsed: 0:02:33.\n","  Batch   250  of    267.    Elapsed: 0:02:39.\n","  Batch   260  of    267.    Elapsed: 0:02:45.\n","Training\n","  Average training loss generetor: 0.740\n","  Average training loss discriminator: 1.058\n","  Training epcoh took: 0:02:49\n","Validation\n","  Accuracy: 0.469\n","  Test Loss: 2.103\n","  Test took: 0:00:23\n","\n"," Epoch = 4\n","  Batch    10  of    267.    Elapsed: 0:00:06.\n","  Batch    20  of    267.    Elapsed: 0:00:13.\n","  Batch    30  of    267.    Elapsed: 0:00:19.\n","  Batch    40  of    267.    Elapsed: 0:00:25.\n","  Batch    50  of    267.    Elapsed: 0:00:32.\n","  Batch    60  of    267.    Elapsed: 0:00:38.\n","  Batch    70  of    267.    Elapsed: 0:00:44.\n","  Batch    80  of    267.    Elapsed: 0:00:51.\n","  Batch    90  of    267.    Elapsed: 0:00:57.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:10.\n","  Batch   120  of    267.    Elapsed: 0:01:16.\n","  Batch   130  of    267.    Elapsed: 0:01:23.\n","  Batch   140  of    267.    Elapsed: 0:01:29.\n","  Batch   150  of    267.    Elapsed: 0:01:35.\n","  Batch   160  of    267.    Elapsed: 0:01:42.\n","  Batch   170  of    267.    Elapsed: 0:01:48.\n","  Batch   180  of    267.    Elapsed: 0:01:54.\n","  Batch   190  of    267.    Elapsed: 0:02:01.\n","  Batch   200  of    267.    Elapsed: 0:02:07.\n","  Batch   210  of    267.    Elapsed: 0:02:13.\n","  Batch   220  of    267.    Elapsed: 0:02:20.\n","  Batch   230  of    267.    Elapsed: 0:02:26.\n","  Batch   240  of    267.    Elapsed: 0:02:33.\n","  Batch   250  of    267.    Elapsed: 0:02:39.\n","  Batch   260  of    267.    Elapsed: 0:02:45.\n","Training\n","  Average training loss generetor: 0.734\n","  Average training loss discriminator: 0.837\n","  Training epcoh took: 0:02:49\n","Validation\n","  Accuracy: 0.498\n","  Test Loss: 2.334\n","  Test took: 0:00:23\n","\n"," Epoch = 5\n","  Batch    10  of    267.    Elapsed: 0:00:06.\n","  Batch    20  of    267.    Elapsed: 0:00:13.\n","  Batch    30  of    267.    Elapsed: 0:00:19.\n","  Batch    40  of    267.    Elapsed: 0:00:25.\n","  Batch    50  of    267.    Elapsed: 0:00:32.\n","  Batch    60  of    267.    Elapsed: 0:00:38.\n","  Batch    70  of    267.    Elapsed: 0:00:44.\n","  Batch    80  of    267.    Elapsed: 0:00:51.\n","  Batch    90  of    267.    Elapsed: 0:00:57.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:10.\n","  Batch   120  of    267.    Elapsed: 0:01:16.\n","  Batch   130  of    267.    Elapsed: 0:01:23.\n","  Batch   140  of    267.    Elapsed: 0:01:29.\n","  Batch   150  of    267.    Elapsed: 0:01:35.\n","  Batch   160  of    267.    Elapsed: 0:01:42.\n","  Batch   170  of    267.    Elapsed: 0:01:48.\n","  Batch   180  of    267.    Elapsed: 0:01:54.\n","  Batch   190  of    267.    Elapsed: 0:02:01.\n","  Batch   200  of    267.    Elapsed: 0:02:07.\n","  Batch   210  of    267.    Elapsed: 0:02:13.\n","  Batch   220  of    267.    Elapsed: 0:02:20.\n","  Batch   230  of    267.    Elapsed: 0:02:26.\n","  Batch   240  of    267.    Elapsed: 0:02:33.\n","  Batch   250  of    267.    Elapsed: 0:02:39.\n","  Batch   260  of    267.    Elapsed: 0:02:45.\n","Training\n","  Average training loss generetor: 0.730\n","  Average training loss discriminator: 0.777\n","  Training epcoh took: 0:02:49\n","Validation\n","  Accuracy: 0.506\n","  Test Loss: 2.314\n","  Test took: 0:00:23\n","\n"," Epoch = 6\n","  Batch    10  of    267.    Elapsed: 0:00:06.\n","  Batch    20  of    267.    Elapsed: 0:00:13.\n","  Batch    30  of    267.    Elapsed: 0:00:19.\n","  Batch    40  of    267.    Elapsed: 0:00:25.\n","  Batch    50  of    267.    Elapsed: 0:00:32.\n","  Batch    60  of    267.    Elapsed: 0:00:38.\n","  Batch    70  of    267.    Elapsed: 0:00:44.\n","  Batch    80  of    267.    Elapsed: 0:00:51.\n","  Batch    90  of    267.    Elapsed: 0:00:57.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:10.\n","  Batch   120  of    267.    Elapsed: 0:01:16.\n","  Batch   130  of    267.    Elapsed: 0:01:23.\n","  Batch   140  of    267.    Elapsed: 0:01:29.\n","  Batch   150  of    267.    Elapsed: 0:01:35.\n","  Batch   160  of    267.    Elapsed: 0:01:42.\n","  Batch   170  of    267.    Elapsed: 0:01:48.\n","  Batch   180  of    267.    Elapsed: 0:01:54.\n","  Batch   190  of    267.    Elapsed: 0:02:01.\n","  Batch   200  of    267.    Elapsed: 0:02:07.\n","  Batch   210  of    267.    Elapsed: 0:02:13.\n","  Batch   220  of    267.    Elapsed: 0:02:20.\n","  Batch   230  of    267.    Elapsed: 0:02:26.\n","  Batch   240  of    267.    Elapsed: 0:02:32.\n","  Batch   250  of    267.    Elapsed: 0:02:39.\n","  Batch   260  of    267.    Elapsed: 0:02:45.\n","Training\n","  Average training loss generetor: 0.724\n","  Average training loss discriminator: 0.741\n","  Training epcoh took: 0:02:49\n","Validation\n","  Accuracy: 0.502\n","  Test Loss: 2.529\n","  Test took: 0:00:23\n","\n"," Epoch = 7\n","  Batch    10  of    267.    Elapsed: 0:00:06.\n","  Batch    20  of    267.    Elapsed: 0:00:13.\n","  Batch    30  of    267.    Elapsed: 0:00:19.\n","  Batch    40  of    267.    Elapsed: 0:00:25.\n","  Batch    50  of    267.    Elapsed: 0:00:32.\n","  Batch    60  of    267.    Elapsed: 0:00:38.\n","  Batch    70  of    267.    Elapsed: 0:00:44.\n","  Batch    80  of    267.    Elapsed: 0:00:51.\n","  Batch    90  of    267.    Elapsed: 0:00:57.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:10.\n","  Batch   120  of    267.    Elapsed: 0:01:16.\n","  Batch   130  of    267.    Elapsed: 0:01:23.\n","  Batch   140  of    267.    Elapsed: 0:01:29.\n","  Batch   150  of    267.    Elapsed: 0:01:35.\n","  Batch   160  of    267.    Elapsed: 0:01:42.\n","  Batch   170  of    267.    Elapsed: 0:01:48.\n","  Batch   180  of    267.    Elapsed: 0:01:54.\n","  Batch   190  of    267.    Elapsed: 0:02:01.\n","  Batch   200  of    267.    Elapsed: 0:02:07.\n","  Batch   210  of    267.    Elapsed: 0:02:13.\n","  Batch   220  of    267.    Elapsed: 0:02:20.\n","  Batch   230  of    267.    Elapsed: 0:02:26.\n","  Batch   240  of    267.    Elapsed: 0:02:33.\n","  Batch   250  of    267.    Elapsed: 0:02:39.\n","  Batch   260  of    267.    Elapsed: 0:02:45.\n","Training\n","  Average training loss generetor: 0.720\n","  Average training loss discriminator: 0.728\n","  Training epcoh took: 0:02:49\n","Validation\n","  Accuracy: 0.502\n","  Test Loss: 2.633\n","  Test took: 0:00:23\n","\n"," Epoch = 8\n","  Batch    10  of    267.    Elapsed: 0:00:06.\n","  Batch    20  of    267.    Elapsed: 0:00:13.\n","  Batch    30  of    267.    Elapsed: 0:00:19.\n","  Batch    40  of    267.    Elapsed: 0:00:25.\n","  Batch    50  of    267.    Elapsed: 0:00:32.\n","  Batch    60  of    267.    Elapsed: 0:00:38.\n","  Batch    70  of    267.    Elapsed: 0:00:44.\n","  Batch    80  of    267.    Elapsed: 0:00:51.\n","  Batch    90  of    267.    Elapsed: 0:00:57.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:10.\n","  Batch   120  of    267.    Elapsed: 0:01:16.\n","  Batch   130  of    267.    Elapsed: 0:01:23.\n","  Batch   140  of    267.    Elapsed: 0:01:29.\n","  Batch   150  of    267.    Elapsed: 0:01:35.\n","  Batch   160  of    267.    Elapsed: 0:01:42.\n","  Batch   170  of    267.    Elapsed: 0:01:48.\n","  Batch   180  of    267.    Elapsed: 0:01:54.\n","  Batch   190  of    267.    Elapsed: 0:02:01.\n","  Batch   200  of    267.    Elapsed: 0:02:07.\n","  Batch   210  of    267.    Elapsed: 0:02:13.\n","  Batch   220  of    267.    Elapsed: 0:02:20.\n","  Batch   230  of    267.    Elapsed: 0:02:26.\n","  Batch   240  of    267.    Elapsed: 0:02:32.\n","  Batch   250  of    267.    Elapsed: 0:02:39.\n","  Batch   260  of    267.    Elapsed: 0:02:45.\n","Training\n","  Average training loss generetor: 0.719\n","  Average training loss discriminator: 0.726\n","  Training epcoh took: 0:02:49\n","Validation\n","  Accuracy: 0.511\n","  Test Loss: 2.652\n","  Test took: 0:00:23\n","\n"," Epoch = 9\n","  Batch    10  of    267.    Elapsed: 0:00:06.\n","  Batch    20  of    267.    Elapsed: 0:00:13.\n","  Batch    30  of    267.    Elapsed: 0:00:19.\n","  Batch    40  of    267.    Elapsed: 0:00:25.\n","  Batch    50  of    267.    Elapsed: 0:00:32.\n","  Batch    60  of    267.    Elapsed: 0:00:38.\n","  Batch    70  of    267.    Elapsed: 0:00:44.\n","  Batch    80  of    267.    Elapsed: 0:00:51.\n","  Batch    90  of    267.    Elapsed: 0:00:57.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:10.\n","  Batch   120  of    267.    Elapsed: 0:01:16.\n","  Batch   130  of    267.    Elapsed: 0:01:23.\n","  Batch   140  of    267.    Elapsed: 0:01:29.\n","  Batch   150  of    267.    Elapsed: 0:01:35.\n","  Batch   160  of    267.    Elapsed: 0:01:42.\n","  Batch   170  of    267.    Elapsed: 0:01:48.\n","  Batch   180  of    267.    Elapsed: 0:01:54.\n","  Batch   190  of    267.    Elapsed: 0:02:01.\n","  Batch   200  of    267.    Elapsed: 0:02:07.\n","  Batch   210  of    267.    Elapsed: 0:02:13.\n","  Batch   220  of    267.    Elapsed: 0:02:20.\n","  Batch   230  of    267.    Elapsed: 0:02:26.\n","  Batch   240  of    267.    Elapsed: 0:02:32.\n","  Batch   250  of    267.    Elapsed: 0:02:39.\n","  Batch   260  of    267.    Elapsed: 0:02:45.\n","Training\n","  Average training loss generetor: 0.716\n","  Average training loss discriminator: 0.724\n","  Training epcoh took: 0:02:49\n","Validation\n","  Accuracy: 0.506\n","  Test Loss: 2.780\n","  Test took: 0:00:23\n","\n"," Epoch = 10\n","  Batch    10  of    267.    Elapsed: 0:00:06.\n","  Batch    20  of    267.    Elapsed: 0:00:13.\n","  Batch    30  of    267.    Elapsed: 0:00:19.\n","  Batch    40  of    267.    Elapsed: 0:00:25.\n","  Batch    50  of    267.    Elapsed: 0:00:32.\n","  Batch    60  of    267.    Elapsed: 0:00:38.\n","  Batch    70  of    267.    Elapsed: 0:00:44.\n","  Batch    80  of    267.    Elapsed: 0:00:51.\n","  Batch    90  of    267.    Elapsed: 0:00:57.\n","  Batch   100  of    267.    Elapsed: 0:01:04.\n","  Batch   110  of    267.    Elapsed: 0:01:10.\n","  Batch   120  of    267.    Elapsed: 0:01:16.\n","  Batch   130  of    267.    Elapsed: 0:01:23.\n","  Batch   140  of    267.    Elapsed: 0:01:29.\n","  Batch   150  of    267.    Elapsed: 0:01:35.\n","  Batch   160  of    267.    Elapsed: 0:01:42.\n","  Batch   170  of    267.    Elapsed: 0:01:48.\n","  Batch   180  of    267.    Elapsed: 0:01:54.\n","  Batch   190  of    267.    Elapsed: 0:02:01.\n","  Batch   200  of    267.    Elapsed: 0:02:07.\n","  Batch   210  of    267.    Elapsed: 0:02:13.\n","  Batch   220  of    267.    Elapsed: 0:02:20.\n","  Batch   230  of    267.    Elapsed: 0:02:26.\n","  Batch   240  of    267.    Elapsed: 0:02:32.\n","  Batch   250  of    267.    Elapsed: 0:02:39.\n","  Batch   260  of    267.    Elapsed: 0:02:45.\n","Training\n","  Average training loss generetor: 0.716\n","  Average training loss discriminator: 0.722\n","  Training epcoh took: 0:02:49\n","Validation\n","  Accuracy: 0.497\n","  Test Loss: 2.861\n","  Test took: 0:00:23\n"]}],"source":["training_stats = []\n","epsilon = 1e-8  # Small value added for numerical stability\n","num_epochs = 10  # Number of training epochs\n","print_each_n_step = 10  # Print progress every n steps\n","apply_scheduler = False  # Flag to apply learning rate scheduler\n","warmup_proportion = 0.1  # Percentage of warmup steps for the scheduler\n","batch_size = 8\n","num_train_epochs = 10\n","# Measure total training time\n","total_time = time.time()\n","\n","# Define model parameters\n","transformer_vars = [i for i in transformer.parameters()]\n","d_vars = transformer_vars + [v for v in discriminator.parameters()]\n","g_vars = [v for v in generator.parameters()]\n","\n","# Define optimizers\n","dis_optimizer = torch.optim.AdamW(d_vars, lr=1e-5)\n","gen_optimizer = torch.optim.AdamW(g_vars, lr=1e-5)\n","\n","if apply_scheduler:\n","    num_train_examples = len(train_examples)\n","    num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n","    num_warmup_steps = int(num_train_steps * warmup_proportion)\n","\n","    # Get the learning rate scheduler\n","    scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, num_warmup_steps=num_warmup_steps)\n","    scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, num_warmup_steps=num_warmup_steps)\n","\n","# Training loop\n","for epoch_num in range(num_epochs):\n","    print(\"\")\n","    print(f' Epoch = {epoch_num + 1}')\n","    start_time = time.time()\n","\n","    total_loss_g = 0  # Initialize total generator loss\n","    total_loss_d = 0  # Initialize total discriminator loss\n","\n","    # Set models to training mode\n","    transformer.train()\n","    generator.train()\n","    discriminator.train()\n","\n","    # Iterate over batches in the training dataloader\n","    for step, batch in enumerate(train_dataloader):\n","\n","        if step % print_each_n_step == 0 and not step == 0:\n","            elapsed = format_time(time.time() - start_time)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        b_label_mask = batch[3].to(device)\n","\n","        real_batch_size = b_input_ids.shape[0]\n","\n","        # Generate fake data\n","        noise = torch.randn(real_batch_size, 100, device=device)\n","        gen_rep = generator(noise)\n","\n","        # Concatenate real and fake data for discriminator input\n","        disciminator_input = torch.cat([transformer(b_input_ids, attention_mask=b_input_mask), gen_rep], dim=0)\n","        features, logits, probs = discriminator(disciminator_input)\n","\n","        # Split discriminator's output for real and fake data\n","        features_list = torch.split(features, real_batch_size)\n","        D_real_features = features_list[0]\n","        D_fake_features = features_list[1]\n","\n","        logits_list = torch.split(logits, real_batch_size)\n","        D_real_logits = logits_list[0]\n","        D_fake_logits = logits_list[1]\n","\n","        probs_list = torch.split(probs, real_batch_size)\n","        D_real_probs = probs_list[0]\n","        D_fake_probs = probs_list[1]\n","\n","        # Calculate losses\n","        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:, -1] + epsilon))\n","        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n","        g_loss = g_loss_d + g_feat_reg\n","\n","        logits = D_real_logits[:, 0:-1]\n","        log_probs = F.log_softmax(logits, dim=-1)\n","        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n","        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n","        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n","        labeled_example_count = per_example_loss.type(torch.float32).numel()\n","\n","        if labeled_example_count == 0:\n","            D_L_Supervised = 0\n","        else:\n","            D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n","\n","        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n","        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n","        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n","\n","        gen_optimizer.zero_grad()\n","        dis_optimizer.zero_grad()\n","\n","        # Backward pass and optimization step\n","        g_loss.backward(retain_graph=True)\n","        d_loss.backward()\n","\n","        gen_optimizer.step()\n","        dis_optimizer.step()\n","\n","        # Accumulate losses\n","        total_loss_g += g_loss.item()\n","        total_loss_d += d_loss.item()\n","\n","        # Update learning rate with scheduler if applied\n","        if apply_scheduler:\n","            scheduler_d.step()\n","            scheduler_g.step()\n","\n","    # Calculate average losses\n","    avg_train_loss_g = total_loss_g / len(train_dataloader)\n","    avg_train_loss_d = total_loss_d / len(train_dataloader)\n","\n","    training_time = format_time(time.time() - start_time)\n","\n","    print(\"Training\")\n","    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n","    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","\n","    # Validation\n","    print(\"Validation\")\n","\n","    start_time = time.time()\n","\n","    transformer.eval()\n","    discriminator.eval()\n","    generator.eval()\n","\n","    total_test_accuracy = 0\n","    total_test_loss = 0\n","    nb_test_steps = 0\n","\n","    all_preds = []\n","    all_labels_ids = []\n","    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n","\n","    for batch in test_dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        with torch.no_grad():\n","            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n","            _, logits, probs = discriminator(model_outputs)\n","            filtered_logits = logits[:, 0:-1]\n","            total_test_loss += nll_loss(filtered_logits, b_labels)\n","\n","        _, preds = torch.max(filtered_logits, 1)\n","        all_preds += preds.detach().cpu()\n","        all_labels_ids += b_labels.detach().cpu()\n","\n","    all_preds = torch.stack(all_preds).numpy()\n","    all_labels_ids = torch.stack(all_labels_ids).numpy()\n","    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n","    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n","\n","    avg_test_loss = total_test_loss / len(test_dataloader)\n","    avg_test_loss = avg_test_loss.item()\n","\n","    test_time = format_time(time.time() - start_time)\n","\n","    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n","    print(\"  Test took: {:}\".format(test_time))\n","\n","    training_stats.append(\n","        {\n","            'epoch': epoch_num + 1,\n","            'Training Loss generator': avg_train_loss_g,\n","            'Training Loss discriminator': avg_train_loss_d,\n","            'Valid. Loss': avg_test_loss,\n","            'Valid. Accur.': test_accuracy,\n","            'Training Time': training_time,\n","            'Test Time': test_time\n","        }\n","    )\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-02-03T21:38:37.041881Z","iopub.status.busy":"2024-02-03T21:38:37.041505Z","iopub.status.idle":"2024-02-03T21:38:37.047269Z","shell.execute_reply":"2024-02-03T21:38:37.046351Z","shell.execute_reply.started":"2024-02-03T21:38:37.041851Z"},"id":"dDm9NProRB4c","outputId":"2ffebcf1-6b39-4442-88c6-5f72a58a3722","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'epoch': 1, 'Training Loss generator': 0.5251315175817254, 'Training Loss discriminator': 2.8015501624189514, 'Valid. Loss': 1.449839472770691, 'Valid. Accur.': 0.399, 'Training Time': '0:02:50', 'Test Time': '0:00:23'}\n","{'epoch': 2, 'Training Loss generator': 0.7474294856246491, 'Training Loss discriminator': 1.5577362373973547, 'Valid. Loss': 1.4101380109786987, 'Valid. Accur.': 0.44466666666666665, 'Training Time': '0:02:49', 'Test Time': '0:00:23'}\n","{'epoch': 3, 'Training Loss generator': 0.7402147367205959, 'Training Loss discriminator': 1.0584569765387404, 'Valid. Loss': 2.1029582023620605, 'Valid. Accur.': 0.4686666666666667, 'Training Time': '0:02:49', 'Test Time': '0:00:23'}\n","{'epoch': 4, 'Training Loss generator': 0.7336423379205139, 'Training Loss discriminator': 0.8370720717344391, 'Valid. Loss': 2.3337581157684326, 'Valid. Accur.': 0.49766666666666665, 'Training Time': '0:02:49', 'Test Time': '0:00:23'}\n","{'epoch': 5, 'Training Loss generator': 0.7295457709594613, 'Training Loss discriminator': 0.77722805202677, 'Valid. Loss': 2.3142919540405273, 'Valid. Accur.': 0.5056666666666667, 'Training Time': '0:02:49', 'Test Time': '0:00:23'}\n","{'epoch': 6, 'Training Loss generator': 0.723517933365111, 'Training Loss discriminator': 0.7411749117383349, 'Valid. Loss': 2.52864933013916, 'Valid. Accur.': 0.5016666666666667, 'Training Time': '0:02:49', 'Test Time': '0:00:23'}\n","{'epoch': 7, 'Training Loss generator': 0.719955386740438, 'Training Loss discriminator': 0.7282235548737344, 'Valid. Loss': 2.6325039863586426, 'Valid. Accur.': 0.5023333333333333, 'Training Time': '0:02:49', 'Test Time': '0:00:23'}\n","{'epoch': 8, 'Training Loss generator': 0.7191280472591128, 'Training Loss discriminator': 0.7255369790930873, 'Valid. Loss': 2.6517186164855957, 'Valid. Accur.': 0.5113333333333333, 'Training Time': '0:02:49', 'Test Time': '0:00:23'}\n","{'epoch': 9, 'Training Loss generator': 0.7156966252719865, 'Training Loss discriminator': 0.7238981540729937, 'Valid. Loss': 2.7799031734466553, 'Valid. Accur.': 0.5056666666666667, 'Training Time': '0:02:49', 'Test Time': '0:00:23'}\n","{'epoch': 10, 'Training Loss generator': 0.7160400129882584, 'Training Loss discriminator': 0.7217679840795109, 'Valid. Loss': 2.860692262649536, 'Valid. Accur.': 0.497, 'Training Time': '0:02:49', 'Test Time': '0:00:23'}\n"]}],"source":["for stat in training_stats:\n","    print(stat)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"include_colab_link":true,"name":"GANBERT_pytorch croce.ipynb","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4288371,"sourceId":7379337,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0097aa33393342cd99be3dcc30edc5a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_504e8c3a107e4e04b51df39e1b3c584e","max":435779157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a56008dc6c6b41c3850611cc15fb6ea8","value":435779157}},"098f203f1209452a9d4192af92da7057":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b94243bfea7e4441b809b38c7cecd875","IPY_MODEL_0097aa33393342cd99be3dcc30edc5a0","IPY_MODEL_293c4d8660f546f79b43e0dc63250c2f"],"layout":"IPY_MODEL_ec76cfd2d1da498e9b66885ff1be46b3"}},"0dccd0ab28c34880be92b35aa05e6ffb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14a6abbb244b41f89626a37640c63118":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14bf2ab82bfc45bd8a3b93f2ab9aa656":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"193a5a054d6f4a319842820c4c308322":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b465cf9004f549ffa85444bfa16ee4c2","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7bef2816920414f99a5c9cc676ec254","value":213450}},"1f25240f5457445795af70e20e5903f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22cde8fbae4e49af993e33f3f2d9a28e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_44660941ffcc44beae72a1974d458583","IPY_MODEL_afdbd837001c4c74b5ac332ca061ef3a","IPY_MODEL_b489404bf53b4fab9bdb1c0c79a33008"],"layout":"IPY_MODEL_2c671428c4df4355a7a53c71e9bd14ee"}},"28f045edfa48462fa96a94cffd3b143f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"293c4d8660f546f79b43e0dc63250c2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5110d1cb9a7547f49244113dc5dd8321","placeholder":"","style":"IPY_MODEL_1f25240f5457445795af70e20e5903f9","value":" 436M/436M [00:29&lt;00:00, 14.8MB/s]"}},"2bfb43b9e8604cbf8ebfd162267f1b8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c671428c4df4355a7a53c71e9bd14ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30e0829529874db1802f411f72f3d76a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f41b83ccf26c40ed88ca6eaf49e09de5","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0f0d9a0d4f4440e81e5a6d5a2a3b4ab","value":435797}},"44660941ffcc44beae72a1974d458583":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f556917850542da8508f9f839cae9bc","placeholder":"","style":"IPY_MODEL_2bfb43b9e8604cbf8ebfd162267f1b8a","value":"Downloading: 100%"}},"4d22913664fb4cdbb38e217d4197601d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f556917850542da8508f9f839cae9bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"504e8c3a107e4e04b51df39e1b3c584e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5110d1cb9a7547f49244113dc5dd8321":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"547d7329b8554b7bb8ae51d61a5e41f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bac8f28c84144450b24bbc97fa4860db","IPY_MODEL_30e0829529874db1802f411f72f3d76a","IPY_MODEL_83dd72fbb4204fefb951b3800d73a8d2"],"layout":"IPY_MODEL_81b6bafd3fc248afa76cf463f2cb8ab8"}},"5a478b81997c4263a60d938447232fd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d501eb3d36e48128a5232879141b281","placeholder":"","style":"IPY_MODEL_748d5c1fb00e4d91809003527319a9f6","value":" 213k/213k [00:00&lt;00:00, 102kB/s]"}},"5fbebd67d40e470e8a75a4b5b540bbdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"748d5c1fb00e4d91809003527319a9f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d501eb3d36e48128a5232879141b281":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81b6bafd3fc248afa76cf463f2cb8ab8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83dd72fbb4204fefb951b3800d73a8d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b79fef6d585843c0a4d885edb2d01ebd","placeholder":"","style":"IPY_MODEL_be6339f6256d4b579c53ef8b430ecb25","value":" 436k/436k [00:00&lt;00:00, 1.26MB/s]"}},"870fe8f58bb24a47b6a98fa0eed0ebf5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8b619dff35e4f8cabf586221ad8c962","placeholder":"","style":"IPY_MODEL_5fbebd67d40e470e8a75a4b5b540bbdf","value":"Downloading: 100%"}},"9fc9479d78e442db91360de7f45b6d7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a56008dc6c6b41c3850611cc15fb6ea8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afdbd837001c4c74b5ac332ca061ef3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14a6abbb244b41f89626a37640c63118","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28f045edfa48462fa96a94cffd3b143f","value":570}},"b465cf9004f549ffa85444bfa16ee4c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b489404bf53b4fab9bdb1c0c79a33008":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf127a02cf6647aba4035c5cbfadc378","placeholder":"","style":"IPY_MODEL_0dccd0ab28c34880be92b35aa05e6ffb","value":" 570/570 [00:00&lt;00:00, 12.0kB/s]"}},"b79fef6d585843c0a4d885edb2d01ebd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b94243bfea7e4441b809b38c7cecd875":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14bf2ab82bfc45bd8a3b93f2ab9aa656","placeholder":"","style":"IPY_MODEL_9fc9479d78e442db91360de7f45b6d7f","value":"Downloading: 100%"}},"bac8f28c84144450b24bbc97fa4860db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddf20490dc874352aa7df35f07a60bcc","placeholder":"","style":"IPY_MODEL_f9390d4fc9b147729f1ef5ea85d03774","value":"Downloading: 100%"}},"be6339f6256d4b579c53ef8b430ecb25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf127a02cf6647aba4035c5cbfadc378":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0f0d9a0d4f4440e81e5a6d5a2a3b4ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3a13b7869354881ac7b7887e05d56a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_870fe8f58bb24a47b6a98fa0eed0ebf5","IPY_MODEL_193a5a054d6f4a319842820c4c308322","IPY_MODEL_5a478b81997c4263a60d938447232fd9"],"layout":"IPY_MODEL_4d22913664fb4cdbb38e217d4197601d"}},"d7bef2816920414f99a5c9cc676ec254":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d8b619dff35e4f8cabf586221ad8c962":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddf20490dc874352aa7df35f07a60bcc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec76cfd2d1da498e9b66885ff1be46b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f41b83ccf26c40ed88ca6eaf49e09de5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9390d4fc9b147729f1ef5ea85d03774":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":4}
