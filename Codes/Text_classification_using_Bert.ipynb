{"metadata":{"accelerator":"GPU","colab":{"name":"GANBERT_pytorch croce.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7379337,"sourceType":"datasetVersion","datasetId":4288371}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport io\nimport torch.nn.functional as F\nimport numpy as np\nimport time\nimport math\nimport datetime\nfrom transformers import AutoModel, AutoTokenizer , AutoConfig\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nimport random\n\n\n##Set random values\nseed_val = 42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed_val)","metadata":{"id":"UIqpm34x2rms","execution":{"iopub.status.busy":"2024-02-02T14:33:00.711084Z","iopub.execute_input":"2024-02-02T14:33:00.711402Z","iopub.status.idle":"2024-02-02T14:33:06.675796Z","shell.execute_reply.started":"2024-02-02T14:33:00.711377Z","shell.execute_reply":"2024-02-02T14:33:06.674836Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import json\n\n\ndata_list = []\nfile_path = \"/kaggle/input/subtaskB_train.jsonl\"\nwith open(file_path, 'r') as file:\n    for line in file:\n        json_object = json.loads(line)\n        data_list.append(json_object)\ntest_list = []\nfile_path = \"/kaggle/input/subtaskB_dev.jsonl\"\nwith open(file_path, 'r') as file:\n    for line in file:\n        json_object = json.loads(line)\n        test_list.append(json_object)","metadata":{"id":"rCO_hOeKfeeu","execution":{"iopub.status.busy":"2024-02-02T14:33:06.677389Z","iopub.execute_input":"2024-02-02T14:33:06.677830Z","iopub.status.idle":"2024-02-02T14:33:09.863738Z","shell.execute_reply.started":"2024-02-02T14:33:06.677788Z","shell.execute_reply":"2024-02-02T14:33:09.862931Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(data_list)\nmodel_counts = df.groupby('model').size().reset_index(name='Count')\ndel df\nlabel_map = {}\nlabel_list = list(model_counts.model)\nfor (i, label) in enumerate(label_list):\n    label_map[label] = i\ninverted_label_map = {value: key for key, value in label_map.items()}\ndisplay(model_counts)","metadata":{"id":"LY9dXq5DkV3v","outputId":"b2797775-5d99-45b3-c65d-8fa6d433bac8","colab":{"base_uri":"https://localhost:8080/","height":268},"execution":{"iopub.status.busy":"2024-02-02T14:33:09.864781Z","iopub.execute_input":"2024-02-02T14:33:09.865064Z","iopub.status.idle":"2024-02-02T14:33:10.962181Z","shell.execute_reply.started":"2024-02-02T14:33:09.865035Z","shell.execute_reply":"2024-02-02T14:33:10.961244Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"     model  Count\n0   bloomz  11998\n1  chatGPT  11995\n2   cohere  11336\n3  davinci  11999\n4    dolly  11702\n5    human  11997","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bloomz</td>\n      <td>11998</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>chatGPT</td>\n      <td>11995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cohere</td>\n      <td>11336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>davinci</td>\n      <td>11999</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dolly</td>\n      <td>11702</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>human</td>\n      <td>11997</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# If there's a GPU available...\nif torch.cuda.is_available():\n    # Tell PyTorch to use the GPU.\n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"id":"LeZgRup520II","colab":{"base_uri":"https://localhost:8080/"},"outputId":"da46c7ac-1f97-4442-e575-b2c870a564cf","execution":{"iopub.status.busy":"2024-02-02T14:33:10.964258Z","iopub.execute_input":"2024-02-02T14:33:10.964674Z","iopub.status.idle":"2024-02-02T14:33:10.990368Z","shell.execute_reply.started":"2024-02-02T14:33:10.964647Z","shell.execute_reply":"2024-02-02T14:33:10.989484Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport random\n\nclass CustomDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length= 128 , percentage = 0.01):\n        random.shuffle(data)\n        self.data = data[: int( percentage * len(data))]\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data[idx]['text']\n        label = label_map[self.data[idx]['model']]\n\n        # Tokenize input text\n        inputs = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n\n        # Convert label to tensor\n        label_tensor = torch.tensor(label)\n        \n        return {\n            'input_ids': inputs['input_ids'].squeeze(),\n            'attention_mask': inputs['attention_mask'].squeeze(),\n            'label': label_tensor\n        }","metadata":{"execution":{"iopub.status.busy":"2024-02-02T14:33:10.992610Z","iopub.execute_input":"2024-02-02T14:33:10.993316Z","iopub.status.idle":"2024-02-02T14:33:11.000937Z","shell.execute_reply.started":"2024-02-02T14:33:10.993290Z","shell.execute_reply":"2024-02-02T14:33:11.000009Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\n# del model, org_image, changed_image, labels\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-02T14:33:11.002085Z","iopub.execute_input":"2024-02-02T14:33:11.002395Z","iopub.status.idle":"2024-02-02T14:33:11.138770Z","shell.execute_reply.started":"2024-02-02T14:33:11.002366Z","shell.execute_reply":"2024-02-02T14:33:11.137780Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"69"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AdamW, BertConfig, BertForSequenceClassification, BertTokenizer\nfrom sklearn.metrics import accuracy_score,f1_score, classification_report\nimport time\nimport warnings\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n### Deffine Bert Tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n### Hyper Parameters \npercentages = [0.01, 0.05, 0.1, 0.5]\nbatch_size = 16\nnum_epochs = 10\nprinter_controler = 0\naccuracies = []\nbest_accuracy = 0\nweighted_f1s = []\nbest_weighted_f1 = 0\nnum_workers = 2\n### Using 1,5,10,50 %  of Training Data\nfor percentage in percentages:\n    printer_controler += 1 \n    print(\"#\"* 80)\n    print(f\"\\033[1m Percentage of training data = {percentage * 100 } % \\033[0m\") \n    ### Load Bert classifier and optimizer \n    model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels = 6 ).to(device)\n    optimizer = AdamW(model.parameters(), lr=1e-5)\n    max_length = 256\n    ### Define Train and Validation Dataset\n    train_dataset = CustomDataset(data_list, tokenizer = tokenizer, max_length = max_length, percentage = percentage )\n    test_dataset = CustomDataset(test_list, tokenizer = tokenizer, max_length = max_length, percentage = 1)\n    # Create Train & Validation DataLoader \n    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n    valid_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=True)\n    \n    # Training loop\n    ### Calculate Time\n    start_time = time.time() \n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        train_labels = []\n        train_predictions = []\n        for (idx,batch) in enumerate(dataloader):\n            ### Using Gpu Device\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            optimizer.zero_grad()\n            ### Define loss of Classifier and EBP\n            loss = model(input_ids = input_ids ,attention_mask = attention_mask , labels = labels).loss\n            outputs = model(input_ids = input_ids ,attention_mask = attention_mask)\n            logits = outputs.logits\n            predictions = torch.argmax(logits, dim=1)\n            ### Calculate Accuracy on Train Data\n            train_labels.extend(labels.cpu().numpy())\n            train_predictions.extend(predictions.cpu().numpy())\n            total_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            if (idx+1) % ( 10 * printer_controler )  == 0 :\n                end_time = time.time()  \n                training_time = end_time - start_time \n                training_time = str(datetime.timedelta(seconds=int(training_time)))\n                print(f\"Epoch = {epoch+1}, Iteration = {idx + 1 }/ {len(dataloader)}  ===> Average training loss = , {'{:.3f}'.format(total_loss/(idx )) }, Training Time: {training_time}\" ) \n        \n        train_accuracy = accuracy_score(train_labels, train_predictions)\n\n        print(f\"Epoch = {epoch+1} ===> training_accuracy ={'{:.3f}'.format(train_accuracy) } \" )\n        \n        model.eval()\n        all_labels = []\n        all_predictions = []\n        with torch.no_grad():\n            for batch in valid_dataloader:\n                input_ids, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n                outputs = model(input_ids, attention_mask=attention_mask)\n                logits = outputs.logits\n                predictions = torch.argmax(logits, dim=1)\n                all_labels.extend(labels.cpu().numpy())\n                all_predictions.extend(predictions.cpu().numpy())\n            accuracy = accuracy_score(all_labels, all_predictions)\n            best_accuracy = max(accuracy, best_accuracy)\n            if accuracy == best_accuracy :\n                output_dir = f\"/kaggle/working/best_model_for_{percentage*100}_percentage\"\n                model.save_pretrained(output_dir)\n        weighted_f1 = f1_score(all_labels, all_predictions, average='weighted')\n        print(f'Weighted F1 Score: {weighted_f1:.4f}')\n        best_weighted_f1 = max(weighted_f1, best_weighted_f1)\n        f1_per_class = f1_score(all_labels, all_predictions, average = None)\n        print(f\"\\033[1mEpoch = {epoch+1} ====> Accuracy On Validation Dataset={'{:.3f}'.format(accuracy) }\\033[0m\")\n        \n        for class_idx, f1 in enumerate(f1_per_class):\n            print(f'F1 Score (Class {inverted_label_map[class_idx]}): {f1:.4f}')\n        print()\n    accuracies.append(best_accuracy)\n    weighted_f1s.append(best_weighted_f1)\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")","metadata":{"id":"TgKUgRxdfsq1","execution":{"iopub.status.busy":"2024-02-01T22:09:07.109628Z","iopub.execute_input":"2024-02-01T22:09:07.109961Z","iopub.status.idle":"2024-02-02T02:46:30.805165Z","shell.execute_reply.started":"2024-02-01T22:09:07.109912Z","shell.execute_reply":"2024-02-02T02:46:30.803955Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"################################################################################\n\u001b[1m Percentage of training data = 1.0 % \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch = 1, Iteration = 10/ 45  ===> Average training loss = , 2.025, Training Time: 0:00:06\nEpoch = 1, Iteration = 20/ 45  ===> Average training loss = , 1.915, Training Time: 0:00:11\nEpoch = 1, Iteration = 30/ 45  ===> Average training loss = , 1.878, Training Time: 0:00:16\nEpoch = 1, Iteration = 40/ 45  ===> Average training loss = , 1.851, Training Time: 0:00:21\nEpoch = 1 ===> training_accuracy =0.182 \nWeighted F1 Score: 0.2283\n\u001b[1mEpoch = 1 ====> Accuracy On Validation Dataset=0.305\u001b[0m\nF1 Score (Class bloomz): 0.5090\nF1 Score (Class chatGPT): 0.3951\nF1 Score (Class cohere): 0.2342\nF1 Score (Class davinci): 0.2006\nF1 Score (Class dolly): 0.0000\nF1 Score (Class human): 0.0311\n\nEpoch = 2, Iteration = 10/ 45  ===> Average training loss = , 1.920, Training Time: 0:01:16\nEpoch = 2, Iteration = 20/ 45  ===> Average training loss = , 1.796, Training Time: 0:01:21\nEpoch = 2, Iteration = 30/ 45  ===> Average training loss = , 1.758, Training Time: 0:01:26\nEpoch = 2, Iteration = 40/ 45  ===> Average training loss = , 1.724, Training Time: 0:01:31\nEpoch = 2 ===> training_accuracy =0.337 \nWeighted F1 Score: 0.3179\n\u001b[1mEpoch = 2 ====> Accuracy On Validation Dataset=0.347\u001b[0m\nF1 Score (Class bloomz): 0.6421\nF1 Score (Class chatGPT): 0.3182\nF1 Score (Class cohere): 0.2944\nF1 Score (Class davinci): 0.1480\nF1 Score (Class dolly): 0.2013\nF1 Score (Class human): 0.3030\n\nEpoch = 3, Iteration = 10/ 45  ===> Average training loss = , 1.727, Training Time: 0:02:27\nEpoch = 3, Iteration = 20/ 45  ===> Average training loss = , 1.576, Training Time: 0:02:32\nEpoch = 3, Iteration = 30/ 45  ===> Average training loss = , 1.550, Training Time: 0:02:37\nEpoch = 3, Iteration = 40/ 45  ===> Average training loss = , 1.527, Training Time: 0:02:42\nEpoch = 3 ===> training_accuracy =0.415 \nWeighted F1 Score: 0.3217\n\u001b[1mEpoch = 3 ====> Accuracy On Validation Dataset=0.360\u001b[0m\nF1 Score (Class bloomz): 0.6471\nF1 Score (Class chatGPT): 0.3404\nF1 Score (Class cohere): 0.1814\nF1 Score (Class davinci): 0.2848\nF1 Score (Class dolly): 0.1562\nF1 Score (Class human): 0.3203\n\nEpoch = 4, Iteration = 10/ 45  ===> Average training loss = , 1.539, Training Time: 0:03:39\nEpoch = 4, Iteration = 20/ 45  ===> Average training loss = , 1.398, Training Time: 0:03:44\nEpoch = 4, Iteration = 30/ 45  ===> Average training loss = , 1.360, Training Time: 0:03:49\nEpoch = 4, Iteration = 40/ 45  ===> Average training loss = , 1.315, Training Time: 0:03:54\nEpoch = 4 ===> training_accuracy =0.546 \nWeighted F1 Score: 0.3645\n\u001b[1mEpoch = 4 ====> Accuracy On Validation Dataset=0.438\u001b[0m\nF1 Score (Class bloomz): 0.7553\nF1 Score (Class chatGPT): 0.5230\nF1 Score (Class cohere): 0.2334\nF1 Score (Class davinci): 0.3896\nF1 Score (Class dolly): 0.0372\nF1 Score (Class human): 0.2484\n\nEpoch = 5, Iteration = 10/ 45  ===> Average training loss = , 1.280, Training Time: 0:04:50\nEpoch = 5, Iteration = 20/ 45  ===> Average training loss = , 1.200, Training Time: 0:04:55\nEpoch = 5, Iteration = 30/ 45  ===> Average training loss = , 1.153, Training Time: 0:05:00\nEpoch = 5, Iteration = 40/ 45  ===> Average training loss = , 1.115, Training Time: 0:05:05\nEpoch = 5 ===> training_accuracy =0.637 \nWeighted F1 Score: 0.4254\n\u001b[1mEpoch = 5 ====> Accuracy On Validation Dataset=0.442\u001b[0m\nF1 Score (Class bloomz): 0.8406\nF1 Score (Class chatGPT): 0.5255\nF1 Score (Class cohere): 0.3784\nF1 Score (Class davinci): 0.1731\nF1 Score (Class dolly): 0.1410\nF1 Score (Class human): 0.4941\n\nEpoch = 6, Iteration = 10/ 45  ===> Average training loss = , 1.017, Training Time: 0:06:01\nEpoch = 6, Iteration = 20/ 45  ===> Average training loss = , 0.974, Training Time: 0:06:06\nEpoch = 6, Iteration = 30/ 45  ===> Average training loss = , 0.948, Training Time: 0:06:11\nEpoch = 6, Iteration = 40/ 45  ===> Average training loss = , 0.922, Training Time: 0:06:17\nEpoch = 6 ===> training_accuracy =0.720 \nWeighted F1 Score: 0.4438\n\u001b[1mEpoch = 6 ====> Accuracy On Validation Dataset=0.464\u001b[0m\nF1 Score (Class bloomz): 0.8492\nF1 Score (Class chatGPT): 0.5855\nF1 Score (Class cohere): 0.2503\nF1 Score (Class davinci): 0.2960\nF1 Score (Class dolly): 0.1814\nF1 Score (Class human): 0.5005\n\nEpoch = 7, Iteration = 10/ 45  ===> Average training loss = , 0.801, Training Time: 0:07:12\nEpoch = 7, Iteration = 20/ 45  ===> Average training loss = , 0.765, Training Time: 0:07:17\nEpoch = 7, Iteration = 30/ 45  ===> Average training loss = , 0.771, Training Time: 0:07:23\nEpoch = 7, Iteration = 40/ 45  ===> Average training loss = , 0.751, Training Time: 0:07:28\nEpoch = 7 ===> training_accuracy =0.804 \nWeighted F1 Score: 0.4707\n\u001b[1mEpoch = 7 ====> Accuracy On Validation Dataset=0.473\u001b[0m\nF1 Score (Class bloomz): 0.8651\nF1 Score (Class chatGPT): 0.5012\nF1 Score (Class cohere): 0.4060\nF1 Score (Class davinci): 0.2460\nF1 Score (Class dolly): 0.2537\nF1 Score (Class human): 0.5524\n\nEpoch = 8, Iteration = 10/ 45  ===> Average training loss = , 0.614, Training Time: 0:08:24\nEpoch = 8, Iteration = 20/ 45  ===> Average training loss = , 0.591, Training Time: 0:08:29\nEpoch = 8, Iteration = 30/ 45  ===> Average training loss = , 0.580, Training Time: 0:08:34\nEpoch = 8, Iteration = 40/ 45  ===> Average training loss = , 0.597, Training Time: 0:08:39\nEpoch = 8 ===> training_accuracy =0.865 \nWeighted F1 Score: 0.4599\n\u001b[1mEpoch = 8 ====> Accuracy On Validation Dataset=0.471\u001b[0m\nF1 Score (Class bloomz): 0.8429\nF1 Score (Class chatGPT): 0.5712\nF1 Score (Class cohere): 0.3594\nF1 Score (Class davinci): 0.3296\nF1 Score (Class dolly): 0.1899\nF1 Score (Class human): 0.4665\n\nEpoch = 9, Iteration = 10/ 45  ===> Average training loss = , 0.563, Training Time: 0:09:34\nEpoch = 9, Iteration = 20/ 45  ===> Average training loss = , 0.529, Training Time: 0:09:39\nEpoch = 9, Iteration = 30/ 45  ===> Average training loss = , 0.504, Training Time: 0:09:44\nEpoch = 9, Iteration = 40/ 45  ===> Average training loss = , 0.496, Training Time: 0:09:49\nEpoch = 9 ===> training_accuracy =0.928 \nWeighted F1 Score: 0.4489\n\u001b[1mEpoch = 9 ====> Accuracy On Validation Dataset=0.448\u001b[0m\nF1 Score (Class bloomz): 0.8769\nF1 Score (Class chatGPT): 0.3211\nF1 Score (Class cohere): 0.4313\nF1 Score (Class davinci): 0.2018\nF1 Score (Class dolly): 0.2878\nF1 Score (Class human): 0.5748\n\nEpoch = 10, Iteration = 10/ 45  ===> Average training loss = , 0.518, Training Time: 0:10:44\nEpoch = 10, Iteration = 20/ 45  ===> Average training loss = , 0.435, Training Time: 0:10:49\nEpoch = 10, Iteration = 30/ 45  ===> Average training loss = , 0.416, Training Time: 0:10:54\nEpoch = 10, Iteration = 40/ 45  ===> Average training loss = , 0.406, Training Time: 0:10:59\nEpoch = 10 ===> training_accuracy =0.949 \nWeighted F1 Score: 0.4448\n\u001b[1mEpoch = 10 ====> Accuracy On Validation Dataset=0.441\u001b[0m\nF1 Score (Class bloomz): 0.8730\nF1 Score (Class chatGPT): 0.2818\nF1 Score (Class cohere): 0.3575\nF1 Score (Class davinci): 0.2760\nF1 Score (Class dolly): 0.3532\nF1 Score (Class human): 0.5271\n\n################################################################################\n\u001b[1m Percentage of training data = 5.0 % \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch = 1, Iteration = 20/ 222  ===> Average training loss = , 1.949, Training Time: 0:00:10\nEpoch = 1, Iteration = 40/ 222  ===> Average training loss = , 1.866, Training Time: 0:00:20\nEpoch = 1, Iteration = 60/ 222  ===> Average training loss = , 1.833, Training Time: 0:00:30\nEpoch = 1, Iteration = 80/ 222  ===> Average training loss = , 1.805, Training Time: 0:00:40\nEpoch = 1, Iteration = 100/ 222  ===> Average training loss = , 1.776, Training Time: 0:00:50\nEpoch = 1, Iteration = 120/ 222  ===> Average training loss = , 1.747, Training Time: 0:01:00\nEpoch = 1, Iteration = 140/ 222  ===> Average training loss = , 1.717, Training Time: 0:01:10\nEpoch = 1, Iteration = 160/ 222  ===> Average training loss = , 1.692, Training Time: 0:01:20\nEpoch = 1, Iteration = 180/ 222  ===> Average training loss = , 1.659, Training Time: 0:01:31\nEpoch = 1, Iteration = 200/ 222  ===> Average training loss = , 1.624, Training Time: 0:01:41\nEpoch = 1, Iteration = 220/ 222  ===> Average training loss = , 1.589, Training Time: 0:01:51\nEpoch = 1 ===> training_accuracy =0.366 \nWeighted F1 Score: 0.3555\n\u001b[1mEpoch = 1 ====> Accuracy On Validation Dataset=0.409\u001b[0m\nF1 Score (Class bloomz): 0.8091\nF1 Score (Class chatGPT): 0.4587\nF1 Score (Class cohere): 0.3356\nF1 Score (Class davinci): 0.0462\nF1 Score (Class dolly): 0.0079\nF1 Score (Class human): 0.4752\n\nEpoch = 2, Iteration = 20/ 222  ===> Average training loss = , 1.151, Training Time: 0:02:49\nEpoch = 2, Iteration = 40/ 222  ===> Average training loss = , 1.106, Training Time: 0:02:59\nEpoch = 2, Iteration = 60/ 222  ===> Average training loss = , 1.045, Training Time: 0:03:09\nEpoch = 2, Iteration = 80/ 222  ===> Average training loss = , 1.030, Training Time: 0:03:19\nEpoch = 2, Iteration = 100/ 222  ===> Average training loss = , 1.003, Training Time: 0:03:30\nEpoch = 2, Iteration = 120/ 222  ===> Average training loss = , 0.984, Training Time: 0:03:40\nEpoch = 2, Iteration = 140/ 222  ===> Average training loss = , 0.964, Training Time: 0:03:50\nEpoch = 2, Iteration = 160/ 222  ===> Average training loss = , 0.939, Training Time: 0:04:00\nEpoch = 2, Iteration = 180/ 222  ===> Average training loss = , 0.918, Training Time: 0:04:10\nEpoch = 2, Iteration = 200/ 222  ===> Average training loss = , 0.897, Training Time: 0:04:20\nEpoch = 2, Iteration = 220/ 222  ===> Average training loss = , 0.888, Training Time: 0:04:30\nEpoch = 2 ===> training_accuracy =0.690 \nWeighted F1 Score: 0.5025\n\u001b[1mEpoch = 2 ====> Accuracy On Validation Dataset=0.524\u001b[0m\nF1 Score (Class bloomz): 0.9046\nF1 Score (Class chatGPT): 0.6011\nF1 Score (Class cohere): 0.4432\nF1 Score (Class davinci): 0.1020\nF1 Score (Class dolly): 0.3768\nF1 Score (Class human): 0.5874\n\nEpoch = 3, Iteration = 20/ 222  ===> Average training loss = , 0.598, Training Time: 0:05:29\nEpoch = 3, Iteration = 40/ 222  ===> Average training loss = , 0.586, Training Time: 0:05:39\nEpoch = 3, Iteration = 60/ 222  ===> Average training loss = , 0.597, Training Time: 0:05:50\nEpoch = 3, Iteration = 80/ 222  ===> Average training loss = , 0.576, Training Time: 0:06:00\nEpoch = 3, Iteration = 100/ 222  ===> Average training loss = , 0.557, Training Time: 0:06:10\nEpoch = 3, Iteration = 120/ 222  ===> Average training loss = , 0.558, Training Time: 0:06:20\nEpoch = 3, Iteration = 140/ 222  ===> Average training loss = , 0.550, Training Time: 0:06:30\nEpoch = 3, Iteration = 160/ 222  ===> Average training loss = , 0.546, Training Time: 0:06:40\nEpoch = 3, Iteration = 180/ 222  ===> Average training loss = , 0.539, Training Time: 0:06:50\nEpoch = 3, Iteration = 200/ 222  ===> Average training loss = , 0.540, Training Time: 0:07:00\nEpoch = 3, Iteration = 220/ 222  ===> Average training loss = , 0.535, Training Time: 0:07:10\nEpoch = 3 ===> training_accuracy =0.818 \nWeighted F1 Score: 0.4805\n\u001b[1mEpoch = 3 ====> Accuracy On Validation Dataset=0.508\u001b[0m\nF1 Score (Class bloomz): 0.8969\nF1 Score (Class chatGPT): 0.5347\nF1 Score (Class cohere): 0.4094\nF1 Score (Class davinci): 0.0426\nF1 Score (Class dolly): 0.4205\nF1 Score (Class human): 0.5789\n\nEpoch = 4, Iteration = 20/ 222  ===> Average training loss = , 0.381, Training Time: 0:08:08\nEpoch = 4, Iteration = 40/ 222  ===> Average training loss = , 0.354, Training Time: 0:08:18\nEpoch = 4, Iteration = 60/ 222  ===> Average training loss = , 0.363, Training Time: 0:08:29\nEpoch = 4, Iteration = 80/ 222  ===> Average training loss = , 0.347, Training Time: 0:08:39\nEpoch = 4, Iteration = 100/ 222  ===> Average training loss = , 0.341, Training Time: 0:08:49\nEpoch = 4, Iteration = 120/ 222  ===> Average training loss = , 0.346, Training Time: 0:08:59\nEpoch = 4, Iteration = 140/ 222  ===> Average training loss = , 0.340, Training Time: 0:09:09\nEpoch = 4, Iteration = 160/ 222  ===> Average training loss = , 0.332, Training Time: 0:09:19\nEpoch = 4, Iteration = 180/ 222  ===> Average training loss = , 0.327, Training Time: 0:09:29\nEpoch = 4, Iteration = 200/ 222  ===> Average training loss = , 0.323, Training Time: 0:09:39\nEpoch = 4, Iteration = 220/ 222  ===> Average training loss = , 0.326, Training Time: 0:09:49\nEpoch = 4 ===> training_accuracy =0.892 \nWeighted F1 Score: 0.5166\n\u001b[1mEpoch = 4 ====> Accuracy On Validation Dataset=0.525\u001b[0m\nF1 Score (Class bloomz): 0.9221\nF1 Score (Class chatGPT): 0.5171\nF1 Score (Class cohere): 0.4201\nF1 Score (Class davinci): 0.1679\nF1 Score (Class dolly): 0.4857\nF1 Score (Class human): 0.5866\n\nEpoch = 5, Iteration = 20/ 222  ===> Average training loss = , 0.210, Training Time: 0:10:49\nEpoch = 5, Iteration = 40/ 222  ===> Average training loss = , 0.205, Training Time: 0:10:59\nEpoch = 5, Iteration = 60/ 222  ===> Average training loss = , 0.200, Training Time: 0:11:09\nEpoch = 5, Iteration = 80/ 222  ===> Average training loss = , 0.191, Training Time: 0:11:19\nEpoch = 5, Iteration = 100/ 222  ===> Average training loss = , 0.178, Training Time: 0:11:29\nEpoch = 5, Iteration = 120/ 222  ===> Average training loss = , 0.187, Training Time: 0:11:39\nEpoch = 5, Iteration = 140/ 222  ===> Average training loss = , 0.181, Training Time: 0:11:49\nEpoch = 5, Iteration = 160/ 222  ===> Average training loss = , 0.179, Training Time: 0:11:59\nEpoch = 5, Iteration = 180/ 222  ===> Average training loss = , 0.174, Training Time: 0:12:09\nEpoch = 5, Iteration = 200/ 222  ===> Average training loss = , 0.174, Training Time: 0:12:19\nEpoch = 5, Iteration = 220/ 222  ===> Average training loss = , 0.176, Training Time: 0:12:29\nEpoch = 5 ===> training_accuracy =0.948 \nWeighted F1 Score: 0.4429\n\u001b[1mEpoch = 5 ====> Accuracy On Validation Dataset=0.498\u001b[0m\nF1 Score (Class bloomz): 0.9118\nF1 Score (Class chatGPT): 0.3415\nF1 Score (Class cohere): 0.4622\nF1 Score (Class davinci): 0.0107\nF1 Score (Class dolly): 0.5487\nF1 Score (Class human): 0.3829\n\nEpoch = 6, Iteration = 20/ 222  ===> Average training loss = , 0.170, Training Time: 0:13:28\nEpoch = 6, Iteration = 40/ 222  ===> Average training loss = , 0.151, Training Time: 0:13:38\nEpoch = 6, Iteration = 60/ 222  ===> Average training loss = , 0.139, Training Time: 0:13:48\nEpoch = 6, Iteration = 80/ 222  ===> Average training loss = , 0.129, Training Time: 0:13:58\nEpoch = 6, Iteration = 100/ 222  ===> Average training loss = , 0.118, Training Time: 0:14:08\nEpoch = 6, Iteration = 120/ 222  ===> Average training loss = , 0.110, Training Time: 0:14:18\nEpoch = 6, Iteration = 140/ 222  ===> Average training loss = , 0.104, Training Time: 0:14:28\nEpoch = 6, Iteration = 160/ 222  ===> Average training loss = , 0.105, Training Time: 0:14:38\nEpoch = 6, Iteration = 180/ 222  ===> Average training loss = , 0.105, Training Time: 0:14:48\nEpoch = 6, Iteration = 200/ 222  ===> Average training loss = , 0.109, Training Time: 0:14:58\nEpoch = 6, Iteration = 220/ 222  ===> Average training loss = , 0.108, Training Time: 0:15:08\nEpoch = 6 ===> training_accuracy =0.976 \nWeighted F1 Score: 0.5059\n\u001b[1mEpoch = 6 ====> Accuracy On Validation Dataset=0.537\u001b[0m\nF1 Score (Class bloomz): 0.9199\nF1 Score (Class chatGPT): 0.5667\nF1 Score (Class cohere): 0.4457\nF1 Score (Class davinci): 0.0520\nF1 Score (Class dolly): 0.5511\nF1 Score (Class human): 0.5000\n\nEpoch = 7, Iteration = 20/ 222  ===> Average training loss = , 0.077, Training Time: 0:16:08\nEpoch = 7, Iteration = 40/ 222  ===> Average training loss = , 0.075, Training Time: 0:16:18\nEpoch = 7, Iteration = 60/ 222  ===> Average training loss = , 0.078, Training Time: 0:16:28\nEpoch = 7, Iteration = 80/ 222  ===> Average training loss = , 0.078, Training Time: 0:16:38\nEpoch = 7, Iteration = 100/ 222  ===> Average training loss = , 0.077, Training Time: 0:16:48\nEpoch = 7, Iteration = 120/ 222  ===> Average training loss = , 0.074, Training Time: 0:16:58\nEpoch = 7, Iteration = 140/ 222  ===> Average training loss = , 0.077, Training Time: 0:17:08\nEpoch = 7, Iteration = 160/ 222  ===> Average training loss = , 0.074, Training Time: 0:17:18\nEpoch = 7, Iteration = 180/ 222  ===> Average training loss = , 0.073, Training Time: 0:17:28\nEpoch = 7, Iteration = 200/ 222  ===> Average training loss = , 0.076, Training Time: 0:17:38\nEpoch = 7, Iteration = 220/ 222  ===> Average training loss = , 0.077, Training Time: 0:17:48\nEpoch = 7 ===> training_accuracy =0.979 \nWeighted F1 Score: 0.4874\n\u001b[1mEpoch = 7 ====> Accuracy On Validation Dataset=0.501\u001b[0m\nF1 Score (Class bloomz): 0.9282\nF1 Score (Class chatGPT): 0.3519\nF1 Score (Class cohere): 0.4507\nF1 Score (Class davinci): 0.1207\nF1 Score (Class dolly): 0.4716\nF1 Score (Class human): 0.6014\n\nEpoch = 8, Iteration = 20/ 222  ===> Average training loss = , 0.060, Training Time: 0:18:47\nEpoch = 8, Iteration = 40/ 222  ===> Average training loss = , 0.050, Training Time: 0:18:57\nEpoch = 8, Iteration = 60/ 222  ===> Average training loss = , 0.054, Training Time: 0:19:07\nEpoch = 8, Iteration = 80/ 222  ===> Average training loss = , 0.051, Training Time: 0:19:17\nEpoch = 8, Iteration = 100/ 222  ===> Average training loss = , 0.054, Training Time: 0:19:27\nEpoch = 8, Iteration = 120/ 222  ===> Average training loss = , 0.061, Training Time: 0:19:37\nEpoch = 8, Iteration = 140/ 222  ===> Average training loss = , 0.063, Training Time: 0:19:47\nEpoch = 8, Iteration = 160/ 222  ===> Average training loss = , 0.068, Training Time: 0:19:57\nEpoch = 8, Iteration = 180/ 222  ===> Average training loss = , 0.065, Training Time: 0:20:07\nEpoch = 8, Iteration = 200/ 222  ===> Average training loss = , 0.062, Training Time: 0:20:17\nEpoch = 8, Iteration = 220/ 222  ===> Average training loss = , 0.061, Training Time: 0:20:28\nEpoch = 8 ===> training_accuracy =0.986 \nWeighted F1 Score: 0.4500\n\u001b[1mEpoch = 8 ====> Accuracy On Validation Dataset=0.489\u001b[0m\nF1 Score (Class bloomz): 0.9187\nF1 Score (Class chatGPT): 0.4330\nF1 Score (Class cohere): 0.4484\nF1 Score (Class davinci): 0.0224\nF1 Score (Class dolly): 0.5134\nF1 Score (Class human): 0.3639\n\nEpoch = 9, Iteration = 20/ 222  ===> Average training loss = , 0.043, Training Time: 0:21:26\nEpoch = 9, Iteration = 40/ 222  ===> Average training loss = , 0.048, Training Time: 0:21:36\nEpoch = 9, Iteration = 60/ 222  ===> Average training loss = , 0.052, Training Time: 0:21:46\nEpoch = 9, Iteration = 80/ 222  ===> Average training loss = , 0.047, Training Time: 0:21:56\nEpoch = 9, Iteration = 100/ 222  ===> Average training loss = , 0.045, Training Time: 0:22:06\nEpoch = 9, Iteration = 120/ 222  ===> Average training loss = , 0.046, Training Time: 0:22:16\nEpoch = 9, Iteration = 140/ 222  ===> Average training loss = , 0.044, Training Time: 0:22:26\nEpoch = 9, Iteration = 160/ 222  ===> Average training loss = , 0.042, Training Time: 0:22:36\nEpoch = 9, Iteration = 180/ 222  ===> Average training loss = , 0.043, Training Time: 0:22:46\nEpoch = 9, Iteration = 200/ 222  ===> Average training loss = , 0.043, Training Time: 0:22:57\nEpoch = 9, Iteration = 220/ 222  ===> Average training loss = , 0.044, Training Time: 0:23:07\nEpoch = 9 ===> training_accuracy =0.991 \nWeighted F1 Score: 0.5087\n\u001b[1mEpoch = 9 ====> Accuracy On Validation Dataset=0.539\u001b[0m\nF1 Score (Class bloomz): 0.9040\nF1 Score (Class chatGPT): 0.4776\nF1 Score (Class cohere): 0.4656\nF1 Score (Class davinci): 0.0426\nF1 Score (Class dolly): 0.5473\nF1 Score (Class human): 0.6154\n\nEpoch = 10, Iteration = 20/ 222  ===> Average training loss = , 0.054, Training Time: 0:24:06\nEpoch = 10, Iteration = 40/ 222  ===> Average training loss = , 0.041, Training Time: 0:24:16\nEpoch = 10, Iteration = 60/ 222  ===> Average training loss = , 0.033, Training Time: 0:24:26\nEpoch = 10, Iteration = 80/ 222  ===> Average training loss = , 0.031, Training Time: 0:24:36\nEpoch = 10, Iteration = 100/ 222  ===> Average training loss = , 0.029, Training Time: 0:24:46\nEpoch = 10, Iteration = 120/ 222  ===> Average training loss = , 0.028, Training Time: 0:24:57\nEpoch = 10, Iteration = 140/ 222  ===> Average training loss = , 0.028, Training Time: 0:25:07\nEpoch = 10, Iteration = 160/ 222  ===> Average training loss = , 0.027, Training Time: 0:25:17\nEpoch = 10, Iteration = 180/ 222  ===> Average training loss = , 0.027, Training Time: 0:25:27\nEpoch = 10, Iteration = 200/ 222  ===> Average training loss = , 0.029, Training Time: 0:25:37\nEpoch = 10, Iteration = 220/ 222  ===> Average training loss = , 0.028, Training Time: 0:25:47\nEpoch = 10 ===> training_accuracy =0.995 \nWeighted F1 Score: 0.4913\n\u001b[1mEpoch = 10 ====> Accuracy On Validation Dataset=0.519\u001b[0m\nF1 Score (Class bloomz): 0.9098\nF1 Score (Class chatGPT): 0.5166\nF1 Score (Class cohere): 0.4575\nF1 Score (Class davinci): 0.0449\nF1 Score (Class dolly): 0.5476\nF1 Score (Class human): 0.4714\n\n################################################################################\n\u001b[1m Percentage of training data = 10.0 % \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch = 1, Iteration = 30/ 444  ===> Average training loss = , 1.858, Training Time: 0:00:15\nEpoch = 1, Iteration = 60/ 444  ===> Average training loss = , 1.783, Training Time: 0:00:30\nEpoch = 1, Iteration = 90/ 444  ===> Average training loss = , 1.730, Training Time: 0:00:45\nEpoch = 1, Iteration = 120/ 444  ===> Average training loss = , 1.686, Training Time: 0:01:00\nEpoch = 1, Iteration = 150/ 444  ===> Average training loss = , 1.642, Training Time: 0:01:15\nEpoch = 1, Iteration = 180/ 444  ===> Average training loss = , 1.592, Training Time: 0:01:30\nEpoch = 1, Iteration = 210/ 444  ===> Average training loss = , 1.538, Training Time: 0:01:46\nEpoch = 1, Iteration = 240/ 444  ===> Average training loss = , 1.491, Training Time: 0:02:01\nEpoch = 1, Iteration = 270/ 444  ===> Average training loss = , 1.442, Training Time: 0:02:16\nEpoch = 1, Iteration = 300/ 444  ===> Average training loss = , 1.399, Training Time: 0:02:31\nEpoch = 1, Iteration = 330/ 444  ===> Average training loss = , 1.363, Training Time: 0:02:46\nEpoch = 1, Iteration = 360/ 444  ===> Average training loss = , 1.324, Training Time: 0:03:01\nEpoch = 1, Iteration = 390/ 444  ===> Average training loss = , 1.288, Training Time: 0:03:16\nEpoch = 1, Iteration = 420/ 444  ===> Average training loss = , 1.254, Training Time: 0:03:31\nEpoch = 1 ===> training_accuracy =0.522 \nWeighted F1 Score: 0.4835\n\u001b[1mEpoch = 1 ====> Accuracy On Validation Dataset=0.512\u001b[0m\nF1 Score (Class bloomz): 0.9363\nF1 Score (Class chatGPT): 0.4627\nF1 Score (Class cohere): 0.4287\nF1 Score (Class davinci): 0.0000\nF1 Score (Class dolly): 0.4436\nF1 Score (Class human): 0.6297\n\nEpoch = 2, Iteration = 30/ 444  ===> Average training loss = , 0.751, Training Time: 0:04:46\nEpoch = 2, Iteration = 60/ 444  ===> Average training loss = , 0.702, Training Time: 0:05:01\nEpoch = 2, Iteration = 90/ 444  ===> Average training loss = , 0.686, Training Time: 0:05:16\nEpoch = 2, Iteration = 120/ 444  ===> Average training loss = , 0.670, Training Time: 0:05:31\nEpoch = 2, Iteration = 150/ 444  ===> Average training loss = , 0.657, Training Time: 0:05:46\nEpoch = 2, Iteration = 180/ 444  ===> Average training loss = , 0.639, Training Time: 0:06:01\nEpoch = 2, Iteration = 210/ 444  ===> Average training loss = , 0.630, Training Time: 0:06:16\nEpoch = 2, Iteration = 240/ 444  ===> Average training loss = , 0.630, Training Time: 0:06:31\nEpoch = 2, Iteration = 270/ 444  ===> Average training loss = , 0.630, Training Time: 0:06:46\nEpoch = 2, Iteration = 300/ 444  ===> Average training loss = , 0.629, Training Time: 0:07:01\nEpoch = 2, Iteration = 330/ 444  ===> Average training loss = , 0.623, Training Time: 0:07:17\nEpoch = 2, Iteration = 360/ 444  ===> Average training loss = , 0.609, Training Time: 0:07:32\nEpoch = 2, Iteration = 390/ 444  ===> Average training loss = , 0.608, Training Time: 0:07:47\nEpoch = 2, Iteration = 420/ 444  ===> Average training loss = , 0.606, Training Time: 0:08:02\nEpoch = 2 ===> training_accuracy =0.785 \nWeighted F1 Score: 0.5093\n\u001b[1mEpoch = 2 ====> Accuracy On Validation Dataset=0.522\u001b[0m\nF1 Score (Class bloomz): 0.9515\nF1 Score (Class chatGPT): 0.3634\nF1 Score (Class cohere): 0.4558\nF1 Score (Class davinci): 0.0737\nF1 Score (Class dolly): 0.5773\nF1 Score (Class human): 0.6341\n\nEpoch = 3, Iteration = 30/ 444  ===> Average training loss = , 0.432, Training Time: 0:09:16\nEpoch = 3, Iteration = 60/ 444  ===> Average training loss = , 0.396, Training Time: 0:09:31\nEpoch = 3, Iteration = 90/ 444  ===> Average training loss = , 0.379, Training Time: 0:09:46\nEpoch = 3, Iteration = 120/ 444  ===> Average training loss = , 0.368, Training Time: 0:10:02\nEpoch = 3, Iteration = 150/ 444  ===> Average training loss = , 0.354, Training Time: 0:10:17\nEpoch = 3, Iteration = 180/ 444  ===> Average training loss = , 0.352, Training Time: 0:10:32\nEpoch = 3, Iteration = 210/ 444  ===> Average training loss = , 0.349, Training Time: 0:10:47\nEpoch = 3, Iteration = 240/ 444  ===> Average training loss = , 0.357, Training Time: 0:11:02\nEpoch = 3, Iteration = 270/ 444  ===> Average training loss = , 0.351, Training Time: 0:11:17\nEpoch = 3, Iteration = 300/ 444  ===> Average training loss = , 0.348, Training Time: 0:11:32\nEpoch = 3, Iteration = 330/ 444  ===> Average training loss = , 0.343, Training Time: 0:11:47\nEpoch = 3, Iteration = 360/ 444  ===> Average training loss = , 0.340, Training Time: 0:12:02\nEpoch = 3, Iteration = 390/ 444  ===> Average training loss = , 0.339, Training Time: 0:12:17\nEpoch = 3, Iteration = 420/ 444  ===> Average training loss = , 0.338, Training Time: 0:12:32\nEpoch = 3 ===> training_accuracy =0.881 \nWeighted F1 Score: 0.3748\n\u001b[1mEpoch = 3 ====> Accuracy On Validation Dataset=0.432\u001b[0m\nF1 Score (Class bloomz): 0.9659\nF1 Score (Class chatGPT): 0.1531\nF1 Score (Class cohere): 0.4202\nF1 Score (Class davinci): 0.0034\nF1 Score (Class dolly): 0.4257\nF1 Score (Class human): 0.2803\n\nEpoch = 4, Iteration = 30/ 444  ===> Average training loss = , 0.188, Training Time: 0:13:47\nEpoch = 4, Iteration = 60/ 444  ===> Average training loss = , 0.184, Training Time: 0:14:02\nEpoch = 4, Iteration = 90/ 444  ===> Average training loss = , 0.178, Training Time: 0:14:17\nEpoch = 4, Iteration = 120/ 444  ===> Average training loss = , 0.178, Training Time: 0:14:32\nEpoch = 4, Iteration = 150/ 444  ===> Average training loss = , 0.188, Training Time: 0:14:47\nEpoch = 4, Iteration = 180/ 444  ===> Average training loss = , 0.189, Training Time: 0:15:02\nEpoch = 4, Iteration = 210/ 444  ===> Average training loss = , 0.198, Training Time: 0:15:17\nEpoch = 4, Iteration = 240/ 444  ===> Average training loss = , 0.198, Training Time: 0:15:33\nEpoch = 4, Iteration = 270/ 444  ===> Average training loss = , 0.201, Training Time: 0:15:48\nEpoch = 4, Iteration = 300/ 444  ===> Average training loss = , 0.196, Training Time: 0:16:03\nEpoch = 4, Iteration = 330/ 444  ===> Average training loss = , 0.198, Training Time: 0:16:18\nEpoch = 4, Iteration = 360/ 444  ===> Average training loss = , 0.200, Training Time: 0:16:33\nEpoch = 4, Iteration = 390/ 444  ===> Average training loss = , 0.204, Training Time: 0:16:48\nEpoch = 4, Iteration = 420/ 444  ===> Average training loss = , 0.203, Training Time: 0:17:03\nEpoch = 4 ===> training_accuracy =0.932 \nWeighted F1 Score: 0.4401\n\u001b[1mEpoch = 4 ====> Accuracy On Validation Dataset=0.482\u001b[0m\nF1 Score (Class bloomz): 0.9671\nF1 Score (Class chatGPT): 0.3419\nF1 Score (Class cohere): 0.4517\nF1 Score (Class davinci): 0.0120\nF1 Score (Class dolly): 0.5466\nF1 Score (Class human): 0.3212\n\nEpoch = 5, Iteration = 30/ 444  ===> Average training loss = , 0.101, Training Time: 0:18:18\nEpoch = 5, Iteration = 60/ 444  ===> Average training loss = , 0.108, Training Time: 0:18:33\nEpoch = 5, Iteration = 90/ 444  ===> Average training loss = , 0.108, Training Time: 0:18:48\nEpoch = 5, Iteration = 120/ 444  ===> Average training loss = , 0.102, Training Time: 0:19:03\nEpoch = 5, Iteration = 150/ 444  ===> Average training loss = , 0.104, Training Time: 0:19:18\nEpoch = 5, Iteration = 180/ 444  ===> Average training loss = , 0.102, Training Time: 0:19:33\nEpoch = 5, Iteration = 210/ 444  ===> Average training loss = , 0.097, Training Time: 0:19:48\nEpoch = 5, Iteration = 240/ 444  ===> Average training loss = , 0.093, Training Time: 0:20:03\nEpoch = 5, Iteration = 270/ 444  ===> Average training loss = , 0.094, Training Time: 0:20:18\nEpoch = 5, Iteration = 300/ 444  ===> Average training loss = , 0.094, Training Time: 0:20:33\nEpoch = 5, Iteration = 330/ 444  ===> Average training loss = , 0.094, Training Time: 0:20:48\nEpoch = 5, Iteration = 360/ 444  ===> Average training loss = , 0.094, Training Time: 0:21:03\nEpoch = 5, Iteration = 390/ 444  ===> Average training loss = , 0.095, Training Time: 0:21:18\nEpoch = 5, Iteration = 420/ 444  ===> Average training loss = , 0.096, Training Time: 0:21:34\nEpoch = 5 ===> training_accuracy =0.973 \nWeighted F1 Score: 0.5612\n\u001b[1mEpoch = 5 ====> Accuracy On Validation Dataset=0.575\u001b[0m\nF1 Score (Class bloomz): 0.9551\nF1 Score (Class chatGPT): 0.5559\nF1 Score (Class cohere): 0.4593\nF1 Score (Class davinci): 0.0793\nF1 Score (Class dolly): 0.6184\nF1 Score (Class human): 0.6990\n\nEpoch = 6, Iteration = 30/ 444  ===> Average training loss = , 0.056, Training Time: 0:22:50\nEpoch = 6, Iteration = 60/ 444  ===> Average training loss = , 0.053, Training Time: 0:23:05\nEpoch = 6, Iteration = 90/ 444  ===> Average training loss = , 0.073, Training Time: 0:23:20\nEpoch = 6, Iteration = 120/ 444  ===> Average training loss = , 0.070, Training Time: 0:23:35\nEpoch = 6, Iteration = 150/ 444  ===> Average training loss = , 0.069, Training Time: 0:23:51\nEpoch = 6, Iteration = 180/ 444  ===> Average training loss = , 0.069, Training Time: 0:24:06\nEpoch = 6, Iteration = 210/ 444  ===> Average training loss = , 0.066, Training Time: 0:24:21\nEpoch = 6, Iteration = 240/ 444  ===> Average training loss = , 0.066, Training Time: 0:24:36\nEpoch = 6, Iteration = 270/ 444  ===> Average training loss = , 0.063, Training Time: 0:24:51\nEpoch = 6, Iteration = 300/ 444  ===> Average training loss = , 0.063, Training Time: 0:25:06\nEpoch = 6, Iteration = 330/ 444  ===> Average training loss = , 0.072, Training Time: 0:25:21\nEpoch = 6, Iteration = 360/ 444  ===> Average training loss = , 0.074, Training Time: 0:25:36\nEpoch = 6, Iteration = 390/ 444  ===> Average training loss = , 0.073, Training Time: 0:25:51\nEpoch = 6, Iteration = 420/ 444  ===> Average training loss = , 0.072, Training Time: 0:26:06\nEpoch = 6 ===> training_accuracy =0.979 \nWeighted F1 Score: 0.5037\n\u001b[1mEpoch = 6 ====> Accuracy On Validation Dataset=0.525\u001b[0m\nF1 Score (Class bloomz): 0.9643\nF1 Score (Class chatGPT): 0.4098\nF1 Score (Class cohere): 0.4494\nF1 Score (Class davinci): 0.0233\nF1 Score (Class dolly): 0.5709\nF1 Score (Class human): 0.6045\n\nEpoch = 7, Iteration = 30/ 444  ===> Average training loss = , 0.057, Training Time: 0:27:20\nEpoch = 7, Iteration = 60/ 444  ===> Average training loss = , 0.067, Training Time: 0:27:36\nEpoch = 7, Iteration = 90/ 444  ===> Average training loss = , 0.062, Training Time: 0:27:51\nEpoch = 7, Iteration = 120/ 444  ===> Average training loss = , 0.058, Training Time: 0:28:06\nEpoch = 7, Iteration = 150/ 444  ===> Average training loss = , 0.053, Training Time: 0:28:21\nEpoch = 7, Iteration = 180/ 444  ===> Average training loss = , 0.053, Training Time: 0:28:36\nEpoch = 7, Iteration = 210/ 444  ===> Average training loss = , 0.056, Training Time: 0:28:51\nEpoch = 7, Iteration = 240/ 444  ===> Average training loss = , 0.059, Training Time: 0:29:06\nEpoch = 7, Iteration = 270/ 444  ===> Average training loss = , 0.060, Training Time: 0:29:21\nEpoch = 7, Iteration = 300/ 444  ===> Average training loss = , 0.056, Training Time: 0:29:36\nEpoch = 7, Iteration = 330/ 444  ===> Average training loss = , 0.056, Training Time: 0:29:51\nEpoch = 7, Iteration = 360/ 444  ===> Average training loss = , 0.057, Training Time: 0:30:06\nEpoch = 7, Iteration = 390/ 444  ===> Average training loss = , 0.058, Training Time: 0:30:21\nEpoch = 7, Iteration = 420/ 444  ===> Average training loss = , 0.056, Training Time: 0:30:36\nEpoch = 7 ===> training_accuracy =0.984 \nWeighted F1 Score: 0.4988\n\u001b[1mEpoch = 7 ====> Accuracy On Validation Dataset=0.527\u001b[0m\nF1 Score (Class bloomz): 0.9696\nF1 Score (Class chatGPT): 0.2204\nF1 Score (Class cohere): 0.4340\nF1 Score (Class davinci): 0.0964\nF1 Score (Class dolly): 0.6189\nF1 Score (Class human): 0.6537\n\nEpoch = 8, Iteration = 30/ 444  ===> Average training loss = , 0.042, Training Time: 0:31:51\nEpoch = 8, Iteration = 60/ 444  ===> Average training loss = , 0.040, Training Time: 0:32:06\nEpoch = 8, Iteration = 90/ 444  ===> Average training loss = , 0.032, Training Time: 0:32:21\nEpoch = 8, Iteration = 120/ 444  ===> Average training loss = , 0.031, Training Time: 0:32:36\nEpoch = 8, Iteration = 150/ 444  ===> Average training loss = , 0.032, Training Time: 0:32:51\nEpoch = 8, Iteration = 180/ 444  ===> Average training loss = , 0.034, Training Time: 0:33:06\nEpoch = 8, Iteration = 210/ 444  ===> Average training loss = , 0.032, Training Time: 0:33:21\nEpoch = 8, Iteration = 240/ 444  ===> Average training loss = , 0.032, Training Time: 0:33:36\nEpoch = 8, Iteration = 270/ 444  ===> Average training loss = , 0.038, Training Time: 0:33:51\nEpoch = 8, Iteration = 300/ 444  ===> Average training loss = , 0.038, Training Time: 0:34:06\nEpoch = 8, Iteration = 330/ 444  ===> Average training loss = , 0.038, Training Time: 0:34:21\nEpoch = 8, Iteration = 360/ 444  ===> Average training loss = , 0.039, Training Time: 0:34:37\nEpoch = 8, Iteration = 390/ 444  ===> Average training loss = , 0.040, Training Time: 0:34:52\nEpoch = 8, Iteration = 420/ 444  ===> Average training loss = , 0.041, Training Time: 0:35:07\nEpoch = 8 ===> training_accuracy =0.987 \nWeighted F1 Score: 0.4630\n\u001b[1mEpoch = 8 ====> Accuracy On Validation Dataset=0.508\u001b[0m\nF1 Score (Class bloomz): 0.9643\nF1 Score (Class chatGPT): 0.1544\nF1 Score (Class cohere): 0.4156\nF1 Score (Class davinci): 0.0642\nF1 Score (Class dolly): 0.4597\nF1 Score (Class human): 0.7201\n\nEpoch = 9, Iteration = 30/ 444  ===> Average training loss = , 0.086, Training Time: 0:36:21\nEpoch = 9, Iteration = 60/ 444  ===> Average training loss = , 0.067, Training Time: 0:36:36\nEpoch = 9, Iteration = 90/ 444  ===> Average training loss = , 0.071, Training Time: 0:36:51\nEpoch = 9, Iteration = 120/ 444  ===> Average training loss = , 0.093, Training Time: 0:37:06\nEpoch = 9, Iteration = 150/ 444  ===> Average training loss = , 0.085, Training Time: 0:37:21\nEpoch = 9, Iteration = 180/ 444  ===> Average training loss = , 0.087, Training Time: 0:37:37\nEpoch = 9, Iteration = 210/ 444  ===> Average training loss = , 0.082, Training Time: 0:37:52\nEpoch = 9, Iteration = 240/ 444  ===> Average training loss = , 0.075, Training Time: 0:38:07\nEpoch = 9, Iteration = 270/ 444  ===> Average training loss = , 0.070, Training Time: 0:38:22\nEpoch = 9, Iteration = 300/ 444  ===> Average training loss = , 0.065, Training Time: 0:38:37\nEpoch = 9, Iteration = 330/ 444  ===> Average training loss = , 0.062, Training Time: 0:38:52\nEpoch = 9, Iteration = 360/ 444  ===> Average training loss = , 0.060, Training Time: 0:39:07\nEpoch = 9, Iteration = 390/ 444  ===> Average training loss = , 0.058, Training Time: 0:39:22\nEpoch = 9, Iteration = 420/ 444  ===> Average training loss = , 0.059, Training Time: 0:39:37\nEpoch = 9 ===> training_accuracy =0.979 \nWeighted F1 Score: 0.4621\n\u001b[1mEpoch = 9 ====> Accuracy On Validation Dataset=0.504\u001b[0m\nF1 Score (Class bloomz): 0.9579\nF1 Score (Class chatGPT): 0.1667\nF1 Score (Class cohere): 0.4245\nF1 Score (Class davinci): 0.0613\nF1 Score (Class dolly): 0.4987\nF1 Score (Class human): 0.6635\n\nEpoch = 10, Iteration = 30/ 444  ===> Average training loss = , 0.031, Training Time: 0:40:52\nEpoch = 10, Iteration = 60/ 444  ===> Average training loss = , 0.021, Training Time: 0:41:07\nEpoch = 10, Iteration = 90/ 444  ===> Average training loss = , 0.029, Training Time: 0:41:22\nEpoch = 10, Iteration = 120/ 444  ===> Average training loss = , 0.025, Training Time: 0:41:37\nEpoch = 10, Iteration = 150/ 444  ===> Average training loss = , 0.025, Training Time: 0:41:52\nEpoch = 10, Iteration = 180/ 444  ===> Average training loss = , 0.025, Training Time: 0:42:07\nEpoch = 10, Iteration = 210/ 444  ===> Average training loss = , 0.026, Training Time: 0:42:22\nEpoch = 10, Iteration = 240/ 444  ===> Average training loss = , 0.027, Training Time: 0:42:38\nEpoch = 10, Iteration = 270/ 444  ===> Average training loss = , 0.028, Training Time: 0:42:53\nEpoch = 10, Iteration = 300/ 444  ===> Average training loss = , 0.027, Training Time: 0:43:08\nEpoch = 10, Iteration = 330/ 444  ===> Average training loss = , 0.029, Training Time: 0:43:23\nEpoch = 10, Iteration = 360/ 444  ===> Average training loss = , 0.029, Training Time: 0:43:38\nEpoch = 10, Iteration = 390/ 444  ===> Average training loss = , 0.031, Training Time: 0:43:53\nEpoch = 10, Iteration = 420/ 444  ===> Average training loss = , 0.031, Training Time: 0:44:08\nEpoch = 10 ===> training_accuracy =0.992 \nWeighted F1 Score: 0.4835\n\u001b[1mEpoch = 10 ====> Accuracy On Validation Dataset=0.508\u001b[0m\nF1 Score (Class bloomz): 0.9434\nF1 Score (Class chatGPT): 0.3961\nF1 Score (Class cohere): 0.4397\nF1 Score (Class davinci): 0.0726\nF1 Score (Class dolly): 0.5858\nF1 Score (Class human): 0.4632\n\n################################################################################\n\u001b[1m Percentage of training data = 50.0 % \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch = 1, Iteration = 40/ 2220  ===> Average training loss = , 1.829, Training Time: 0:00:20\nEpoch = 1, Iteration = 80/ 2220  ===> Average training loss = , 1.785, Training Time: 0:00:40\nEpoch = 1, Iteration = 120/ 2220  ===> Average training loss = , 1.717, Training Time: 0:01:00\nEpoch = 1, Iteration = 160/ 2220  ===> Average training loss = , 1.640, Training Time: 0:01:20\nEpoch = 1, Iteration = 200/ 2220  ===> Average training loss = , 1.558, Training Time: 0:01:40\nEpoch = 1, Iteration = 240/ 2220  ===> Average training loss = , 1.483, Training Time: 0:02:01\nEpoch = 1, Iteration = 280/ 2220  ===> Average training loss = , 1.417, Training Time: 0:02:21\nEpoch = 1, Iteration = 320/ 2220  ===> Average training loss = , 1.367, Training Time: 0:02:41\nEpoch = 1, Iteration = 360/ 2220  ===> Average training loss = , 1.311, Training Time: 0:03:01\nEpoch = 1, Iteration = 400/ 2220  ===> Average training loss = , 1.257, Training Time: 0:03:21\nEpoch = 1, Iteration = 440/ 2220  ===> Average training loss = , 1.215, Training Time: 0:03:41\nEpoch = 1, Iteration = 480/ 2220  ===> Average training loss = , 1.177, Training Time: 0:04:01\nEpoch = 1, Iteration = 520/ 2220  ===> Average training loss = , 1.140, Training Time: 0:04:21\nEpoch = 1, Iteration = 560/ 2220  ===> Average training loss = , 1.105, Training Time: 0:04:41\nEpoch = 1, Iteration = 600/ 2220  ===> Average training loss = , 1.076, Training Time: 0:05:01\nEpoch = 1, Iteration = 640/ 2220  ===> Average training loss = , 1.048, Training Time: 0:05:22\nEpoch = 1, Iteration = 680/ 2220  ===> Average training loss = , 1.024, Training Time: 0:05:42\nEpoch = 1, Iteration = 720/ 2220  ===> Average training loss = , 1.003, Training Time: 0:06:02\nEpoch = 1, Iteration = 760/ 2220  ===> Average training loss = , 0.982, Training Time: 0:06:22\nEpoch = 1, Iteration = 800/ 2220  ===> Average training loss = , 0.963, Training Time: 0:06:42\nEpoch = 1, Iteration = 840/ 2220  ===> Average training loss = , 0.942, Training Time: 0:07:02\nEpoch = 1, Iteration = 880/ 2220  ===> Average training loss = , 0.926, Training Time: 0:07:22\nEpoch = 1, Iteration = 920/ 2220  ===> Average training loss = , 0.909, Training Time: 0:07:42\nEpoch = 1, Iteration = 960/ 2220  ===> Average training loss = , 0.895, Training Time: 0:08:02\nEpoch = 1, Iteration = 1000/ 2220  ===> Average training loss = , 0.881, Training Time: 0:08:22\nEpoch = 1, Iteration = 1040/ 2220  ===> Average training loss = , 0.865, Training Time: 0:08:42\nEpoch = 1, Iteration = 1080/ 2220  ===> Average training loss = , 0.850, Training Time: 0:09:02\nEpoch = 1, Iteration = 1120/ 2220  ===> Average training loss = , 0.838, Training Time: 0:09:23\nEpoch = 1, Iteration = 1160/ 2220  ===> Average training loss = , 0.827, Training Time: 0:09:43\nEpoch = 1, Iteration = 1200/ 2220  ===> Average training loss = , 0.816, Training Time: 0:10:03\nEpoch = 1, Iteration = 1240/ 2220  ===> Average training loss = , 0.805, Training Time: 0:10:23\nEpoch = 1, Iteration = 1280/ 2220  ===> Average training loss = , 0.794, Training Time: 0:10:43\nEpoch = 1, Iteration = 1320/ 2220  ===> Average training loss = , 0.784, Training Time: 0:11:03\nEpoch = 1, Iteration = 1360/ 2220  ===> Average training loss = , 0.775, Training Time: 0:11:23\nEpoch = 1, Iteration = 1400/ 2220  ===> Average training loss = , 0.765, Training Time: 0:11:43\nEpoch = 1, Iteration = 1440/ 2220  ===> Average training loss = , 0.756, Training Time: 0:12:03\nEpoch = 1, Iteration = 1480/ 2220  ===> Average training loss = , 0.747, Training Time: 0:12:23\nEpoch = 1, Iteration = 1520/ 2220  ===> Average training loss = , 0.739, Training Time: 0:12:43\nEpoch = 1, Iteration = 1560/ 2220  ===> Average training loss = , 0.730, Training Time: 0:13:03\nEpoch = 1, Iteration = 1600/ 2220  ===> Average training loss = , 0.722, Training Time: 0:13:23\nEpoch = 1, Iteration = 1640/ 2220  ===> Average training loss = , 0.715, Training Time: 0:13:44\nEpoch = 1, Iteration = 1680/ 2220  ===> Average training loss = , 0.710, Training Time: 0:14:04\nEpoch = 1, Iteration = 1720/ 2220  ===> Average training loss = , 0.703, Training Time: 0:14:24\nEpoch = 1, Iteration = 1760/ 2220  ===> Average training loss = , 0.698, Training Time: 0:14:44\nEpoch = 1, Iteration = 1800/ 2220  ===> Average training loss = , 0.690, Training Time: 0:15:04\nEpoch = 1, Iteration = 1840/ 2220  ===> Average training loss = , 0.683, Training Time: 0:15:24\nEpoch = 1, Iteration = 1880/ 2220  ===> Average training loss = , 0.676, Training Time: 0:15:44\nEpoch = 1, Iteration = 1920/ 2220  ===> Average training loss = , 0.670, Training Time: 0:16:04\nEpoch = 1, Iteration = 1960/ 2220  ===> Average training loss = , 0.664, Training Time: 0:16:24\nEpoch = 1, Iteration = 2000/ 2220  ===> Average training loss = , 0.659, Training Time: 0:16:44\nEpoch = 1, Iteration = 2040/ 2220  ===> Average training loss = , 0.653, Training Time: 0:17:05\nEpoch = 1, Iteration = 2080/ 2220  ===> Average training loss = , 0.647, Training Time: 0:17:25\nEpoch = 1, Iteration = 2120/ 2220  ===> Average training loss = , 0.642, Training Time: 0:17:45\nEpoch = 1, Iteration = 2160/ 2220  ===> Average training loss = , 0.637, Training Time: 0:18:05\nEpoch = 1, Iteration = 2200/ 2220  ===> Average training loss = , 0.632, Training Time: 0:18:25\nEpoch = 1 ===> training_accuracy =0.765 \nWeighted F1 Score: 0.4960\n\u001b[1mEpoch = 1 ====> Accuracy On Validation Dataset=0.545\u001b[0m\nF1 Score (Class bloomz): 0.8881\nF1 Score (Class chatGPT): 0.3820\nF1 Score (Class cohere): 0.4686\nF1 Score (Class davinci): 0.0036\nF1 Score (Class dolly): 0.5753\nF1 Score (Class human): 0.6581\n\nEpoch = 2, Iteration = 40/ 2220  ===> Average training loss = , 0.294, Training Time: 0:19:43\nEpoch = 2, Iteration = 80/ 2220  ===> Average training loss = , 0.288, Training Time: 0:20:03\nEpoch = 2, Iteration = 120/ 2220  ===> Average training loss = , 0.283, Training Time: 0:20:23\nEpoch = 2, Iteration = 160/ 2220  ===> Average training loss = , 0.272, Training Time: 0:20:43\nEpoch = 2, Iteration = 200/ 2220  ===> Average training loss = , 0.271, Training Time: 0:21:03\nEpoch = 2, Iteration = 240/ 2220  ===> Average training loss = , 0.266, Training Time: 0:21:23\nEpoch = 2, Iteration = 280/ 2220  ===> Average training loss = , 0.266, Training Time: 0:21:43\nEpoch = 2, Iteration = 320/ 2220  ===> Average training loss = , 0.271, Training Time: 0:22:03\nEpoch = 2, Iteration = 360/ 2220  ===> Average training loss = , 0.272, Training Time: 0:22:24\nEpoch = 2, Iteration = 400/ 2220  ===> Average training loss = , 0.272, Training Time: 0:22:44\nEpoch = 2, Iteration = 440/ 2220  ===> Average training loss = , 0.273, Training Time: 0:23:04\nEpoch = 2, Iteration = 480/ 2220  ===> Average training loss = , 0.273, Training Time: 0:23:24\nEpoch = 2, Iteration = 520/ 2220  ===> Average training loss = , 0.272, Training Time: 0:23:44\nEpoch = 2, Iteration = 560/ 2220  ===> Average training loss = , 0.269, Training Time: 0:24:04\nEpoch = 2, Iteration = 600/ 2220  ===> Average training loss = , 0.268, Training Time: 0:24:24\nEpoch = 2, Iteration = 640/ 2220  ===> Average training loss = , 0.267, Training Time: 0:24:44\nEpoch = 2, Iteration = 680/ 2220  ===> Average training loss = , 0.267, Training Time: 0:25:05\nEpoch = 2, Iteration = 720/ 2220  ===> Average training loss = , 0.267, Training Time: 0:25:25\nEpoch = 2, Iteration = 760/ 2220  ===> Average training loss = , 0.268, Training Time: 0:25:45\nEpoch = 2, Iteration = 800/ 2220  ===> Average training loss = , 0.269, Training Time: 0:26:05\nEpoch = 2, Iteration = 840/ 2220  ===> Average training loss = , 0.270, Training Time: 0:26:25\nEpoch = 2, Iteration = 880/ 2220  ===> Average training loss = , 0.271, Training Time: 0:26:45\nEpoch = 2, Iteration = 920/ 2220  ===> Average training loss = , 0.276, Training Time: 0:27:05\nEpoch = 2, Iteration = 960/ 2220  ===> Average training loss = , 0.276, Training Time: 0:27:25\nEpoch = 2, Iteration = 1000/ 2220  ===> Average training loss = , 0.275, Training Time: 0:27:46\nEpoch = 2, Iteration = 1040/ 2220  ===> Average training loss = , 0.275, Training Time: 0:28:06\nEpoch = 2, Iteration = 1080/ 2220  ===> Average training loss = , 0.276, Training Time: 0:28:26\nEpoch = 2, Iteration = 1120/ 2220  ===> Average training loss = , 0.275, Training Time: 0:28:46\nEpoch = 2, Iteration = 1160/ 2220  ===> Average training loss = , 0.274, Training Time: 0:29:06\nEpoch = 2, Iteration = 1200/ 2220  ===> Average training loss = , 0.273, Training Time: 0:29:26\nEpoch = 2, Iteration = 1240/ 2220  ===> Average training loss = , 0.272, Training Time: 0:29:46\nEpoch = 2, Iteration = 1280/ 2220  ===> Average training loss = , 0.271, Training Time: 0:30:06\nEpoch = 2, Iteration = 1320/ 2220  ===> Average training loss = , 0.268, Training Time: 0:30:26\nEpoch = 2, Iteration = 1360/ 2220  ===> Average training loss = , 0.268, Training Time: 0:30:46\nEpoch = 2, Iteration = 1400/ 2220  ===> Average training loss = , 0.268, Training Time: 0:31:07\nEpoch = 2, Iteration = 1440/ 2220  ===> Average training loss = , 0.267, Training Time: 0:31:27\nEpoch = 2, Iteration = 1480/ 2220  ===> Average training loss = , 0.266, Training Time: 0:31:47\nEpoch = 2, Iteration = 1520/ 2220  ===> Average training loss = , 0.265, Training Time: 0:32:07\nEpoch = 2, Iteration = 1560/ 2220  ===> Average training loss = , 0.266, Training Time: 0:32:27\nEpoch = 2, Iteration = 1600/ 2220  ===> Average training loss = , 0.266, Training Time: 0:32:47\nEpoch = 2, Iteration = 1640/ 2220  ===> Average training loss = , 0.264, Training Time: 0:33:07\nEpoch = 2, Iteration = 1680/ 2220  ===> Average training loss = , 0.264, Training Time: 0:33:27\nEpoch = 2, Iteration = 1720/ 2220  ===> Average training loss = , 0.263, Training Time: 0:33:47\nEpoch = 2, Iteration = 1760/ 2220  ===> Average training loss = , 0.261, Training Time: 0:34:07\nEpoch = 2, Iteration = 1800/ 2220  ===> Average training loss = , 0.260, Training Time: 0:34:28\nEpoch = 2, Iteration = 1840/ 2220  ===> Average training loss = , 0.260, Training Time: 0:34:48\nEpoch = 2, Iteration = 1880/ 2220  ===> Average training loss = , 0.260, Training Time: 0:35:08\nEpoch = 2, Iteration = 1920/ 2220  ===> Average training loss = , 0.260, Training Time: 0:35:28\nEpoch = 2, Iteration = 1960/ 2220  ===> Average training loss = , 0.259, Training Time: 0:35:48\nEpoch = 2, Iteration = 2000/ 2220  ===> Average training loss = , 0.259, Training Time: 0:36:08\nEpoch = 2, Iteration = 2040/ 2220  ===> Average training loss = , 0.259, Training Time: 0:36:28\nEpoch = 2, Iteration = 2080/ 2220  ===> Average training loss = , 0.259, Training Time: 0:36:48\nEpoch = 2, Iteration = 2120/ 2220  ===> Average training loss = , 0.261, Training Time: 0:37:08\nEpoch = 2, Iteration = 2160/ 2220  ===> Average training loss = , 0.260, Training Time: 0:37:29\nEpoch = 2, Iteration = 2200/ 2220  ===> Average training loss = , 0.261, Training Time: 0:37:49\nEpoch = 2 ===> training_accuracy =0.907 \nWeighted F1 Score: 0.4749\n\u001b[1mEpoch = 2 ====> Accuracy On Validation Dataset=0.523\u001b[0m\nF1 Score (Class bloomz): 0.9578\nF1 Score (Class chatGPT): 0.2651\nF1 Score (Class cohere): 0.4433\nF1 Score (Class davinci): 0.0037\nF1 Score (Class dolly): 0.6172\nF1 Score (Class human): 0.5626\n\nEpoch = 3, Iteration = 40/ 2220  ===> Average training loss = , 0.154, Training Time: 0:39:06\nEpoch = 3, Iteration = 80/ 2220  ===> Average training loss = , 0.153, Training Time: 0:39:27\nEpoch = 3, Iteration = 120/ 2220  ===> Average training loss = , 0.150, Training Time: 0:39:47\nEpoch = 3, Iteration = 160/ 2220  ===> Average training loss = , 0.141, Training Time: 0:40:07\nEpoch = 3, Iteration = 200/ 2220  ===> Average training loss = , 0.139, Training Time: 0:40:27\nEpoch = 3, Iteration = 240/ 2220  ===> Average training loss = , 0.134, Training Time: 0:40:47\nEpoch = 3, Iteration = 280/ 2220  ===> Average training loss = , 0.133, Training Time: 0:41:07\nEpoch = 3, Iteration = 320/ 2220  ===> Average training loss = , 0.133, Training Time: 0:41:27\nEpoch = 3, Iteration = 360/ 2220  ===> Average training loss = , 0.136, Training Time: 0:41:48\nEpoch = 3, Iteration = 400/ 2220  ===> Average training loss = , 0.138, Training Time: 0:42:08\nEpoch = 3, Iteration = 440/ 2220  ===> Average training loss = , 0.140, Training Time: 0:42:28\nEpoch = 3, Iteration = 480/ 2220  ===> Average training loss = , 0.140, Training Time: 0:42:48\nEpoch = 3, Iteration = 520/ 2220  ===> Average training loss = , 0.142, Training Time: 0:43:08\nEpoch = 3, Iteration = 560/ 2220  ===> Average training loss = , 0.144, Training Time: 0:43:28\nEpoch = 3, Iteration = 600/ 2220  ===> Average training loss = , 0.145, Training Time: 0:43:48\nEpoch = 3, Iteration = 640/ 2220  ===> Average training loss = , 0.146, Training Time: 0:44:08\nEpoch = 3, Iteration = 680/ 2220  ===> Average training loss = , 0.146, Training Time: 0:44:28\nEpoch = 3, Iteration = 720/ 2220  ===> Average training loss = , 0.142, Training Time: 0:44:49\nEpoch = 3, Iteration = 760/ 2220  ===> Average training loss = , 0.140, Training Time: 0:45:09\nEpoch = 3, Iteration = 800/ 2220  ===> Average training loss = , 0.140, Training Time: 0:45:29\nEpoch = 3, Iteration = 840/ 2220  ===> Average training loss = , 0.140, Training Time: 0:45:49\nEpoch = 3, Iteration = 880/ 2220  ===> Average training loss = , 0.140, Training Time: 0:46:09\nEpoch = 3, Iteration = 920/ 2220  ===> Average training loss = , 0.142, Training Time: 0:46:29\nEpoch = 3, Iteration = 960/ 2220  ===> Average training loss = , 0.142, Training Time: 0:46:49\nEpoch = 3, Iteration = 1000/ 2220  ===> Average training loss = , 0.142, Training Time: 0:47:09\nEpoch = 3, Iteration = 1040/ 2220  ===> Average training loss = , 0.141, Training Time: 0:47:29\nEpoch = 3, Iteration = 1080/ 2220  ===> Average training loss = , 0.141, Training Time: 0:47:49\nEpoch = 3, Iteration = 1120/ 2220  ===> Average training loss = , 0.141, Training Time: 0:48:10\nEpoch = 3, Iteration = 1160/ 2220  ===> Average training loss = , 0.142, Training Time: 0:48:30\nEpoch = 3, Iteration = 1200/ 2220  ===> Average training loss = , 0.142, Training Time: 0:48:50\nEpoch = 3, Iteration = 1240/ 2220  ===> Average training loss = , 0.142, Training Time: 0:49:10\nEpoch = 3, Iteration = 1280/ 2220  ===> Average training loss = , 0.141, Training Time: 0:49:30\nEpoch = 3, Iteration = 1320/ 2220  ===> Average training loss = , 0.143, Training Time: 0:49:50\nEpoch = 3, Iteration = 1360/ 2220  ===> Average training loss = , 0.143, Training Time: 0:50:10\nEpoch = 3, Iteration = 1400/ 2220  ===> Average training loss = , 0.143, Training Time: 0:50:30\nEpoch = 3, Iteration = 1440/ 2220  ===> Average training loss = , 0.142, Training Time: 0:50:50\nEpoch = 3, Iteration = 1480/ 2220  ===> Average training loss = , 0.143, Training Time: 0:51:11\nEpoch = 3, Iteration = 1520/ 2220  ===> Average training loss = , 0.142, Training Time: 0:51:31\nEpoch = 3, Iteration = 1560/ 2220  ===> Average training loss = , 0.142, Training Time: 0:51:51\nEpoch = 3, Iteration = 1600/ 2220  ===> Average training loss = , 0.142, Training Time: 0:52:11\nEpoch = 3, Iteration = 1640/ 2220  ===> Average training loss = , 0.143, Training Time: 0:52:31\nEpoch = 3, Iteration = 1680/ 2220  ===> Average training loss = , 0.143, Training Time: 0:52:51\nEpoch = 3, Iteration = 1720/ 2220  ===> Average training loss = , 0.144, Training Time: 0:53:11\nEpoch = 3, Iteration = 1760/ 2220  ===> Average training loss = , 0.145, Training Time: 0:53:31\nEpoch = 3, Iteration = 1800/ 2220  ===> Average training loss = , 0.145, Training Time: 0:53:52\nEpoch = 3, Iteration = 1840/ 2220  ===> Average training loss = , 0.145, Training Time: 0:54:12\nEpoch = 3, Iteration = 1880/ 2220  ===> Average training loss = , 0.145, Training Time: 0:54:32\nEpoch = 3, Iteration = 1920/ 2220  ===> Average training loss = , 0.145, Training Time: 0:54:52\nEpoch = 3, Iteration = 1960/ 2220  ===> Average training loss = , 0.145, Training Time: 0:55:12\nEpoch = 3, Iteration = 2000/ 2220  ===> Average training loss = , 0.145, Training Time: 0:55:32\nEpoch = 3, Iteration = 2040/ 2220  ===> Average training loss = , 0.145, Training Time: 0:55:52\nEpoch = 3, Iteration = 2080/ 2220  ===> Average training loss = , 0.146, Training Time: 0:56:12\nEpoch = 3, Iteration = 2120/ 2220  ===> Average training loss = , 0.146, Training Time: 0:56:33\nEpoch = 3, Iteration = 2160/ 2220  ===> Average training loss = , 0.147, Training Time: 0:56:53\nEpoch = 3, Iteration = 2200/ 2220  ===> Average training loss = , 0.147, Training Time: 0:57:13\nEpoch = 3 ===> training_accuracy =0.948 \nWeighted F1 Score: 0.5232\n\u001b[1mEpoch = 3 ====> Accuracy On Validation Dataset=0.571\u001b[0m\nF1 Score (Class bloomz): 0.9242\nF1 Score (Class chatGPT): 0.4505\nF1 Score (Class cohere): 0.4895\nF1 Score (Class davinci): 0.0036\nF1 Score (Class dolly): 0.6933\nF1 Score (Class human): 0.5782\n\nEpoch = 4, Iteration = 40/ 2220  ===> Average training loss = , 0.067, Training Time: 0:58:31\nEpoch = 4, Iteration = 80/ 2220  ===> Average training loss = , 0.080, Training Time: 0:58:51\nEpoch = 4, Iteration = 120/ 2220  ===> Average training loss = , 0.085, Training Time: 0:59:11\nEpoch = 4, Iteration = 160/ 2220  ===> Average training loss = , 0.082, Training Time: 0:59:31\nEpoch = 4, Iteration = 200/ 2220  ===> Average training loss = , 0.080, Training Time: 0:59:51\nEpoch = 4, Iteration = 240/ 2220  ===> Average training loss = , 0.076, Training Time: 1:00:11\nEpoch = 4, Iteration = 280/ 2220  ===> Average training loss = , 0.075, Training Time: 1:00:31\nEpoch = 4, Iteration = 320/ 2220  ===> Average training loss = , 0.073, Training Time: 1:00:51\nEpoch = 4, Iteration = 360/ 2220  ===> Average training loss = , 0.070, Training Time: 1:01:12\nEpoch = 4, Iteration = 400/ 2220  ===> Average training loss = , 0.072, Training Time: 1:01:32\nEpoch = 4, Iteration = 440/ 2220  ===> Average training loss = , 0.071, Training Time: 1:01:52\nEpoch = 4, Iteration = 480/ 2220  ===> Average training loss = , 0.072, Training Time: 1:02:12\nEpoch = 4, Iteration = 520/ 2220  ===> Average training loss = , 0.072, Training Time: 1:02:32\nEpoch = 4, Iteration = 560/ 2220  ===> Average training loss = , 0.072, Training Time: 1:02:52\nEpoch = 4, Iteration = 600/ 2220  ===> Average training loss = , 0.073, Training Time: 1:03:12\nEpoch = 4, Iteration = 640/ 2220  ===> Average training loss = , 0.074, Training Time: 1:03:32\nEpoch = 4, Iteration = 680/ 2220  ===> Average training loss = , 0.075, Training Time: 1:03:52\nEpoch = 4, Iteration = 720/ 2220  ===> Average training loss = , 0.076, Training Time: 1:04:12\nEpoch = 4, Iteration = 760/ 2220  ===> Average training loss = , 0.078, Training Time: 1:04:32\nEpoch = 4, Iteration = 800/ 2220  ===> Average training loss = , 0.078, Training Time: 1:04:53\nEpoch = 4, Iteration = 840/ 2220  ===> Average training loss = , 0.078, Training Time: 1:05:13\nEpoch = 4, Iteration = 880/ 2220  ===> Average training loss = , 0.079, Training Time: 1:05:33\nEpoch = 4, Iteration = 920/ 2220  ===> Average training loss = , 0.079, Training Time: 1:05:53\nEpoch = 4, Iteration = 960/ 2220  ===> Average training loss = , 0.079, Training Time: 1:06:13\nEpoch = 4, Iteration = 1000/ 2220  ===> Average training loss = , 0.080, Training Time: 1:06:33\nEpoch = 4, Iteration = 1040/ 2220  ===> Average training loss = , 0.081, Training Time: 1:06:53\nEpoch = 4, Iteration = 1080/ 2220  ===> Average training loss = , 0.081, Training Time: 1:07:13\nEpoch = 4, Iteration = 1120/ 2220  ===> Average training loss = , 0.082, Training Time: 1:07:33\nEpoch = 4, Iteration = 1160/ 2220  ===> Average training loss = , 0.083, Training Time: 1:07:53\nEpoch = 4, Iteration = 1200/ 2220  ===> Average training loss = , 0.083, Training Time: 1:08:13\nEpoch = 4, Iteration = 1240/ 2220  ===> Average training loss = , 0.083, Training Time: 1:08:33\nEpoch = 4, Iteration = 1280/ 2220  ===> Average training loss = , 0.082, Training Time: 1:08:54\nEpoch = 4, Iteration = 1320/ 2220  ===> Average training loss = , 0.083, Training Time: 1:09:14\nEpoch = 4, Iteration = 1360/ 2220  ===> Average training loss = , 0.083, Training Time: 1:09:34\nEpoch = 4, Iteration = 1400/ 2220  ===> Average training loss = , 0.083, Training Time: 1:09:54\nEpoch = 4, Iteration = 1440/ 2220  ===> Average training loss = , 0.082, Training Time: 1:10:14\nEpoch = 4, Iteration = 1480/ 2220  ===> Average training loss = , 0.083, Training Time: 1:10:34\nEpoch = 4, Iteration = 1520/ 2220  ===> Average training loss = , 0.084, Training Time: 1:10:54\nEpoch = 4, Iteration = 1560/ 2220  ===> Average training loss = , 0.084, Training Time: 1:11:14\nEpoch = 4, Iteration = 1600/ 2220  ===> Average training loss = , 0.084, Training Time: 1:11:34\nEpoch = 4, Iteration = 1640/ 2220  ===> Average training loss = , 0.084, Training Time: 1:11:54\nEpoch = 4, Iteration = 1680/ 2220  ===> Average training loss = , 0.084, Training Time: 1:12:14\nEpoch = 4, Iteration = 1720/ 2220  ===> Average training loss = , 0.083, Training Time: 1:12:34\nEpoch = 4, Iteration = 1760/ 2220  ===> Average training loss = , 0.083, Training Time: 1:12:55\nEpoch = 4, Iteration = 1800/ 2220  ===> Average training loss = , 0.082, Training Time: 1:13:15\nEpoch = 4, Iteration = 1840/ 2220  ===> Average training loss = , 0.083, Training Time: 1:13:35\nEpoch = 4, Iteration = 1880/ 2220  ===> Average training loss = , 0.083, Training Time: 1:13:55\nEpoch = 4, Iteration = 1920/ 2220  ===> Average training loss = , 0.084, Training Time: 1:14:15\nEpoch = 4, Iteration = 1960/ 2220  ===> Average training loss = , 0.085, Training Time: 1:14:35\nEpoch = 4, Iteration = 2000/ 2220  ===> Average training loss = , 0.085, Training Time: 1:14:55\nEpoch = 4, Iteration = 2040/ 2220  ===> Average training loss = , 0.085, Training Time: 1:15:15\nEpoch = 4, Iteration = 2080/ 2220  ===> Average training loss = , 0.085, Training Time: 1:15:35\nEpoch = 4, Iteration = 2120/ 2220  ===> Average training loss = , 0.085, Training Time: 1:15:55\nEpoch = 4, Iteration = 2160/ 2220  ===> Average training loss = , 0.085, Training Time: 1:16:16\nEpoch = 4, Iteration = 2200/ 2220  ===> Average training loss = , 0.085, Training Time: 1:16:36\nEpoch = 4 ===> training_accuracy =0.971 \nWeighted F1 Score: 0.5084\n\u001b[1mEpoch = 4 ====> Accuracy On Validation Dataset=0.558\u001b[0m\nF1 Score (Class bloomz): 0.9625\nF1 Score (Class chatGPT): 0.4919\nF1 Score (Class cohere): 0.4958\nF1 Score (Class davinci): 0.0283\nF1 Score (Class dolly): 0.6291\nF1 Score (Class human): 0.4427\n\nEpoch = 5, Iteration = 40/ 2220  ===> Average training loss = , 0.060, Training Time: 1:17:53\nEpoch = 5, Iteration = 80/ 2220  ===> Average training loss = , 0.049, Training Time: 1:18:13\nEpoch = 5, Iteration = 120/ 2220  ===> Average training loss = , 0.047, Training Time: 1:18:33\nEpoch = 5, Iteration = 160/ 2220  ===> Average training loss = , 0.043, Training Time: 1:18:53\nEpoch = 5, Iteration = 200/ 2220  ===> Average training loss = , 0.045, Training Time: 1:19:13\nEpoch = 5, Iteration = 240/ 2220  ===> Average training loss = , 0.045, Training Time: 1:19:33\nEpoch = 5, Iteration = 280/ 2220  ===> Average training loss = , 0.044, Training Time: 1:19:53\nEpoch = 5, Iteration = 320/ 2220  ===> Average training loss = , 0.042, Training Time: 1:20:13\nEpoch = 5, Iteration = 360/ 2220  ===> Average training loss = , 0.042, Training Time: 1:20:33\nEpoch = 5, Iteration = 400/ 2220  ===> Average training loss = , 0.043, Training Time: 1:20:54\nEpoch = 5, Iteration = 440/ 2220  ===> Average training loss = , 0.044, Training Time: 1:21:14\nEpoch = 5, Iteration = 480/ 2220  ===> Average training loss = , 0.046, Training Time: 1:21:34\nEpoch = 5, Iteration = 520/ 2220  ===> Average training loss = , 0.049, Training Time: 1:21:54\nEpoch = 5, Iteration = 560/ 2220  ===> Average training loss = , 0.049, Training Time: 1:22:14\nEpoch = 5, Iteration = 600/ 2220  ===> Average training loss = , 0.048, Training Time: 1:22:34\nEpoch = 5, Iteration = 640/ 2220  ===> Average training loss = , 0.049, Training Time: 1:22:54\nEpoch = 5, Iteration = 680/ 2220  ===> Average training loss = , 0.049, Training Time: 1:23:14\nEpoch = 5, Iteration = 720/ 2220  ===> Average training loss = , 0.050, Training Time: 1:23:34\nEpoch = 5, Iteration = 760/ 2220  ===> Average training loss = , 0.051, Training Time: 1:23:54\nEpoch = 5, Iteration = 800/ 2220  ===> Average training loss = , 0.052, Training Time: 1:24:14\nEpoch = 5, Iteration = 840/ 2220  ===> Average training loss = , 0.052, Training Time: 1:24:34\nEpoch = 5, Iteration = 880/ 2220  ===> Average training loss = , 0.053, Training Time: 1:24:55\nEpoch = 5, Iteration = 920/ 2220  ===> Average training loss = , 0.053, Training Time: 1:25:15\nEpoch = 5, Iteration = 960/ 2220  ===> Average training loss = , 0.053, Training Time: 1:25:35\nEpoch = 5, Iteration = 1000/ 2220  ===> Average training loss = , 0.054, Training Time: 1:25:55\nEpoch = 5, Iteration = 1040/ 2220  ===> Average training loss = , 0.054, Training Time: 1:26:15\nEpoch = 5, Iteration = 1080/ 2220  ===> Average training loss = , 0.054, Training Time: 1:26:35\nEpoch = 5, Iteration = 1120/ 2220  ===> Average training loss = , 0.055, Training Time: 1:26:55\nEpoch = 5, Iteration = 1160/ 2220  ===> Average training loss = , 0.055, Training Time: 1:27:15\nEpoch = 5, Iteration = 1200/ 2220  ===> Average training loss = , 0.056, Training Time: 1:27:35\nEpoch = 5, Iteration = 1240/ 2220  ===> Average training loss = , 0.056, Training Time: 1:27:56\nEpoch = 5, Iteration = 1280/ 2220  ===> Average training loss = , 0.057, Training Time: 1:28:16\nEpoch = 5, Iteration = 1320/ 2220  ===> Average training loss = , 0.056, Training Time: 1:28:36\nEpoch = 5, Iteration = 1360/ 2220  ===> Average training loss = , 0.057, Training Time: 1:28:56\nEpoch = 5, Iteration = 1400/ 2220  ===> Average training loss = , 0.057, Training Time: 1:29:16\nEpoch = 5, Iteration = 1440/ 2220  ===> Average training loss = , 0.058, Training Time: 1:29:36\nEpoch = 5, Iteration = 1480/ 2220  ===> Average training loss = , 0.057, Training Time: 1:29:56\nEpoch = 5, Iteration = 1520/ 2220  ===> Average training loss = , 0.058, Training Time: 1:30:16\nEpoch = 5, Iteration = 1560/ 2220  ===> Average training loss = , 0.058, Training Time: 1:30:36\nEpoch = 5, Iteration = 1600/ 2220  ===> Average training loss = , 0.058, Training Time: 1:30:56\nEpoch = 5, Iteration = 1640/ 2220  ===> Average training loss = , 0.058, Training Time: 1:31:16\nEpoch = 5, Iteration = 1680/ 2220  ===> Average training loss = , 0.058, Training Time: 1:31:36\nEpoch = 5, Iteration = 1720/ 2220  ===> Average training loss = , 0.059, Training Time: 1:31:56\nEpoch = 5, Iteration = 1760/ 2220  ===> Average training loss = , 0.059, Training Time: 1:32:17\nEpoch = 5, Iteration = 1800/ 2220  ===> Average training loss = , 0.059, Training Time: 1:32:37\nEpoch = 5, Iteration = 1840/ 2220  ===> Average training loss = , 0.058, Training Time: 1:32:57\nEpoch = 5, Iteration = 2000/ 2220  ===> Average training loss = , 0.059, Training Time: 1:34:17\nEpoch = 5, Iteration = 2040/ 2220  ===> Average training loss = , 0.058, Training Time: 1:34:37\nEpoch = 5, Iteration = 2080/ 2220  ===> Average training loss = , 0.058, Training Time: 1:34:57\nEpoch = 5, Iteration = 2120/ 2220  ===> Average training loss = , 0.058, Training Time: 1:35:17\nEpoch = 5, Iteration = 2160/ 2220  ===> Average training loss = , 0.058, Training Time: 1:35:37\nEpoch = 5, Iteration = 2200/ 2220  ===> Average training loss = , 0.058, Training Time: 1:35:58\nEpoch = 5 ===> training_accuracy =0.980 \nWeighted F1 Score: 0.5367\n\u001b[1mEpoch = 5 ====> Accuracy On Validation Dataset=0.581\u001b[0m\nF1 Score (Class bloomz): 0.9302\nF1 Score (Class chatGPT): 0.5216\nF1 Score (Class cohere): 0.4976\nF1 Score (Class davinci): 0.0144\nF1 Score (Class dolly): 0.6687\nF1 Score (Class human): 0.5874\n\nEpoch = 6, Iteration = 40/ 2220  ===> Average training loss = , 0.026, Training Time: 1:37:16\nEpoch = 6, Iteration = 80/ 2220  ===> Average training loss = , 0.026, Training Time: 1:37:36\nEpoch = 6, Iteration = 120/ 2220  ===> Average training loss = , 0.025, Training Time: 1:37:56\nEpoch = 6, Iteration = 160/ 2220  ===> Average training loss = , 0.029, Training Time: 1:38:16\nEpoch = 6, Iteration = 200/ 2220  ===> Average training loss = , 0.028, Training Time: 1:38:36\nEpoch = 6, Iteration = 240/ 2220  ===> Average training loss = , 0.033, Training Time: 1:38:56\nEpoch = 6, Iteration = 280/ 2220  ===> Average training loss = , 0.034, Training Time: 1:39:16\nEpoch = 6, Iteration = 320/ 2220  ===> Average training loss = , 0.033, Training Time: 1:39:36\nEpoch = 6, Iteration = 360/ 2220  ===> Average training loss = , 0.037, Training Time: 1:39:57\nEpoch = 6, Iteration = 400/ 2220  ===> Average training loss = , 0.036, Training Time: 1:40:17\nEpoch = 6, Iteration = 440/ 2220  ===> Average training loss = , 0.036, Training Time: 1:40:37\nEpoch = 6, Iteration = 480/ 2220  ===> Average training loss = , 0.036, Training Time: 1:40:57\nEpoch = 6, Iteration = 520/ 2220  ===> Average training loss = , 0.036, Training Time: 1:41:17\nEpoch = 6, Iteration = 560/ 2220  ===> Average training loss = , 0.036, Training Time: 1:41:37\nEpoch = 6, Iteration = 600/ 2220  ===> Average training loss = , 0.037, Training Time: 1:41:57\nEpoch = 6, Iteration = 640/ 2220  ===> Average training loss = , 0.037, Training Time: 1:42:17\nEpoch = 6, Iteration = 680/ 2220  ===> Average training loss = , 0.037, Training Time: 1:42:37\nEpoch = 6, Iteration = 720/ 2220  ===> Average training loss = , 0.038, Training Time: 1:42:57\nEpoch = 6, Iteration = 760/ 2220  ===> Average training loss = , 0.039, Training Time: 1:43:17\nEpoch = 6, Iteration = 800/ 2220  ===> Average training loss = , 0.040, Training Time: 1:43:38\nEpoch = 6, Iteration = 840/ 2220  ===> Average training loss = , 0.040, Training Time: 1:43:58\nEpoch = 6, Iteration = 880/ 2220  ===> Average training loss = , 0.039, Training Time: 1:44:18\nEpoch = 6, Iteration = 920/ 2220  ===> Average training loss = , 0.038, Training Time: 1:44:38\nEpoch = 6, Iteration = 960/ 2220  ===> Average training loss = , 0.039, Training Time: 1:44:58\nEpoch = 6, Iteration = 1000/ 2220  ===> Average training loss = , 0.040, Training Time: 1:45:18\nEpoch = 6, Iteration = 1040/ 2220  ===> Average training loss = , 0.040, Training Time: 1:45:38\nEpoch = 6, Iteration = 1080/ 2220  ===> Average training loss = , 0.041, Training Time: 1:45:58\nEpoch = 6, Iteration = 1120/ 2220  ===> Average training loss = , 0.041, Training Time: 1:46:18\nEpoch = 6, Iteration = 1160/ 2220  ===> Average training loss = , 0.040, Training Time: 1:46:38\nEpoch = 6, Iteration = 1200/ 2220  ===> Average training loss = , 0.040, Training Time: 1:46:58\nEpoch = 6, Iteration = 1240/ 2220  ===> Average training loss = , 0.040, Training Time: 1:47:18\nEpoch = 6, Iteration = 1280/ 2220  ===> Average training loss = , 0.040, Training Time: 1:47:38\nEpoch = 6, Iteration = 1320/ 2220  ===> Average training loss = , 0.039, Training Time: 1:47:59\nEpoch = 6, Iteration = 1360/ 2220  ===> Average training loss = , 0.040, Training Time: 1:48:19\nEpoch = 6, Iteration = 1400/ 2220  ===> Average training loss = , 0.039, Training Time: 1:48:39\nEpoch = 6, Iteration = 1440/ 2220  ===> Average training loss = , 0.038, Training Time: 1:48:59\nEpoch = 6, Iteration = 1480/ 2220  ===> Average training loss = , 0.038, Training Time: 1:49:19\nEpoch = 6, Iteration = 1520/ 2220  ===> Average training loss = , 0.038, Training Time: 1:49:39\nEpoch = 6, Iteration = 1560/ 2220  ===> Average training loss = , 0.037, Training Time: 1:49:59\nEpoch = 6, Iteration = 1600/ 2220  ===> Average training loss = , 0.038, Training Time: 1:50:19\nEpoch = 6, Iteration = 1640/ 2220  ===> Average training loss = , 0.039, Training Time: 1:50:39\nEpoch = 6, Iteration = 1680/ 2220  ===> Average training loss = , 0.040, Training Time: 1:50:59\nEpoch = 6, Iteration = 1720/ 2220  ===> Average training loss = , 0.041, Training Time: 1:51:19\nEpoch = 6, Iteration = 1760/ 2220  ===> Average training loss = , 0.041, Training Time: 1:51:39\nEpoch = 6, Iteration = 1800/ 2220  ===> Average training loss = , 0.041, Training Time: 1:52:00\nEpoch = 6, Iteration = 1840/ 2220  ===> Average training loss = , 0.041, Training Time: 1:52:20\nEpoch = 6, Iteration = 1880/ 2220  ===> Average training loss = , 0.042, Training Time: 1:52:40\nEpoch = 6, Iteration = 1920/ 2220  ===> Average training loss = , 0.042, Training Time: 1:53:00\nEpoch = 6, Iteration = 1960/ 2220  ===> Average training loss = , 0.042, Training Time: 1:53:20\nEpoch = 6, Iteration = 2000/ 2220  ===> Average training loss = , 0.042, Training Time: 1:53:40\nEpoch = 6, Iteration = 2040/ 2220  ===> Average training loss = , 0.042, Training Time: 1:54:00\nEpoch = 6, Iteration = 2080/ 2220  ===> Average training loss = , 0.041, Training Time: 1:54:20\nEpoch = 6, Iteration = 2120/ 2220  ===> Average training loss = , 0.041, Training Time: 1:54:40\nEpoch = 6, Iteration = 2160/ 2220  ===> Average training loss = , 0.041, Training Time: 1:55:00\nEpoch = 6, Iteration = 2200/ 2220  ===> Average training loss = , 0.041, Training Time: 1:55:20\nEpoch = 6 ===> training_accuracy =0.986 \nWeighted F1 Score: 0.5846\n\u001b[1mEpoch = 6 ====> Accuracy On Validation Dataset=0.613\u001b[0m\nF1 Score (Class bloomz): 0.9524\nF1 Score (Class chatGPT): 0.6795\nF1 Score (Class cohere): 0.5142\nF1 Score (Class davinci): 0.0625\nF1 Score (Class dolly): 0.6055\nF1 Score (Class human): 0.6936\n\nEpoch = 7, Iteration = 40/ 2220  ===> Average training loss = , 0.030, Training Time: 1:56:39\nEpoch = 7, Iteration = 80/ 2220  ===> Average training loss = , 0.028, Training Time: 1:56:59\nEpoch = 7, Iteration = 120/ 2220  ===> Average training loss = , 0.025, Training Time: 1:57:19\nEpoch = 7, Iteration = 160/ 2220  ===> Average training loss = , 0.025, Training Time: 1:57:39\nEpoch = 7, Iteration = 200/ 2220  ===> Average training loss = , 0.029, Training Time: 1:57:59\nEpoch = 7, Iteration = 240/ 2220  ===> Average training loss = , 0.028, Training Time: 1:58:19\nEpoch = 7, Iteration = 280/ 2220  ===> Average training loss = , 0.028, Training Time: 1:58:39\nEpoch = 7, Iteration = 320/ 2220  ===> Average training loss = , 0.027, Training Time: 1:59:00\nEpoch = 7, Iteration = 360/ 2220  ===> Average training loss = , 0.026, Training Time: 1:59:20\nEpoch = 7, Iteration = 400/ 2220  ===> Average training loss = , 0.026, Training Time: 1:59:40\nEpoch = 7, Iteration = 440/ 2220  ===> Average training loss = , 0.027, Training Time: 2:00:00\nEpoch = 7, Iteration = 480/ 2220  ===> Average training loss = , 0.028, Training Time: 2:00:20\nEpoch = 7, Iteration = 520/ 2220  ===> Average training loss = , 0.029, Training Time: 2:00:40\nEpoch = 7, Iteration = 560/ 2220  ===> Average training loss = , 0.030, Training Time: 2:01:00\nEpoch = 7, Iteration = 600/ 2220  ===> Average training loss = , 0.030, Training Time: 2:01:20\nEpoch = 7, Iteration = 640/ 2220  ===> Average training loss = , 0.028, Training Time: 2:01:40\nEpoch = 7, Iteration = 680/ 2220  ===> Average training loss = , 0.029, Training Time: 2:02:00\nEpoch = 7, Iteration = 720/ 2220  ===> Average training loss = , 0.029, Training Time: 2:02:20\nEpoch = 7, Iteration = 760/ 2220  ===> Average training loss = , 0.029, Training Time: 2:02:41\nEpoch = 7, Iteration = 800/ 2220  ===> Average training loss = , 0.030, Training Time: 2:03:01\nEpoch = 7, Iteration = 840/ 2220  ===> Average training loss = , 0.031, Training Time: 2:03:21\nEpoch = 7, Iteration = 880/ 2220  ===> Average training loss = , 0.032, Training Time: 2:03:41\nEpoch = 7, Iteration = 920/ 2220  ===> Average training loss = , 0.032, Training Time: 2:04:01\nEpoch = 7, Iteration = 960/ 2220  ===> Average training loss = , 0.033, Training Time: 2:04:21\nEpoch = 7, Iteration = 1000/ 2220  ===> Average training loss = , 0.032, Training Time: 2:04:41\nEpoch = 7, Iteration = 1040/ 2220  ===> Average training loss = , 0.032, Training Time: 2:05:01\nEpoch = 7, Iteration = 1080/ 2220  ===> Average training loss = , 0.032, Training Time: 2:05:21\nEpoch = 7, Iteration = 1120/ 2220  ===> Average training loss = , 0.031, Training Time: 2:05:41\nEpoch = 7, Iteration = 1160/ 2220  ===> Average training loss = , 0.033, Training Time: 2:06:01\nEpoch = 7, Iteration = 1200/ 2220  ===> Average training loss = , 0.034, Training Time: 2:06:22\nEpoch = 7, Iteration = 1240/ 2220  ===> Average training loss = , 0.034, Training Time: 2:06:42\nEpoch = 7, Iteration = 1280/ 2220  ===> Average training loss = , 0.034, Training Time: 2:07:02\nEpoch = 7, Iteration = 1320/ 2220  ===> Average training loss = , 0.035, Training Time: 2:07:22\nEpoch = 7, Iteration = 1360/ 2220  ===> Average training loss = , 0.034, Training Time: 2:07:42\nEpoch = 7, Iteration = 1400/ 2220  ===> Average training loss = , 0.034, Training Time: 2:08:02\nEpoch = 7, Iteration = 1440/ 2220  ===> Average training loss = , 0.035, Training Time: 2:08:22\nEpoch = 7, Iteration = 1480/ 2220  ===> Average training loss = , 0.035, Training Time: 2:08:42\nEpoch = 7, Iteration = 1520/ 2220  ===> Average training loss = , 0.034, Training Time: 2:09:02\nEpoch = 7, Iteration = 1560/ 2220  ===> Average training loss = , 0.034, Training Time: 2:09:22\nEpoch = 7, Iteration = 1600/ 2220  ===> Average training loss = , 0.034, Training Time: 2:09:42\nEpoch = 7, Iteration = 1640/ 2220  ===> Average training loss = , 0.034, Training Time: 2:10:02\nEpoch = 7, Iteration = 1680/ 2220  ===> Average training loss = , 0.034, Training Time: 2:10:23\nEpoch = 7, Iteration = 1720/ 2220  ===> Average training loss = , 0.034, Training Time: 2:10:43\nEpoch = 7, Iteration = 1760/ 2220  ===> Average training loss = , 0.035, Training Time: 2:11:03\nEpoch = 7, Iteration = 1800/ 2220  ===> Average training loss = , 0.035, Training Time: 2:11:23\nEpoch = 7, Iteration = 1840/ 2220  ===> Average training loss = , 0.036, Training Time: 2:11:43\nEpoch = 7, Iteration = 1880/ 2220  ===> Average training loss = , 0.036, Training Time: 2:12:03\nEpoch = 7, Iteration = 1920/ 2220  ===> Average training loss = , 0.037, Training Time: 2:12:23\nEpoch = 7, Iteration = 1960/ 2220  ===> Average training loss = , 0.037, Training Time: 2:12:43\nEpoch = 7, Iteration = 2000/ 2220  ===> Average training loss = , 0.036, Training Time: 2:13:03\nEpoch = 7, Iteration = 2040/ 2220  ===> Average training loss = , 0.036, Training Time: 2:13:23\nEpoch = 7, Iteration = 2080/ 2220  ===> Average training loss = , 0.036, Training Time: 2:13:43\nEpoch = 7, Iteration = 2120/ 2220  ===> Average training loss = , 0.035, Training Time: 2:14:04\nEpoch = 7, Iteration = 2160/ 2220  ===> Average training loss = , 0.035, Training Time: 2:14:24\nEpoch = 7, Iteration = 2200/ 2220  ===> Average training loss = , 0.035, Training Time: 2:14:44\nEpoch = 7 ===> training_accuracy =0.989 \nWeighted F1 Score: 0.5384\n\u001b[1mEpoch = 7 ====> Accuracy On Validation Dataset=0.573\u001b[0m\nF1 Score (Class bloomz): 0.9728\nF1 Score (Class chatGPT): 0.4821\nF1 Score (Class cohere): 0.4818\nF1 Score (Class davinci): 0.0256\nF1 Score (Class dolly): 0.6923\nF1 Score (Class human): 0.5758\n\nEpoch = 8, Iteration = 40/ 2220  ===> Average training loss = , 0.014, Training Time: 2:16:01\nEpoch = 8, Iteration = 80/ 2220  ===> Average training loss = , 0.025, Training Time: 2:16:21\nEpoch = 8, Iteration = 120/ 2220  ===> Average training loss = , 0.031, Training Time: 2:16:41\nEpoch = 8, Iteration = 160/ 2220  ===> Average training loss = , 0.030, Training Time: 2:17:01\nEpoch = 8, Iteration = 200/ 2220  ===> Average training loss = , 0.029, Training Time: 2:17:22\nEpoch = 8, Iteration = 240/ 2220  ===> Average training loss = , 0.030, Training Time: 2:17:42\nEpoch = 8, Iteration = 280/ 2220  ===> Average training loss = , 0.030, Training Time: 2:18:02\nEpoch = 8, Iteration = 320/ 2220  ===> Average training loss = , 0.028, Training Time: 2:18:22\nEpoch = 8, Iteration = 360/ 2220  ===> Average training loss = , 0.027, Training Time: 2:18:42\nEpoch = 8, Iteration = 400/ 2220  ===> Average training loss = , 0.029, Training Time: 2:19:02\nEpoch = 8, Iteration = 440/ 2220  ===> Average training loss = , 0.027, Training Time: 2:19:22\nEpoch = 8, Iteration = 480/ 2220  ===> Average training loss = , 0.027, Training Time: 2:19:42\nEpoch = 8, Iteration = 520/ 2220  ===> Average training loss = , 0.026, Training Time: 2:20:02\nEpoch = 8, Iteration = 560/ 2220  ===> Average training loss = , 0.025, Training Time: 2:20:22\nEpoch = 8, Iteration = 600/ 2220  ===> Average training loss = , 0.024, Training Time: 2:20:42\nEpoch = 8, Iteration = 640/ 2220  ===> Average training loss = , 0.025, Training Time: 2:21:02\nEpoch = 8, Iteration = 680/ 2220  ===> Average training loss = , 0.025, Training Time: 2:21:23\nEpoch = 8, Iteration = 720/ 2220  ===> Average training loss = , 0.025, Training Time: 2:21:43\nEpoch = 8, Iteration = 760/ 2220  ===> Average training loss = , 0.024, Training Time: 2:22:03\nEpoch = 8, Iteration = 800/ 2220  ===> Average training loss = , 0.024, Training Time: 2:22:23\nEpoch = 8, Iteration = 840/ 2220  ===> Average training loss = , 0.024, Training Time: 2:22:43\nEpoch = 8, Iteration = 880/ 2220  ===> Average training loss = , 0.024, Training Time: 2:23:03\nEpoch = 8, Iteration = 920/ 2220  ===> Average training loss = , 0.024, Training Time: 2:23:23\nEpoch = 8, Iteration = 960/ 2220  ===> Average training loss = , 0.025, Training Time: 2:23:43\nEpoch = 8, Iteration = 1000/ 2220  ===> Average training loss = , 0.026, Training Time: 2:24:03\nEpoch = 8, Iteration = 1040/ 2220  ===> Average training loss = , 0.026, Training Time: 2:24:24\nEpoch = 8, Iteration = 1080/ 2220  ===> Average training loss = , 0.026, Training Time: 2:24:44\nEpoch = 8, Iteration = 1120/ 2220  ===> Average training loss = , 0.026, Training Time: 2:25:04\nEpoch = 8, Iteration = 1160/ 2220  ===> Average training loss = , 0.026, Training Time: 2:25:24\nEpoch = 8, Iteration = 1200/ 2220  ===> Average training loss = , 0.027, Training Time: 2:25:44\nEpoch = 8, Iteration = 1240/ 2220  ===> Average training loss = , 0.027, Training Time: 2:26:04\nEpoch = 8, Iteration = 1280/ 2220  ===> Average training loss = , 0.027, Training Time: 2:26:24\nEpoch = 8, Iteration = 1320/ 2220  ===> Average training loss = , 0.027, Training Time: 2:26:44\nEpoch = 8, Iteration = 1360/ 2220  ===> Average training loss = , 0.027, Training Time: 2:27:04\nEpoch = 8, Iteration = 1400/ 2220  ===> Average training loss = , 0.029, Training Time: 2:27:24\nEpoch = 8, Iteration = 1440/ 2220  ===> Average training loss = , 0.029, Training Time: 2:27:45\nEpoch = 8, Iteration = 1480/ 2220  ===> Average training loss = , 0.029, Training Time: 2:28:05\nEpoch = 8, Iteration = 1520/ 2220  ===> Average training loss = , 0.030, Training Time: 2:28:25\nEpoch = 8, Iteration = 1560/ 2220  ===> Average training loss = , 0.030, Training Time: 2:28:45\nEpoch = 8, Iteration = 1600/ 2220  ===> Average training loss = , 0.031, Training Time: 2:29:05\nEpoch = 8, Iteration = 1640/ 2220  ===> Average training loss = , 0.030, Training Time: 2:29:25\nEpoch = 8, Iteration = 1680/ 2220  ===> Average training loss = , 0.030, Training Time: 2:29:45\nEpoch = 8, Iteration = 1720/ 2220  ===> Average training loss = , 0.030, Training Time: 2:30:05\nEpoch = 8, Iteration = 1760/ 2220  ===> Average training loss = , 0.030, Training Time: 2:30:26\nEpoch = 8, Iteration = 1800/ 2220  ===> Average training loss = , 0.030, Training Time: 2:30:46\nEpoch = 8, Iteration = 1840/ 2220  ===> Average training loss = , 0.029, Training Time: 2:31:06\nEpoch = 8, Iteration = 1880/ 2220  ===> Average training loss = , 0.029, Training Time: 2:31:26\nEpoch = 8, Iteration = 1920/ 2220  ===> Average training loss = , 0.029, Training Time: 2:31:46\nEpoch = 8, Iteration = 1960/ 2220  ===> Average training loss = , 0.030, Training Time: 2:32:06\nEpoch = 8, Iteration = 2000/ 2220  ===> Average training loss = , 0.030, Training Time: 2:32:26\nEpoch = 8, Iteration = 2040/ 2220  ===> Average training loss = , 0.030, Training Time: 2:32:46\nEpoch = 8, Iteration = 2080/ 2220  ===> Average training loss = , 0.030, Training Time: 2:33:06\nEpoch = 8, Iteration = 2120/ 2220  ===> Average training loss = , 0.031, Training Time: 2:33:27\nEpoch = 8, Iteration = 2160/ 2220  ===> Average training loss = , 0.031, Training Time: 2:33:47\nEpoch = 8, Iteration = 2200/ 2220  ===> Average training loss = , 0.031, Training Time: 2:34:07\nEpoch = 8 ===> training_accuracy =0.990 \nWeighted F1 Score: 0.5583\n\u001b[1mEpoch = 8 ====> Accuracy On Validation Dataset=0.594\u001b[0m\nF1 Score (Class bloomz): 0.9662\nF1 Score (Class chatGPT): 0.6667\nF1 Score (Class cohere): 0.5120\nF1 Score (Class davinci): 0.0102\nF1 Score (Class dolly): 0.6007\nF1 Score (Class human): 0.5942\n\nEpoch = 9, Iteration = 40/ 2220  ===> Average training loss = , 0.017, Training Time: 2:35:24\nEpoch = 9, Iteration = 80/ 2220  ===> Average training loss = , 0.019, Training Time: 2:35:44\nEpoch = 9, Iteration = 120/ 2220  ===> Average training loss = , 0.016, Training Time: 2:36:05\nEpoch = 9, Iteration = 160/ 2220  ===> Average training loss = , 0.014, Training Time: 2:36:25\nEpoch = 9, Iteration = 200/ 2220  ===> Average training loss = , 0.012, Training Time: 2:36:45\nEpoch = 9, Iteration = 240/ 2220  ===> Average training loss = , 0.013, Training Time: 2:37:05\nEpoch = 9, Iteration = 280/ 2220  ===> Average training loss = , 0.015, Training Time: 2:37:25\nEpoch = 9, Iteration = 320/ 2220  ===> Average training loss = , 0.014, Training Time: 2:37:45\nEpoch = 9, Iteration = 360/ 2220  ===> Average training loss = , 0.014, Training Time: 2:38:05\nEpoch = 9, Iteration = 400/ 2220  ===> Average training loss = , 0.015, Training Time: 2:38:25\nEpoch = 9, Iteration = 440/ 2220  ===> Average training loss = , 0.016, Training Time: 2:38:46\nEpoch = 9, Iteration = 480/ 2220  ===> Average training loss = , 0.019, Training Time: 2:39:06\nEpoch = 9, Iteration = 520/ 2220  ===> Average training loss = , 0.020, Training Time: 2:39:26\nEpoch = 9, Iteration = 560/ 2220  ===> Average training loss = , 0.021, Training Time: 2:39:46\nEpoch = 9, Iteration = 600/ 2220  ===> Average training loss = , 0.020, Training Time: 2:40:06\nEpoch = 9, Iteration = 640/ 2220  ===> Average training loss = , 0.022, Training Time: 2:40:26\nEpoch = 9, Iteration = 680/ 2220  ===> Average training loss = , 0.022, Training Time: 2:40:46\nEpoch = 9, Iteration = 720/ 2220  ===> Average training loss = , 0.023, Training Time: 2:41:06\nEpoch = 9, Iteration = 760/ 2220  ===> Average training loss = , 0.024, Training Time: 2:41:26\nEpoch = 9, Iteration = 800/ 2220  ===> Average training loss = , 0.024, Training Time: 2:41:47\nEpoch = 9, Iteration = 840/ 2220  ===> Average training loss = , 0.023, Training Time: 2:42:07\nEpoch = 9, Iteration = 880/ 2220  ===> Average training loss = , 0.023, Training Time: 2:42:27\nEpoch = 9, Iteration = 920/ 2220  ===> Average training loss = , 0.023, Training Time: 2:42:47\nEpoch = 9, Iteration = 960/ 2220  ===> Average training loss = , 0.024, Training Time: 2:43:07\nEpoch = 9, Iteration = 1000/ 2220  ===> Average training loss = , 0.024, Training Time: 2:43:27\nEpoch = 9, Iteration = 1040/ 2220  ===> Average training loss = , 0.024, Training Time: 2:43:47\nEpoch = 9, Iteration = 1080/ 2220  ===> Average training loss = , 0.024, Training Time: 2:44:07\nEpoch = 9, Iteration = 1120/ 2220  ===> Average training loss = , 0.024, Training Time: 2:44:27\nEpoch = 9, Iteration = 1160/ 2220  ===> Average training loss = , 0.024, Training Time: 2:44:47\nEpoch = 9, Iteration = 1200/ 2220  ===> Average training loss = , 0.024, Training Time: 2:45:07\nEpoch = 9, Iteration = 1240/ 2220  ===> Average training loss = , 0.024, Training Time: 2:45:28\nEpoch = 9, Iteration = 1280/ 2220  ===> Average training loss = , 0.025, Training Time: 2:45:48\nEpoch = 9, Iteration = 1320/ 2220  ===> Average training loss = , 0.025, Training Time: 2:46:08\nEpoch = 9, Iteration = 1360/ 2220  ===> Average training loss = , 0.026, Training Time: 2:46:28\nEpoch = 9, Iteration = 1400/ 2220  ===> Average training loss = , 0.027, Training Time: 2:46:48\nEpoch = 9, Iteration = 1440/ 2220  ===> Average training loss = , 0.027, Training Time: 2:47:08\nEpoch = 9, Iteration = 1480/ 2220  ===> Average training loss = , 0.027, Training Time: 2:47:28\nEpoch = 9, Iteration = 1520/ 2220  ===> Average training loss = , 0.027, Training Time: 2:47:48\nEpoch = 9, Iteration = 1560/ 2220  ===> Average training loss = , 0.027, Training Time: 2:48:08\nEpoch = 9, Iteration = 1600/ 2220  ===> Average training loss = , 0.026, Training Time: 2:48:28\nEpoch = 9, Iteration = 1640/ 2220  ===> Average training loss = , 0.026, Training Time: 2:48:48\nEpoch = 9, Iteration = 1680/ 2220  ===> Average training loss = , 0.026, Training Time: 2:49:08\nEpoch = 9, Iteration = 1720/ 2220  ===> Average training loss = , 0.026, Training Time: 2:49:29\nEpoch = 9, Iteration = 1760/ 2220  ===> Average training loss = , 0.027, Training Time: 2:49:49\nEpoch = 9, Iteration = 1800/ 2220  ===> Average training loss = , 0.027, Training Time: 2:50:09\nEpoch = 9, Iteration = 1840/ 2220  ===> Average training loss = , 0.027, Training Time: 2:50:29\nEpoch = 9, Iteration = 1880/ 2220  ===> Average training loss = , 0.027, Training Time: 2:50:49\nEpoch = 9, Iteration = 1920/ 2220  ===> Average training loss = , 0.027, Training Time: 2:51:09\nEpoch = 9, Iteration = 1960/ 2220  ===> Average training loss = , 0.027, Training Time: 2:51:29\nEpoch = 9, Iteration = 2000/ 2220  ===> Average training loss = , 0.027, Training Time: 2:51:49\nEpoch = 9, Iteration = 2040/ 2220  ===> Average training loss = , 0.027, Training Time: 2:52:09\nEpoch = 9, Iteration = 2080/ 2220  ===> Average training loss = , 0.026, Training Time: 2:52:29\nEpoch = 9, Iteration = 2120/ 2220  ===> Average training loss = , 0.026, Training Time: 2:52:50\nEpoch = 9, Iteration = 2160/ 2220  ===> Average training loss = , 0.026, Training Time: 2:53:10\nEpoch = 9, Iteration = 2200/ 2220  ===> Average training loss = , 0.027, Training Time: 2:53:30\nEpoch = 9 ===> training_accuracy =0.991 \nEpoch = 10, Iteration = 120/ 2220  ===> Average training loss = , 0.009, Training Time: 2:55:27\nEpoch = 10, Iteration = 160/ 2220  ===> Average training loss = , 0.009, Training Time: 2:55:47\nEpoch = 10, Iteration = 200/ 2220  ===> Average training loss = , 0.013, Training Time: 2:56:08\nEpoch = 10, Iteration = 240/ 2220  ===> Average training loss = , 0.014, Training Time: 2:56:28\nEpoch = 10, Iteration = 280/ 2220  ===> Average training loss = , 0.014, Training Time: 2:56:48\nEpoch = 10, Iteration = 320/ 2220  ===> Average training loss = , 0.015, Training Time: 2:57:08\nEpoch = 10, Iteration = 360/ 2220  ===> Average training loss = , 0.015, Training Time: 2:57:28\nEpoch = 10, Iteration = 400/ 2220  ===> Average training loss = , 0.014, Training Time: 2:57:48\nEpoch = 10, Iteration = 440/ 2220  ===> Average training loss = , 0.015, Training Time: 2:58:08\nEpoch = 10, Iteration = 480/ 2220  ===> Average training loss = , 0.014, Training Time: 2:58:28\nEpoch = 10, Iteration = 520/ 2220  ===> Average training loss = , 0.015, Training Time: 2:58:48\nEpoch = 10, Iteration = 560/ 2220  ===> Average training loss = , 0.016, Training Time: 2:59:09\nEpoch = 10, Iteration = 600/ 2220  ===> Average training loss = , 0.020, Training Time: 2:59:29\nEpoch = 10, Iteration = 640/ 2220  ===> Average training loss = , 0.023, Training Time: 2:59:49\nEpoch = 10, Iteration = 680/ 2220  ===> Average training loss = , 0.024, Training Time: 3:00:09\nEpoch = 10, Iteration = 720/ 2220  ===> Average training loss = , 0.023, Training Time: 3:00:29\nEpoch = 10, Iteration = 760/ 2220  ===> Average training loss = , 0.023, Training Time: 3:00:49\nEpoch = 10, Iteration = 800/ 2220  ===> Average training loss = , 0.023, Training Time: 3:01:09\nEpoch = 10, Iteration = 840/ 2220  ===> Average training loss = , 0.023, Training Time: 3:01:29\nEpoch = 10, Iteration = 880/ 2220  ===> Average training loss = , 0.025, Training Time: 3:01:49\nEpoch = 10, Iteration = 920/ 2220  ===> Average training loss = , 0.025, Training Time: 3:02:09\nEpoch = 10, Iteration = 960/ 2220  ===> Average training loss = , 0.025, Training Time: 3:02:29\nEpoch = 10, Iteration = 1000/ 2220  ===> Average training loss = , 0.025, Training Time: 3:02:49\nEpoch = 10, Iteration = 1040/ 2220  ===> Average training loss = , 0.024, Training Time: 3:03:09\nEpoch = 10, Iteration = 1080/ 2220  ===> Average training loss = , 0.024, Training Time: 3:03:30\nEpoch = 10, Iteration = 1120/ 2220  ===> Average training loss = , 0.024, Training Time: 3:03:50\nEpoch = 10, Iteration = 1160/ 2220  ===> Average training loss = , 0.024, Training Time: 3:04:10\nEpoch = 10, Iteration = 1200/ 2220  ===> Average training loss = , 0.023, Training Time: 3:04:30\nEpoch = 10, Iteration = 1240/ 2220  ===> Average training loss = , 0.023, Training Time: 3:04:50\nEpoch = 10, Iteration = 1280/ 2220  ===> Average training loss = , 0.023, Training Time: 3:05:10\nEpoch = 10, Iteration = 1320/ 2220  ===> Average training loss = , 0.023, Training Time: 3:05:30\nEpoch = 10, Iteration = 1360/ 2220  ===> Average training loss = , 0.022, Training Time: 3:05:50\nEpoch = 10, Iteration = 1400/ 2220  ===> Average training loss = , 0.023, Training Time: 3:06:10\nEpoch = 10, Iteration = 1440/ 2220  ===> Average training loss = , 0.023, Training Time: 3:06:30\nEpoch = 10, Iteration = 1480/ 2220  ===> Average training loss = , 0.023, Training Time: 3:06:50\nEpoch = 10, Iteration = 1520/ 2220  ===> Average training loss = , 0.024, Training Time: 3:07:10\nEpoch = 10, Iteration = 1560/ 2220  ===> Average training loss = , 0.024, Training Time: 3:07:31\nEpoch = 10, Iteration = 1600/ 2220  ===> Average training loss = , 0.024, Training Time: 3:07:51\nEpoch = 10, Iteration = 1640/ 2220  ===> Average training loss = , 0.025, Training Time: 3:08:11\nEpoch = 10, Iteration = 1680/ 2220  ===> Average training loss = , 0.025, Training Time: 3:08:31\nEpoch = 10, Iteration = 1720/ 2220  ===> Average training loss = , 0.024, Training Time: 3:08:51\nEpoch = 10, Iteration = 1760/ 2220  ===> Average training loss = , 0.025, Training Time: 3:09:11\nEpoch = 10, Iteration = 1800/ 2220  ===> Average training loss = , 0.025, Training Time: 3:09:31\nEpoch = 10, Iteration = 1840/ 2220  ===> Average training loss = , 0.025, Training Time: 3:09:51\nEpoch = 10, Iteration = 1880/ 2220  ===> Average training loss = , 0.024, Training Time: 3:10:11\nEpoch = 10, Iteration = 1920/ 2220  ===> Average training loss = , 0.024, Training Time: 3:10:31\nEpoch = 10, Iteration = 1960/ 2220  ===> Average training loss = , 0.024, Training Time: 3:10:51\nEpoch = 10, Iteration = 2000/ 2220  ===> Average training loss = , 0.025, Training Time: 3:11:12\nEpoch = 10, Iteration = 2040/ 2220  ===> Average training loss = , 0.025, Training Time: 3:11:32\nEpoch = 10, Iteration = 2080/ 2220  ===> Average training loss = , 0.025, Training Time: 3:11:52\nEpoch = 10, Iteration = 2120/ 2220  ===> Average training loss = , 0.025, Training Time: 3:12:12\nEpoch = 10, Iteration = 2160/ 2220  ===> Average training loss = , 0.025, Training Time: 3:12:32\nEpoch = 10, Iteration = 2200/ 2220  ===> Average training loss = , 0.025, Training Time: 3:12:52\nEpoch = 10 ===> training_accuracy =0.992 \nWeighted F1 Score: 0.4746\n\u001b[1mEpoch = 10 ====> Accuracy On Validation Dataset=0.530\u001b[0m\nF1 Score (Class bloomz): 0.9559\nF1 Score (Class chatGPT): 0.3458\nF1 Score (Class cohere): 0.4773\nF1 Score (Class davinci): 0.0035\nF1 Score (Class dolly): 0.5837\nF1 Score (Class human): 0.4812\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### PLot Validation Accuracies and Weighted F1 Scores","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10, 8))\n\n# Plot accuracy scores with lines and star markers\nax.plot(percentages, [100*i for i in accuracies], linestyle='-', marker='*', color='blue', label='Accuracy')\n\n# Plot F1 weighted scores with lines and star markers\nax.plot(percentages, [100*i for i in weighted_f1s], linestyle='--', marker='^', color='green', label='F1 Weighted')\n\n# Add labels, legend, and show the plot\nax.set_ylabel('Scores')\nax.set_xlabel('Percentage')\nax.legend()\nplt.title('Accuracy and F1 Weighted Scores by Percentages of training data for bert classifier')\nplt.grid(\"on\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T06:58:56.454382Z","iopub.execute_input":"2024-02-02T06:58:56.454773Z","iopub.status.idle":"2024-02-02T06:58:56.754011Z","shell.execute_reply.started":"2024-02-02T06:58:56.454745Z","shell.execute_reply":"2024-02-02T06:58:56.753084Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA0kAAAK9CAYAAADxDSf7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAADEnklEQVR4nOzdd3gUVdsG8Hs3vYc0UklCAglBapAOoYf+Ih1UQBQRRAEVBOndLpZPEFRQBOkiSu+995YQILQQSkJ6T/Z8f4w7myEJpG/K/bsuLjZzpjyzOzu7z54zz6iEEAJEREREREQEAFDrOwAiIiIiIqKyhEkSERERERFRNkySiIiIiIiIsmGSRERERERElA2TJCIiIiIiomyYJBEREREREWXDJImIiIiIiCgbJklERERERETZMEkiIiIiIiLKhkkSUSG0adMGbdq00XcYpaoo+9ymTRu89NJLxRtQAc2cORMqlUqvMZRF+/fvh0qlwvr16/UdCpVDmZmZmDhxIjw8PKBWq9GrVy+9xKE9jvfv31/gZW/fvg2VSoXly5cXe1yFtXz5cqhUKty+fVvfoSh88cUXqF69OgwMDFC/fv0S3VZZ+NwoirJwXHl5eWHYsGGKaWFhYejUqRNsbGygUqmwadOmMnu86RuTpDLoxx9/hEqlQpMmTfQdChWRl5cXVCpVrv9SU1MBAImJiZgxYwY6d+4MOzu7Ap1UP//8c6hUKpw7d04xXQiBKlWqQKVSITw8XNGWmpoKExMTDB48uFj2sTg9ePAAM2fOxPnz5/Uaxz///IOgoCA4OTnB3Nwc1atXR//+/bF9+3a9xlWeaZNU7T9zc3MEBARg6tSpiI+P13d4RXb06FHMnDkTsbGx+g6lVP3666/44osv0LdvX/z2228YP358nvP++OOPZSoRqahWrVqFhQsXFvt6d+7ciYkTJ6JFixZYtmwZ5s+fX+zb0Jfk5GTMnDmzUEl2eTN06FBcunQJ8+bNw4oVK9CoUSN9h1RmGeo7AMpp5cqV8PLywsmTJ3Hjxg34+vrqOyQqgvr16+PDDz/MMd3Y2BgAEBUVhdmzZ6NatWqoV69egU7SLVu2BAAcPnwYDRo0kKdfuXIFsbGxMDQ0xJEjR+Dt7S23nTp1Cunp6fKy+bVz584CzV8YDx48wKxZs+Dl5VXiv1Lm5csvv8SECRMQFBSEyZMnw9zcHDdu3MDu3buxevVqdO7cWS9xVRSLFi2CpaUlEhMTsXPnTsybNw979+7FkSNHynVP39GjRzFr1iwMGzYMtra2+g6n1Ozduxdubm745ptvXjjvjz/+CAcHhxy/bBeH1q1bIyUlRT6vFoSnpydSUlJgZGRU7HHpw6pVq3D58mWMGzeuWNe7d+9eqNVq/PLLL4V6nsuy5ORkzJo1CwAq1CiR0NBQqNW6/pCUlBQcO3YMU6ZMwZgxY+Tpr7/+OgYOHAgTExN9hFlmMUkqY8LDw3H06FFs3LgRI0eOxMqVKzFjxgx9h5WrpKQkWFhY6DuMMs/NzQ2vvfZanu0uLi6IjIyEs7MzTp8+jZdffjnf627UqBFMTU1x+PBhvPfee/L0I0eOwN7eHo0aNcLhw4cV2z98+DAAFDhJqmgfirnJzMzEnDlz0LFjx1yTwsePH5daLBqNBunp6TA1NS21bZaGvn37wsHBAQDwzjvvoE+fPti4cSOOHz+OZs2aFXq9QgikpqbCzMysuEKlfHj8+HGJJIUF/XxRq9WFfq+oVKoK9z4rCY8fP4aZmVmxfRaUhfes9jxbUT2b9Dx58gQAcrxnDQwMYGBgUGzbrSjfDzncroxZuXIlqlSpgm7duqFv375YuXJlrvPFxsZi/Pjx8PLygomJCdzd3TFkyBBERUXJ86SmpmLmzJmoWbMmTE1N4eLigt69e+PmzZsA8h7Dnds42mHDhsHS0hI3b95E165dYWVlhVdffRUAcOjQIfTr1w/VqlWDiYkJPDw8MH78eKSkpOSIOyQkBP3794ejoyPMzMzg5+eHKVOmAAD27dsHlUqFv/76K8dyq1atgkqlwrFjx/J87p4+fYqPPvoIderUgaWlJaytrdGlSxdcuHBBMZ92v9euXYt58+bB3d0dpqamaN++PW7cuJFjvUuWLIGPjw/MzMzQuHFjHDp0KM8YCsPExATOzs6FWtbY2Bgvv/wyjhw5oph+5MgRNGvWDC1atMi1zdbWVh7rrdFosHDhQtSuXRumpqaoWrUqRo4ciZiYGMVyuV2TdOfOHfTs2RMWFhZwcnLC+PHjsWPHjjyvDbh69Sratm0Lc3NzuLm54fPPP5fb9u/fLyeIb7zxhjwsK/txeOLECXTu3Bk2NjYwNzdHUFBQjv0DpETw5ZdfhqmpKXx8fPDTTz+98LkEpF69+Ph4tGjRItd2Jycnxd8veo8B0ofFhx9+CA8PD5iYmMDPzw9ffvklhBCKdalUKowZMwYrV65E7dq1YWJiIg/vi4iIwPDhw1G1alWYmJigdu3a+PXXX3PE9/3336N27dowNzdHlSpV0KhRI6xatSpf+56VlYVPPvkEzs7OsLCwQM+ePXHv3j25fcaMGTAyMpI/ZLN7++23YWtrKw8hLYh27doBgDwsNL/Ho5eXF7p3744dO3agUaNGMDMzk1/n/Jwf09LSMGPGDPj6+srnrYkTJyItLU2xHe3rsmnTJrz00kvy85996OXMmTMxYcIEAIC3t7d87GrH9y9btgzt2rWDk5MTTExMEBAQgEWLFuV4LjQaDWbOnAlXV1eYm5ujbdu2uHr1aq7XFcTGxmLcuHHyceXr64vPPvsMGo1GMd/q1asRGBgIKysrWFtbo06dOvj2229f+Lq86LjVfk7s27cPV65ckfc5r55wLy8vXLlyBQcOHJDn1Z5PtNdDHDhwAKNHj4aTkxPc3d0BSOeY0aNHw8/PD2ZmZrC3t0e/fv1yXDuR2+eZ9pqW5513su9Lbp95ERER6NWrFywtLeHo6IiPPvoIWVlZiuWjo6Px+uuvw9raGra2thg6dCguXLiQ76HTV65cQbt27WBmZgZ3d3fMnTs3x+sIAH///Te6desGV1dXmJiYwMfHB3PmzFHE06ZNG2zZsgV37tyRn2cvLy8AQHp6OqZPn47AwEDY2NjAwsICrVq1wr59+14Yo0qlwrJly5CUlJTj3Kz9ccnHxwcmJibw8vLCJ598kuO99Lz37POcOXMGzZs3h5mZGby9vbF48eIc8xT0/Zz9PLt48WI4OjoCAGbNmiXv38yZM58bV37OM8+6ePEihg0bhurVq8PU1BTOzs4YPnw4oqOjFfMlJCRg3Lhx8rqdnJzQsWNHnD17Vp4nLCwMffr0gbOzM0xNTeHu7o6BAwciLi5Onif7uWPmzJnw9PQEAEyYMEFxbOR1TdK2bdvQqlUrWFhYwMrKCt26dcOVK1cU8zzv+2F5x56kMmblypXo3bs3jI2NMWjQICxatAinTp1S9C4kJiaiVatWuHbtGoYPH46GDRsiKioKmzdvxv379+Hg4ICsrCx0794de/bswcCBAzF27FgkJCRg165duHz5Mnx8fAocW2ZmJoKDg9GyZUt8+eWXMDc3BwCsW7cOycnJGDVqFOzt7XHy5El8//33uH//PtatWycvf/HiRbRq1QpGRkZ4++234eXlhZs3b+Kff/7BvHnz0KZNG3h4eGDlypV45ZVXcjwvPj4+z/2l+datW9i0aRP69esHb29vPHr0CD/99BOCgoJw9epVuLq6Kub/9NNPoVar8dFHHyEuLg6ff/45Xn31VZw4cUKe55dffsHIkSPRvHlzjBs3Drdu3ULPnj1hZ2cHDw+PfD1vGRkZOU6a5ubm8vNXVC1btsShQ4dw+/Zt+YR35MgRvPXWW2jcuDFmzJiB2NhY2NraQgiBo0ePolmzZnIX/MiRI7F8+XK88cYbeP/99xEeHo4ffvgB586dw5EjR/IcgpKUlIR27dohMjISY8eOhbOzM1atWpXnB25MTAw6d+6M3r17o3///li/fj0+/vhj1KlTB126dEGtWrUwe/ZsTJ8+HW+//TZatWoFAGjevDkAaahHly5dEBgYiBkzZkCtVstfPg8dOoTGjRsDAC5duoROnTrB0dERM2fORGZmJmbMmIGqVau+8Ll0cnKCmZkZ/vnnH7z33nuws7PLc978vMeEEOjZsyf27duHN998E/Xr18eOHTswYcIERERE5BiitHfvXqxduxZjxoyBg4MDvLy88OjRIzRt2lT+cHd0dMS2bdvw5ptvIj4+Xh5Ss3TpUrz//vvo27cvxo4di9TUVFy8eBEnTpzI1/Vn8+bNg0qlwscff4zHjx9j4cKF6NChA86fPw8zMzO8/vrrmD17NtasWaMYppGeno7169ejT58+hfo1XptQ2tvbAyjY8RgaGopBgwZh5MiRGDFiBPz8/PJ1ftRoNOjZsycOHz6Mt99+G7Vq1cKlS5fwzTff4Pr169i0aZMixsOHD2Pjxo0YPXo0rKys8N1336FPnz64e/cu7O3t0bt3b1y/fh1//vknvvnmG7mnTPvFa9GiRahduzZ69uwJQ0ND/PPPPxg9ejQ0Gg3effddeTuTJ0/G559/jh49eiA4OBgXLlxAcHBwjuQzOTkZQUFBiIiIwMiRI1GtWjUcPXoUkydPRmRkpHw9yq5duzBo0CC0b98en332GQDg2rVrOHLkCMaOHZvna5Kf49bR0RErVqzAvHnzkJiYiAULFgAAatWqles6Fy5ciPfeew+WlpbyD2PPvidHjx4NR0dHTJ8+HUlJSQCk4cFHjx7FwIED4e7ujtu3b2PRokVo06YNrl69+sLz6IvOO8+TlZWF4OBgNGnSBF9++SV2796Nr776Cj4+Phg1ahQAKbHt0aMHTp48iVGjRsHf3x9///03hg4d+tx1az18+BBt27ZFZmYmJk2aBAsLCyxZsiTX3pXly5fD0tISH3zwASwtLbF3715Mnz4d8fHx+OKLLwAAU6ZMQVxcHO7fvy+fXywtLQEA8fHx+PnnnzFo0CCMGDECCQkJ+OWXXxAcHIyTJ08+d4jzihUrsGTJEpw8eRI///wzAN25+a233sJvv/2Gvn374sMPP8SJEyewYMECXLt2LcePnrm9Z58nJiYGXbt2Rf/+/TFo0CCsXbsWo0aNgrGxMYYPHw4ABX4/P3uerVevHhYtWoRRo0bhlVdeQe/evQEAdevWzTOu/JxncrNr1y7cunULb7zxBpydnXHlyhUsWbIEV65cwfHjx+Uhx++88w7Wr1+PMWPGICAgANHR0Th8+DCuXbuGhg0bIj09HcHBwUhLS8N7770HZ2dnRERE4N9//0VsbCxsbGxybLt3796wtbXF+PHjMWjQIHTt2lU+NnKzYsUKDB06FMHBwfjss8+QnJyMRYsWoWXLljh37pz8fQPI+/thuSeozDh9+rQAIHbt2iWEEEKj0Qh3d3cxduxYxXzTp08XAMTGjRtzrEOj0QghhPj1118FAPH111/nOc++ffsEALFv3z5Fe3h4uAAgli1bJk8bOnSoACAmTZqUY33Jyck5pi1YsECoVCpx584deVrr1q2FlZWVYlr2eIQQYvLkycLExETExsbK0x4/fiwMDQ3FjBkzcmwnu9TUVJGVlZVjX0xMTMTs2bPladr9rlWrlkhLS5Onf/vttwKAuHTpkhBCiPT0dOHk5CTq16+vmG/JkiUCgAgKCnpuPEII4enpKQDk+JfXvpw6dSrHc/8iW7ZsEQDEihUrhBBCREZGCgDiwIEDIiEhQRgYGIgtW7YIIYS4fPmyACDmzZsnhBDi0KFDAoBYuXKlYp3bt2/PMT0oKEixz1999ZUAIDZt2iRPS0lJEf7+/jmOq6CgIAFA/P777/K0tLQ04ezsLPr06fPC/ddoNKJGjRoiODhYcbwkJycLb29v0bFjR3lar169hKmpqeI4u3r1qjAwMBD5OeVp318WFhaiS5cuYt68eeLMmTM55svPe2zTpk0CgJg7d66ivW/fvkKlUokbN27I0wAItVotrly5opj3zTffFC4uLiIqKkoxfeDAgcLGxkZ+//3vf/8TtWvXfuH+PUv7fnBzcxPx8fHy9LVr1woA4ttvv5WnNWvWTDRp0kSx/MaNG3M9jzxrxowZAoAIDQ0VT548EeHh4eKnn34SJiYmomrVqiIpKalAx6P2vbV9+3bFvPk5P65YsUKo1Wpx6NAhRfvixYsFAHHkyBF5GgBhbGyseK0uXLggAIjvv/9envbFF18IACI8PDzHdnM7RwYHB4vq1avLfz98+FAYGhqKXr16KeabOXOmACCGDh0qT5szZ46wsLAQ169fV8w7adIkYWBgIO7evSuEEGLs2LHC2tpaZGZm5tj+8xTkuA0KCsr3cVe7du1cz5vLli0TAETLli1zxJrbc3fs2LEc55PcPs/ye9553mde9s8OIYRo0KCBCAwMlP/esGGDACAWLlwoT8vKyhLt2rXL17l83LhxAoA4ceKEPO3x48fCxsYmx/GU23MxcuRIYW5uLlJTU+Vp3bp1E56enjnmzczMVHyWCSFETEyMqFq1qhg+fPhz4xRCek4sLCwU086fPy8AiLfeeksx/aOPPhIAxN69e+Vpeb1n86J9/b766it5Wlpamqhfv75wcnIS6enpQoiCv59zO88+efLkuZ/Nz8rPeSa34yq31/DPP/8UAMTBgwflaTY2NuLdd9/Nc/vnzp0TAMS6deueG6enp6fi3KGN6YsvvlDMp30Pao+3hIQEYWtrK0aMGKGY7+HDh8LGxkYx/XnfD8s7DrcrQ1auXImqVauibdu2AKRu4QEDBmD16tWK7vQNGzagXr16OXpbtMto53FwcFBcp/LsPIWh/fUsu+y/eCUlJSEqKgrNmzeHEEKuuvbkyRMcPHgQw4cPR7Vq1fKMZ8iQIUhLS1OUI16zZg0yMzOfe10PIA1b0/aOZGVlITo6GpaWlvDz81N0UWu98cYbirHV2p6LW7duAQBOnz6Nx48f45133lHMN2zYsFx/pclLkyZNsGvXLsW/IUOG5Hv5F2nevDnUarV8rZH21/aXX34ZlpaWqFu3rjwkTfu/9nqkdevWwcbGBh07dkRUVJT8LzAwEJaWls8dhrF9+3a4ubmhZ8+e8jRTU1OMGDEi1/ktLS0Vr6GxsTEaN24sP9/Pc/78eYSFhWHw4MGIjo6W40xKSkL79u1x8OBBaDQaZGVlYceOHejVq5fiOKtVqxaCg4NfuB1AGm6xatUqNGjQADt27MCUKVMQGBiIhg0b4tq1a/J8+XmPbd26FQYGBnj//fcV7R9++CGEENi2bZtielBQEAICAuS/hRDYsGEDevToASGE4jUKDg5GXFycfGzb2tri/v37OHXqVL7281lDhgyBlZWV/Hffvn3h4uKCrVu3KuY5ceKEYjjhypUr4eHhgaCgoHxtx8/PD46OjvD29sbIkSPh6+uLLVu2wNzcvMDHo7e3d47XNT/nx3Xr1qFWrVrw9/dXbEc79O/Z7XTo0EHR+163bl1YW1vn69gFlOfIuLg4REVFISgoCLdu3ZKHxuzZsweZmZkYPXq0Ytncjq9169ahVatWqFKliiL+Dh06ICsrCwcPHgQgHRNJSUnYtWtXvuLUKuhxW1xGjBiR47qI7M9dRkYGoqOj4evrC1tb21zP688qynkHkH7Rz65Vq1aKZbdv3w4jIyPFeU+tVit6CJ9n69ataNq0qdwTDkg9kLkNV8r+XCQkJCAqKgqtWrVCcnIyQkJCXrgtAwMD+bNMo9Hg6dOnyMzMRKNGjfL1XOYVPwB88MEHiunaYkVbtmxRTM/tPfs8hoaGGDlypPy3sbExRo4cicePH+PMmTMACv5+fvY8Wxj5Oc/kJvtrmJqaiqioKDRt2hQAFK+Bra0tTpw4gQcPHuS6Hu13kB07diA5OblQ+/A8u3btQmxsLAYNGqR4Tg0MDNCkSZNcvxvk9v2wvONwuzIiKysLq1evRtu2bRUlm5s0aYKvvvoKe/bsQadOnQBIw1P69Onz3PXdvHkTfn5+MDQsvpfY0NBQHiee3d27dzF9+nRs3rw5x3UD2i8A2g+VF93zwN/fHy+//DJWrlyJN998E4D0Jaxp06YvrPKn0Wjw7bff4scff0R4eLgisdQO5cnu2WStSpUqACDvw507dwAANWrUUMxnZGSE6tWrPzeW7BwcHNChQ4d8z19Qtra2qF27tiIRatCggXwybt68uaJN+yUBkMY0x8XF5bjWRut5hQru3LkDHx+fHB8Ieb1O7u7uOeatUqUKLl68+MJ9DAsLA4DnDmGJi4tDWloaUlJScrxmgPTlPPsX/ucZNGgQBg0ahPj4eJw4cQLLly/HqlWr0KNHD1y+fBmmpqb5eo/duXMHrq6uiuQD0A1J0h5jWtmrEALSjwuxsbFYsmQJlixZkus2tK/Rxx9/jN27d6Nx48bw9fVFp06dMHjw4Dyvr3rWs8+ZSqWCr6+vYoz6gAEDMG7cOKxcuRLTp09HXFwc/v33X4wfPz7fP75s2LAB1tbWMDIygru7uyL5KOjx+OzzBeTv/BgWFoZr167Jw+FetJ1nzxWAdOw+e77Ly5EjRzBjxgwcO3YsxxeauLg42NjYyMfCs+8fOzs7+dyUPf6LFy++MP7Ro0dj7dq16NKlC9zc3NCpUyf079//hRUaC3rcFpfcXs+UlBQsWLAAy5YtQ0REhOJavuzXXuSlKOcdU1PTHM/xs6/7nTt34OLikmN4UX6r0t65cyfX233kNgztypUrmDp1Kvbu3ZujbH5+ngsA+O233/DVV18hJCQEGRkZ8vTcnvv8uHPnDtRqdY79dXZ2hq2t7QvPcS/i6uqaowBAzZo1AUjXkjVt2rTA7+fC7mt2+TnP5Obp06eYNWsWVq9enSOu7K/h559/jqFDh8LDwwOBgYHo2rUrhgwZIn/38Pb2xgcffICvv/4aK1euRKtWrdCzZ0+89tprBfoRNy/az1xtovksa2trxd95fT8s75gklRF79+5FZGQkVq9ejdWrV+doX7lypZwkFZe8vtQ8e1GqVvaemuzzduzYEU+fPsXHH38Mf39/WFhYICIiAsOGDcv14tMXGTJkCMaOHYv79+8jLS0Nx48fxw8//PDC5ebPn49p06Zh+PDhmDNnDuzs7KBWqzFu3Lhc48irkkv2D+HyomXLlli8eDFiY2Nx5MgReaw4ICVJv/76KzIyMnD48GEEBgbK145oNBo4OTnlWSAkrw+dwijK8619/b744os8x81bWlrmuEi3qKytrdGxY0d07NgRRkZG+O2333DixIl895oU1LPXIWj3+7XXXsszQdSOm69VqxZCQ0Px77//Yvv27diwYQN+/PFHTJ8+XS5tW1RVqlRB9+7d5SRp/fr1SEtLe2Evb3atW7fOc7x+QY/HwlbF0mg0qFOnDr7++utc25+93rAox+7NmzfRvn17+Pv74+uvv4aHhweMjY2xdetWfPPNN4U6R2o0GnTs2BETJ07MtV37JdLJyQnnz5/Hjh07sG3bNmzbtg3Lli3DkCFD8NtvvxV4uyUtt9fzvffew7JlyzBu3Dg0a9ZMvgHmwIED8/XcFeW1K85qX0UVGxuLoKAgWFtbY/bs2fDx8YGpqSnOnj2Ljz/+OF/PxR9//IFhw4ahV69emDBhApycnGBgYIAFCxYoeocLI78/kpREJbuCvp/1WU2vf//+OHr0KCZMmID69evD0tISGo0GnTt3VryG/fv3R6tWrfDXX39h586d+OKLL/DZZ59h48aN8rV0X331FYYNG4a///4bO3fuxPvvv48FCxbg+PHjRU5YtLGsWLEi18JSz/44mNv3w4qASVIZsXLlSjg5OeH//u//crRt3LgRf/31FxYvXgwzMzP4+Pjg8uXLz12fj48PTpw4gYyMjDwvvNf+OvnszQ8L8ivhpUuXcP36dfz222+KIWTPDu/Q/vrxorgBYODAgfjggw/w559/yveuGDBgwAuXW79+Pdq2bYtffvlFMT02NjbPL2XPo60CExYWpvg1JSMjA+Hh4ahXr16B11lSWrZsiUWLFmH37t04d+6cXGkLkJKklJQUbNmyBbdu3VL8+uXj44Pdu3ejRYsWBf7g8PT0xNWrVyGEUHxA5lYhML/y+qDV9jZYW1s/t1dOWzVR+ytYdqGhoYWOC5DKrf/222+IjIyUY3rRe8zT0xO7d+9GQkKC4ld57dAY7TGWF0dHR1hZWSErKytfvZEWFhYYMGAABgwYgPT0dPTu3Rvz5s3D5MmTX1hU4dnnTAiBGzdu5Lh4eciQIfjf//6HU6dOYeXKlWjQoAFq1679wtjyoyjHY/Z15Of8eOHCBbRv377Y7s2U13r++ecfpKWlYfPmzYoeqWeHq2iPhRs3bih+6Y6Ojs7RY+Xj44PExMR8HRPGxsbo0aMHevToAY1Gg9GjR+Onn37CtGnT8uztKOpxm5fCPNfr16/H0KFD8dVXX8nTUlNTy8xNez09PbFv3z4kJycrepPyex709PTM1/lq//79iI6OxsaNG9G6dWt5+rM3Cwfyfp7Xr1+P6tWrY+PGjYp5inKbEU9PT2g0GoSFhSmKdjx69AixsbGFPla0Hjx4kKOc9PXr1wFALhxQHO/ngi6Xn/PMs2JiYrBnzx7MmjUL06dPl6fn9voD0u1BRo8ejdGjR+Px48do2LAh5s2bpyg4UqdOHdSpUwdTp07F0aNH0aJFCyxevBhz584tUGzP0n7mOjk5lehImLKu4qV95VBKSgo2btyI7t27o2/fvjn+jRkzBgkJCdi8eTMAoE+fPrhw4UKupbK1v4716dMHUVFRufbAaOfx9PSEgYGBPH5d68cff8x37Npf2rL/KieEyFFi1tHREa1bt8avv/6Ku3fv5hqPloODA7p06YI//vgDK1euROfOnfOV5BgYGORY17p16xAREZHv/cmuUaNGcHR0xOLFixX3UVi+fHmZ+YDW0l5j9PXXXyMjI0PRk+Tl5QUXFxe57G32+yP1798fWVlZmDNnTo51ZmZmPnc/g4ODERERIR+XgPTlZenSpYXeD+0H4bPbDQwMhI+PD7788kskJibmWE5bltrAwADBwcHYtGmT4ji7du0aduzY8cLtJycn51lmXnsdhnYYTH7eY127dkVWVlaOeb755huoVKoXVtcyMDBAnz59sGHDhlw/kLOX4362hKyxsTECAgIghFAMq8nL77//joSEBPnv9evXIzIyMkeMXbp0gYODAz777DMcOHCgQL1IL1KU41ErP+fH/v37IyIiItdjNSUlRa6sVhB5Hbu5nSPj4uKwbNkyxXzt27eHoaFhjtLguR1f/fv3x7Fjx3I9pmNjY5GZmQkg5zGhVqvlpPd5va5FPW7zYmFhUeBzZ27n9e+//z7PEQ+lLTg4GBkZGYpjSaPR5PqDZ266du2K48eP4+TJk/K0J0+e5OhNze04Sk9Pz/Xz2sLCItfhd7mt48SJE8+9tUZ+4gcgV1TU0vbqdOvWrdDrBqT3ffYy4enp6fjpp5/g6OiIwMBAAMXzftYmuPk9PvNznnlWbs8/kPO5y8rKyvH6OTk5wdXVVX7fxsfHy+9zrTp16kCtVhfLiIrg4GBYW1tj/vz5uX5+5HYriIqIPUllwObNm5GQkKC4AD67pk2bwtHREStXrsSAAQMwYcIErF+/Hv369cPw4cMRGBiIp0+fYvPmzVi8eDHq1auHIUOG4Pfff8cHH3yAkydPolWrVkhKSsLu3bsxevRo/O9//4ONjQ369euH77//HiqVCj4+Pvj3338LdMNMf39/+Pj44KOPPkJERASsra2xYcOGXMfqf/fdd2jZsiUaNmyIt99+G97e3rh9+za2bNmC8+fPK+YdMmQI+vbtCwC5fmHKTffu3TF79my88cYbaN68OS5duoSVK1cW6Pqh7IyMjDB37lyMHDkS7dq1w4ABAxAeHo5ly5YVep15+eGHHxAbGytfpPnPP//g/v37AKThJi8aY1ytWjV4eHjg2LFj8PLyylHuvHnz5tiwYQNUKpXiGpWgoCCMHDkSCxYswPnz59GpUycYGRkhLCwM69atw7fffiu/Ds8aOXIkfvjhBwwaNAhjx46Fi4sLVq5cKfdYFOYXPR8fH9ja2mLx4sWwsrKChYUFmjRpAm9vb/z888/o0qULateujTfeeANubm6IiIjAvn37YG1tjX/++QeAVHhh+/btaNWqFUaPHo3MzEz5/kEvug4hOTkZzZs3R9OmTdG5c2d4eHggNjYWmzZtwqFDh9CrVy80aNAAAPL1HuvRowfatm2LKVOm4Pbt26hXrx527tyJv//+G+PGjctXKf5PP/0U+/btQ5MmTTBixAgEBATg6dOnOHv2LHbv3o2nT58CADp16gRnZ2e0aNECVatWxbVr1/DDDz+gW7duOa4tyY2dnR1atmyJN954A48ePcLChQvh6+uboxCHkZERBg4ciB9++AEGBgYYNGjQC9edX0U5HrXyc358/fXXsXbtWrzzzjvYt28fWrRogaysLISEhGDt2rXyfVwKQvuFbcqUKRg4cCCMjIzQo0cPdOrUSe7NGTlyJBITE7F06VI4OTnJvZKAVA577Nix+Oqrr9CzZ0907twZFy5cwLZt2+Dg4KB4P02YMAGbN29G9+7dMWzYMAQGBiIpKQmXLl3C+vXrcfv2bTg4OOCtt97C06dP0a5dO7i7u+POnTv4/vvvUb9+/TxLdQMoluM2r+do0aJFmDt3Lnx9feHk5JTnNQ9a3bt3x4oVK2BjY4OAgAAcO3YMu3fvzvU6U33o1asXGjdujA8//BA3btyAv78/Nm/eLL8vX3QenDhxIlasWIHOnTtj7NixcglwT09PxfmqefPmqFKlCoYOHYr3338fKpUKK1asyPULeWBgINasWYMPPvhALuDTo0cPdO/eHRs3bsQrr7yCbt26ITw8HIsXL0ZAQECuPz7lR7169TB06FAsWbJEHhJ48uRJ/Pbbb+jVq5dciKqwXF1d8dlnn+H27duoWbMm1qxZg/Pnz2PJkiVyD35xvJ/NzMwQEBCANWvWoGbNmrCzs8NLL72U53XU+TnPPMva2hqtW7fG559/joyMDLi5uWHnzp05egMTEhLg7u6Ovn37ol69erC0tMTu3btx6tQpuUd17969GDNmDPr164eaNWsiMzMTK1askH9YKypra2ssWrQIr7/+Oho2bIiBAwfC0dERd+/exZYtW9CiRYt8XQZR7pVOET16nh49eghTU1ORlJSU5zzDhg0TRkZGchng6OhoMWbMGOHm5iaMjY2Fu7u7GDp0qKJMcHJyspgyZYrw9vYWRkZGwtnZWfTt21fcvHlTnufJkyeiT58+wtzcXFSpUkWMHDlSLhP9bDnUZ0t/al29elV06NBBWFpaCgcHBzFixAi5RO6z5U8vX74sXnnlFWFraytMTU2Fn5+fmDZtWo51pqWliSpVqggbGxuRkpKSn6dRpKamig8//FC4uLgIMzMz0aJFC3Hs2LEcpau1pWKfLZ2ZW7lOIYT48ccfhbe3tzAxMRGNGjUSBw8ezLHOvHh6eopu3brlaz7kUioceZQUzs2gQYMEADF48OAcbV9//bVc9jw3S5YsEYGBgcLMzExYWVmJOnXqiIkTJ4oHDx7I8+S2z7du3RLdunUTZmZmwtHRUXz44YdySdzjx48rls2tTPDQoUNzlKr9+++/RUBAgDA0NMzxepw7d0707t1b2NvbCxMTE+Hp6Sn69+8v9uzZo1jHgQMHRGBgoDA2NhbVq1cXixcvlktQP09GRoZYunSp6NWrl/D09BQmJibC3NxcNGjQQHzxxRc5yufm5z2WkJAgxo8fL1xdXYWRkZGoUaOG+OKLLxSlzIWQStPmVfL10aNH4t133xUeHh7ydtq3by+WLFkiz/PTTz+J1q1by8+Nj4+PmDBhgoiLi3vuPmvfD3/++aeYPHmycHJyEmZmZqJbt245yvVrnTx5UgAQnTp1eu66s9M+/0+ePHnhvPk5Hp/33srP+TE9PV189tlnonbt2sLExERUqVJFBAYGilmzZimes7xel2dL6wohleZ2c3MTarVa8d7dvHmzqFu3rjA1NRVeXl7is88+k0vIZ39/Z2ZmimnTpglnZ2dhZmYm2rVrJ65duybs7e3FO++8o9hWQkKCmDx5svD19RXGxsbCwcFBNG/eXHz55ZdyaeT169eLTp06CScnJ2FsbCyqVasmRo4cKSIjI1/4GuT3uC1ICfCHDx+Kbt26CSsrK4Fst1HQlh8+depUjmViYmLEG2+8IRwcHISlpaUIDg4WISEhOZ7/vEqA5+e8k1cJ8Nw+83I7jzx58kQMHjxYWFlZCRsbGzFs2DBx5MgRAUCsXr36hc/LxYsXRVBQkDA1NRVubm5izpw54pdffslxfBw5ckQ0bdpUmJmZCVdXVzFx4kSxY8eOHPudmJgoBg8eLGxtbQUAeV81Go2YP3++fG5r0KCB+Pfff3M9D+cmr+ckIyNDzJo1Sz4Penh4iMmTJyvKkguR/89DLe3rd/r0adGsWTNhamoqPD09xQ8//JBj3qK+n4UQ4ujRo/LnBvJRDvxF55ncjqv79+/L34FsbGxEv379xIMHDxTbS0tLExMmTBD16tUTVlZWwsLCQtSrV0/8+OOP8npu3bolhg8fLnx8fISpqamws7MTbdu2Fbt371bEWNgS4Fr79u0TwcHBwsbGRpiamgofHx8xbNgwcfr0aXme530/LO9UQpTDq9SpwsvMzISrqyt69OiR4xojKtsWLlyI8ePH4/79+3Bzc9N3OFQCLly4gPr16+P333/H66+/ru9wKrTY2FhUqVIFc+fOlW/CSmXfpk2b8Morr+Dw4cP5rjBJRGULr0miMmnTpk148uRJsd5PiIpfSkqK4u/U1FT89NNPqFGjBhOkCmzp0qWwtLSU70xPxePZ9xOgu16hTZs2pRsM5duzr1tWVha+//57WFtbo2HDhnqKioiKitckUZly4sQJXLx4EXPmzEGDBg1KrNQyFY/evXujWrVqqF+/PuLi4vDHH38gJCQkzxLOVL79888/uHr1KpYsWYIxY8bkuH8JFc2aNWuwfPlydO3aFZaWljh8+DD+/PNPdOrUib0RZdh7772HlJQUNGvWDGlpadi4cSOOHj2K+fPn67XcNBEVDYfbUZkybNgw/PHHH6hfvz6WL1/+wpvPkn4tXLgQP//8M27fvo2srCwEBARg4sSJ+SrZTuWPl5cXHj16hODgYKxYsSJfBSEo/86ePYuJEyfi/PnziI+PR9WqVdGnTx/MnTsXlpaW+g6P8rBq1Sp89dVXuHHjBlJTU+Hr64tRo0ZhzJgx+g6NiIqASRIREREREVE2vCaJiIiIiIgoGyZJRERERERE2VT4wg0ajQYPHjyAlZVVoW5uSUREREREFYMQAgkJCXB1dYVanXd/UYVPkh48eAAPDw99h0FERERERGXEvXv34O7unmd7hU+StNWX7t27B2tr62JZZ0ZGBnbu3IlOnTrByMioWNZJlQePHyosHjtUFDx+qCh4/FBRlKXjJz4+Hh4eHi+s0FrhkyTtEDtra+tiTZLMzc1hbW2t9xeayh8eP1RYPHaoKHj8UFHw+KGiKIvHz4suw2HhBiIiIiIiomyYJBEREREREWXDJImIiIiIiCibCn9NUn4IIZCZmYmsrKx8zZ+RkQFDQ0OkpqbmexkqfwwMDGBoaMjS8URERESVTKVPktLT0xEZGYnk5OR8LyOEgLOzM+7du8cv0BWcubk5XFxcYGxsrO9QiIiIiKiUVOokSaPRIDw8HAYGBnB1dYWxsXG+kh6NRoPExERYWlo+9yZUVH4JIZCeno4nT54gPDwcNWrU4GtNREREVElU6iQpPT0dGo0GHh4eMDc3z/dyGo0G6enpMDU15RfnCszMzAxGRka4c+eO/HoTERERUcXHb/gAEx3KE48NIiIiosqH3wCJiIiIiIiyYZJERERERESUDZMkIiIiIiKibJgkFZPTp4F27aT/S8uxY8dgYGCAbt26ld5GiYiIiIgqOCZJxeT334F9+4AVK0pvm7/88gvee+89HDx4EA8ePCi9DT8jPT1db9smIiIiIipuek+SIiIi8Nprr8He3h5mZmaoU6cOTv/XHZORkYGPP/4YderUgYWFBVxdXTFkyJASSwiEAJKS8v/v2jXg8GHgyBFg9WppHX/+Kf19+LDUnt91CVGwWBMTE7FmzRqMGjUK3bp1w/LlyxXt//zzD15++WWYmprCwcEBr7zyityWlpaGjz/+GB4eHjAxMYGvry9++eUXAMDy5ctha2urWNemTZsU94+aOXMm6tevj59//hne3t5yaezt27ejZcuWsLW1hb29Pbp3746bN28q1nX//n0MGjQIdnZ2sLCwQKNGjXDixAncvn0barVafu21Fi5cCE9PT2g0moI9QUREREREhaTX+yTFxMSgRYsWaNu2LbZt2wZHR0eEhYWhSpUqAIDk5GScPXsW06ZNQ7169RATE4OxY8eiZ8+eOb5MF4fkZMDSMj9zqgHY5try5AnQsmXBt52YCFhY5H/+tWvXwt/fH35+fnjttdcwbtw4TJ48GSqVClu2bMErr7yCKVOm4Pfff0d6ejq2bt0qLztkyBAcO3YM3333HerVq4fw8HBERUUVKN4bN25gw4YN2LhxIwwMDAAASUlJ+OCDD1C3bl0kJiZi+vTpeOWVV3D+/Hmo1WokJiYiKCgIbm5u2Lx5M5ydnXH27FloNBp4eXmhQ4cOWLZsGRo1aiRvZ9myZRg2bBhLcRMRERFRqdFrkvTZZ5/Bw8MDy5Ytk6d5e3vLj21sbLBr1y7FMj/88AMaN26Mu3fvolq1aqUWa1nzyy+/4LXXXgMAdO7cGXFxcThw4ADatGmDefPmYeDAgZg1a5Y8f7169QAA169fx9q1a7Fr1y506NABAFC9evUCbz89PR2///47HB0d5Wl9+vRRzPPrr7/C0dERV69exUsvvYRVq1bhyZMnOHXqFOzs7AAAvr6+8vxvvfUW3nnnHXz99dcwMTHB2bNncenSJfz9998Fjo+IiIiIqLD0miRt3rwZwcHB6NevHw4cOAA3NzeMHj0aI0aMyHOZuLg4qFSqHEPCtNLS0pCWlib/HR8fD0AaupeRkaGYNyMjA0IIaDQaaDQamJoC/83+XEIIJCQkwMrKChcuqNC6dc5ejoMHNahf/8Xr0jI1BfI7oiw0NBQnT57Ehg0boNFooFar0b9/f/z8889o3bo1zp8/jzfffDPXIWpnz56FgYEBWrVqlWu7dlr2tmenCSHg6ekJe3t7xXxhYWGYMWMGTp48iaioKLnt9u3bCAgIwLlz59CgQQPY2trmuu2ePXvi3XffxYYNGzBw4EAsW7YMbdu2RbVq1fQ23E6j0UAIgYyMDLnHrKi0x+GzxyPRi/DYoaLg8UNFweOHiqIsHT/5jUGvSdKtW7ewaNEifPDBB/jkk09w6tQpvP/++zA2NsbQoUNzzJ+amoqPP/4YgwYNgrW1da7rXLBggaIHRWvnzp0wNzdXTDM0NISzszMSExMLXHzAwgLQaBKg0RgAsIJKJSCESv5fo0lCVlZWvteXkJD/bS9atAiZmZlwd3eXpwkhYGJignnz5sHU1BSpqalygpid+O/ip/j4eBgZGeVoT09Ph0ajUSyrfaz9Py0tDaampjnW36NHD3h4eOCbb76Bs7MzNBoNmjdvjri4OMTHx8PAwACZmZm5xqU1YMAA/PLLL+jQoQNWrVqFBQsWPHf+kpaeno6UlBQcPHgQmZmZxbruZ3tJifKLxw4VBY8fKgoeP1QUZeH4SU5Oztd8ek2SNBoNGjVqhPnz5wMAGjRogMuXL2Px4sU5kqSMjAz0798fQggsWrQoz3VOnjwZH3zwgfx3fHw8PDw80KlTpxyJVWpqKu7duwdLS0u5+EB+ZO9J8vZWoWpVAQ8PYPhwDX79VYV79wS8vS2QRx5XJJmZmVi7di2+/PJLdOzYUdHWu3dvbNmyBfXq1cPRo0cxatSoHMs3adIEGo0G586dk4fbZefh4YHExEQYGBjA4r+LpK5fvw4A8vNnYmICAwMDxfMZHR2NsLAwLF26FK1atQIAHD58GABgZmYGa2trBAYGYsWKFcjMzJSH2z1r1KhRqFu3LlauXImsrCy8+uqrMDMzK+jTVGxSU1NhZmaG1q1bF+gYeZ6MjAzs2rULHTt2zDVRJcoLjx0qCh4/VBQ8fqgoytLxk98f3/WaJLm4uCAgIEAxrVatWtiwYYNimjZBunPnDvbu3ZtnLxIgfYE3MTHJMd3IyCjHi5KVlQWVSgW1Wl2gwgDaoV8qlQrVqqlx5w5gbCz9/c47QHo6YGKiesFaCmfr1q2IiYnBW2+9BRsbG0Vbnz59sGzZMnzxxRdo3749fH19MXDgQGRmZmLr1q34+OOPUb16dQwdOhRvvfWWXLjhzp07ePz4Mfr3749mzZrB3NwcU6dOxfvvv48TJ07gt99+AwD5OdJWusv+nNnb28Pe3h4///wz3NzccPfuXUyaNEmeT61W49VXX8Wnn36K3r17Y8GCBXBxccG5c+fg6uqKZs2aAQBq166Npk2bYtKkSRg+fLicqOmLWq2GSqXK9fgpqpJYJ1UOPHaoKHj8UFHw+KGiKAvHT363r9eSYS1atEBoaKhi2vXr1+Hp6Sn/rU2QwsLCsHv3btjb25d2mC9kYgJoK2SrVNLfJUU7FO3ZBAmQkqTTp0/Dzs4O69atw+bNm1G/fn20a9cOJ0+elOdbtGgR+vbti9GjR8Pf3x8jRoxAUlISAMDOzg5//PEHtm7dijp16uDPP//EzJkzXxiXWq3G6tWrcebMGbz00ksYP348vvjiC8U8xsbG2LlzJ5ycnNC1a1fUqVMHn376aY5rfd58802kp6dj+PDhhXiGiIiIiIiKRiVEQe/QU3xOnTqF5s2bY9asWejfvz9OnjyJESNGYMmSJXj11VeRkZGBvn374uzZs/j3339RtWpVeVk7OzsYGxu/cBvx8fGwsbFBXFxcrsPtwsPDFff6yQ/tNTvW1tYsTV0C5syZg3Xr1uHixYv6DqXQx8jzZGRkYOvWrejatavef02h8oXHDhUFjx8qCh4/VBTHj2fi7bdjsGRJFTRtqteBbM/NDbLT6zf8l19+GX/99Rf+/PNPvPTSS5gzZw4WLlyIV199FYB0o9nNmzfj/v37qF+/PlxcXOR/R48e1WfoVAISExNx+fJl/PDDD3jvvff0HQ4RERERFYM//lDh0iVHrFxZMpejlAT9pnIAunfvju7du+fa5uXlBT12dFEpGzNmDP7880/06tWLQ+2IiIiIyrE7d4CoKCApCVixQuqXWbNGjTfeAIQAHByAbFfYlDl6T5KItJYvX47ly5frOwwiIiIiKiQhgEuXgHr1sk+VepCiooDAQOW8ZRWTJCIiIiIiKrS4OGDXLmD7dulfRETu8wkhJUuGhkBZ/12cSRIREREREeWbEMD581JCtG0bcPQokJWlazczA9q1A2rXBj7/POfyJ04ADRuWWriFwiSJiIiIiIieKyZG6i3atk1Kjh4+VLb7+QFdukj/WrcGTE2Bs2elJEmtFtBoVPL/5QGTJCIiIiIiUtBogHPnpKRo2zbg+HFpmpaFhdRb1KUL0Lkz4O2dcx1OToCzM+DmJtC48QWcPFkXEREqODmV3n4UFpMkIiIiIiJCdDSwc6eUFO3YATx+rGwPCND1FrVsCZiYPH997u7A7duASpWFbdvuYOHC2hBC/cLlygImSURERERElZBGA5w+rRtCd/KksrfI0hLo0EHXW1StWsG3YWICZGRIj1UqwNi4eGIvaUySqESpVCr89ddf6NWrV77m379/P9q2bYuYmBjY2tqWaGwAMHPmTGzatAnnz58v8W0RERER6duTJ1Iv0fbt0v9RUcr2OnV0SVGLFuUnqSluan0HUFHsvrUbAf8XgN23dpf4toYNGwaVSpXj340bNwAABw8eRI8ePeDq6gqVSoVNmzY9d30hISFQqVQ4fvy4YnrTpk1hamqK1NRUeVpqaipMTU3xyy+/5CvWyMhIdOnSpWA7+AIzZ85E/fr1i3WdRERERBVRVhZw7BgwYwbQuDFQtSrw+uvAypVSgmRtDfTpAyxdCty7B1y8CHz2GdC2beVNkAD2JBULIQQ+2fMJrkVdwyd7PkF77/ZQqUq2ckfnzp2xbNkyxTRHR0cAQFJSEurVq4fhw4ejd+/eL1yXv78/nJ2dsX//fjRt2hQAkJCQgLNnz6Jq1ao4fvw42rRpAwA4duwY0tLS0K5du3zF6ezsXIC9IiIiIqKievRI6iXatk26xujpU2V7vXq6a4uaNQOMjPQTZ1nGnqRcJKUn5fkvNTM1x7ybQzfj1INTAIBTD05hc+hmJKUnISUjJV/rLQwTExM4Ozsr/hkYGAAAunTpgrlz5+KVV17J9/ratm2L/fv3y38fPnwYNWvWRI8ePRTT9+/fD09PT3j/V8Lk77//RsOGDWFqaorq1atj1qxZyMzMlOd/tifr6NGjqF+/PkxNTdGoUSNs2rQJKpUqx3C3M2fOoFGjRjA3N0fz5s0RGhoKAFi+fDlmzZqFCxcuyD1oy/+7G1lsbCzeeustODo6wtraGu3atcOFCxcU6/30009RtWpVWFlZ4c0331T0khERERGVR5mZwJEjwNSpQGCgVFFu6FBg9WopQbK1Bfr1A379VbrR6/nzwIIFUqluJki5Y09SLiwXWObZ1rVGV/wz8B/5b8cvHJGSqUyGeq3pBQAI8gzC/mH75ele33ohKvmZgZ8AxAxRtICLQdu2bTF+/HhkZmbC0NAQ+/btQ5s2bdCqVSv8+OOPmDlzJgBg3759aNu2LQDg0KFDGDJkCL777ju0atUKN2/exNtvvw0AmDFjRo5txMfHo0ePHujatStWrVqFO3fuYNy4cbnGM2XKFHz11VdwdHTEO++8g+HDh+PIkSMYMGAALl++jO3bt2P3bmloo42NDQCgX79+MDMzw7Zt22BjY4OffvoJ7du3x/Xr12FnZ4e1a9di5syZ+L//+z+0bNkSK1aswHfffYfq1asX87NJREREVLIiI3U3c921C4iNVbY3bKjrLWrSBDDkt/4C4dNVRBqhefFMJeDff/+FpaUumevSpQvWrVtX6PW1bdsWSUlJOHXqFJo1a4b9+/djwoQJaNmyJYYOHYrU1FQIIXDy5Em89dZbAIBZs2Zh0qRJGDp0KACgevXqmDNnDiZOnJhrkrRq1SqoVCosXboUpqamCAgIQEREBEaMGJFj3nnz5iEoKAgAMGnSJHTr1g2pqakwMzODpaUlDA0NFUP5Dh8+jJMnT+Lx48cw+a+u5JdffolNmzZh/fr1ePvtt7Fw4UK8+eabePPNNwEAc+fOxe7du9mbRERERGVeRoZ0bZG2Et2zNafs7IBOnaSkqFMnqTeJCo9JUi4SJyfm2WagNpAfCyFQ26k2Ljy8gCyRpZtHZYB6zvWwdfBWxbK3x94uthjbtm2LRYsWyX9bWFgUaX2+vr5wd3fH/v37Ubt2bZw7dw5BQUFwcnJCtWrVcOzYMQghkJaWJvckXbhwAUeOHMG8efPk9WRlZSE1NRXJyckwNzdXbCM0NBR169aFqampPK1x48a5xlO3bl35sYuLCwDg8ePHqJZH7ckLFy4gMTER9vb2iukpKSm4efMmAODatWt45513FO3NmjXDvn37nvvcEBEREelDRISytyg+XtemUgGNGukq0TVuDBgY5L0uKhgmSbmwMH5+wqH5r4D8zls7cTbybI72LJGFs5FncejuIQT7Bud7vQWK0cICvr6+xbY+AGjTpg327duHunXrokaNGnD673bIQUFB2LdvH4QQ8PX1hYeHBwAgMTERs2bNyrU4RPZEqDCMsg2Q1RbB0Gjy7rVLTEyEi4uL4voprdIoJU5ERERUVOnpwNGjUlK0bRtw6ZKy3d4eCA6WEqPgYOC/ml1UApgkFZIQAtP3TYcaamiQ88u7GmpM2zcNnXw6lXilu+LStm1bvP/++wgICJCr2QFA69atsXTpUggh5F4kAGjYsCFCQ0Pznaz5+fnhjz/+QFpamjwk7tSpUwWO09jYGFlZWYppDRs2xMOHD2FoaAgvL69cl6tVqxZOnDiBIUOGyNOeLXtOREREVJru3dMlRXv2AAkJujaVSuoh0l5bFBjI3qLSwiSpkNKz0nEv/l6uCRIAaKDBvfh7SM9Kh4mhSanGlpiYKN8zCQDCw8Nx/vx52NnZ5TlcDdBdl/Trr79i6dKl8vSgoCD5OqTRo0fL06dPn47u3bujWrVq6Nu3L9RqNS5cuIDLly9j7ty5OdY/ePBgTJkyBW+//TYmTZqEu3fv4ssvvwSAAiWSXl5e8j65u7vDysoKHTp0QLNmzdCrVy98/vnnqFmzJh48eIAtW7bglVdeQaNGjTB27FgMGzYMjRo1QosWLbBy5UpcuXKFhRuIiIio1KSlAYcP6xKjq1eV7Y6O0vA57bVFz1xJQKWESVIhmRia4MSbJxCdGp3nPE4WTqWeIAHA6dOnFT0+H3zwAQBg6NChcrns3Hh7e8PT0xN37tyRiyYAQLVq1eDq6orbt28repiCg4Px77//Yvbs2fjss89gZGQEf39/OaF6lrW1Nf755x+MGjUK9evXR506dTB9+nQMHjy4QMPz+vTpg40bN6Jt27aIjY3FsmXLMGzYMGzduhVTpkzBG2+8gSdPnsDZ2RmtW7dG1apVAQADBgzAzZs3MXHiRKSmpqJPnz4YNWoUduzYke9tExERERXU7du6pGjvXiAp2x1g1GqgaVNdb1GDBtI00i+VEEL/9adLUHx8PGxsbBAXFwdra2tFW2pqKsLDw+Ht7V2gL+kajQbx8fGwtraGmkdxkaxcuRJvvPEG4uLiYGZmpu9wcijsMfI8GRkZ2Lp1K7p27aq49oroRXjsUFHw+KGi4PFTMKmpwMGDuqILISHKdmdnqbeoc2egY0epMl1FVpaOn+flBtmxJ4lK1e+//47q1avDzc0NFy5cwMcff4z+/fuXyQSJiIiIKL9u3tQlRfv2AcnJujYDA6B5c10lunr12FtU1jFJolL18OFDTJ8+HQ8fPoSLiwv69eunKCFOREREVB6kpAAHDuiG0YWFKdtdXXXXFnXoALDYbvnCJIlK1cSJEzFx4kR9h0FERERUYGFhuqRo/35pWJ2WoSHQooXu2qI6daTqdFQ+MUkiIiIiIspFcrI0dG7bNmko3X/3p5e5u+uSovbtgedc4kLlDJMkSPc8IsoNjw0iIqLKQwggNFTXW3TwoFSyW8vICGjVSpcYBQSwt6iiqtRJkra6RnJyMgsHUK6S/7vqUt+VWIiIiKhkJCZKZbm1RRdu31a2e3rqCi60awdYWeklTCpllTpJMjAwgK2tLR4/fgwAMDc3z9dNTTUaDdLT05GamsoS4BWUEALJycl4/PgxbG1tYcDbWxMREVUIQkg3cNUmRYcOAenpunZjYyAoSFd0wd+fvUWVUaVOkgDA2dkZAOREKT+EEEhJSYGZmVm+kioqv2xtbeVjhIiIiMqnhARgzx7dtUV37yrbvb11Q+jatgUsLPQTJ5UdlT5JUqlUcHFxgZOTEzIyMvK1TEZGBg4ePIjWrVtzGFYFZmRkxB4kIiKickgI4PJl3bVFhw8DmZm6dhMToE0bXWJUowZ7i0ip0idJWgYGBvn+QmxgYIDMzEyYmpoySSIiIiIqA+LigN27db1FERHKdl9fXVIUFASYm+snTiofmCQRERERUbkjBHDhgi4pOnpU2VtkZiYNndMWXfD11V+sVP4wSSIiIiKiciEmBti1S0qKtm8HIiOV7X5+uqSodWspUSIqDCZJRERERFQmaTTAuXO6SnTHjwNZWbp2c3OpLLd2GJ23t/5ipYqFSRIRERERlRlPnwI7d0pJ0Y4dwKNHyvZatXRJUatWUhEGouLGJImIiIiI9EajAc6c0VWiO3lSmqZlaQm0b68bRufpqb9YqfJgkkREREREpSoqSuol0vYWRUUp2196Sddb1KKFdINXotLEJImIiIiISlRWFnDqlK4S3alTUnU6LSsroGNHKSkKDgY8PPQXKxHAJImIiIiISsCjR7pri3buBKKjle316umG0DVvDvDWk1SWMEkiIiIioiLLzAROnNBVojtzRtluY6PrLercGXB11U+cRPnBJImIiIiICuXhQ11StGuXdB+j7Bo00F1b1LQpYMhvnlRO8FAlIiIionzJzJTuVaStRHf+vLK9ShWgUyfdtUXOznoJk6jImCQRERERUZ4iIoAtW1RYvvxlDB1qiLg4ZXujRrreopdfZm8RVQw8jImIiIhIlpEBHDmiq0R38SIgfWWULiKyt5d6ibp0kXqNnJz0GS1RyWCSRERERFTJ3bunu7Zo924gIUHXplIBL7+sQfXq1zFmjC+aNjWEgYH+YiUqDUySiIiIiCqZtDTg8GFdYnTlirLd0VHZW2Rjk4WtW0PRuLEPEySqFJgkEREREVUCd+7oCi7s2QMkJena1GqgSRPdtUUNG0rTtDIySj9eIn1ikkRERERUAaWlAQcP6hKjkBBle9Wq0v2KunSR7l9kZ6efOInKIiZJRERERBXErVu6pGjfPiA5WddmYAA0a6a7mWv9+sreIiLSYZJEREREVE6lpAAHDuiuLbp+Xdnu4qJLijp2BGxt9RImUbnDJImIiIioHAkL0yVF+/dLiZKWoSHQooVuGF3dulJ1OiIqGCZJRERERGVYcrKUDGmH0d28qWx3c9MVXGjfHrCx0UuYRBUKkyQiIiKiMkQIadicNik6cEAqwqBlZAS0bKlLjGrXZm8RUXFjkkRERESkZ0lJwN69UlK0fTsQHq5sr1ZNlxS1awdYWeknTqLKgkkSERERUSkTArh2TddbdOgQkJ6uazc2Blq31hVdqFWLvUVEpYlJEhEREVEpSEiQbuKqLbpw966y3dtblxS1bQtYWuonTiJikkRERERUIoQALl/WJUWHDwMZGbp2ExMgKEg3jK5mTfYWEZUVTJKIiIiIikl8PLB7t+7aovv3le0+PrqkqE0bwNxcL2ES0QswSSIiIiIqJCGAixd11xYdPQpkZuraTU2loXPaxMjXV3+xElH+MUkiIiIiKoDYWGDXLl1vUWSksr1mTV1S1Lo1YGamlzCJqAiYJBERERE9h0YDnD+vS4qOHQOysnTt5uZSWW5t0YXq1fUWKhEVEyZJRERERM94+hTYuVNKirZvBx49UrbXqiUlRF26AK1aScPqiKjiYJJERERElZ5GA5w5o6tEd+KENE3LwgJo317XW+TlpbdQiagUMEkiIiKiSikqSuot2rYN2LEDePJE2V67tu7aopYtpRu8ElHlwCSJiIiIKoWsLOD0aV0lulOnpOp0WlZWQIcOut4iDw/9xUpE+sUkiYiIiCqsx4+lXqJt26Reo+hoZXvdurqkqHlz9hYRkYRJEhEREVUYWVnS9UTaSnSnTyvbbWyAjh2lxCg4GHBz00+cRFS2qfUdQEREBF577TXY29vDzMwMderUwelsZzQhBKZPnw4XFxeYmZmhQ4cOCAsL02PEREREVJY8fAj89hswcCDg6Ai0aAHMnatLkBo0ACZPBg4elK47WrcOGD6cCRIR5U2vPUkxMTFo0aIF2rZti23btsHR0RFhYWGoUqWKPM/nn3+O7777Dr/99hu8vb0xbdo0BAcH4+rVqzBlvU0iIqJKJzNTuleRthLduXPKdltboFMnXW+Ri4tewiSickyvSdJnn30GDw8PLFu2TJ7m7e0tPxZCYOHChZg6dSr+97//AQB+//13VK1aFZs2bcLAgQNLPWYiIiIqfQ8e6JKiXbuAuDhle2CgrhJd48aAIS8oIKIi0OspZPPmzQgODka/fv1w4MABuLm5YfTo0RgxYgQAIDw8HA8fPkSHDh3kZWxsbNCkSRMcO3Ys1yQpLS0NaWlp8t/x8fEAgIyMDGRkZBRL3Nr1FNf6qHLh8UOFxWOHiqK8HT8ZGcCxYyps367Cjh1qXLqkUrTb2Ql07CgQHKxBp04CTk66NiGk5an4lLfjh8qWsnT85DcGlRDZi1+WLu1wuQ8++AD9+vXDqVOnMHbsWCxevBhDhw7F0aNH0aJFCzx48AAu2frK+/fvD5VKhTVr1uRY58yZMzFr1qwc01etWgVzc/OS2xkiIiIqkqgoU5w9WxVnzzrhwgVHpKQYyW0qlYCvbywaNnyEhg0fw9c3BgYGegyWiMql5ORkDB48GHFxcbC2ts5zPr0mScbGxmjUqBGOHj0qT3v//fdx6tQpHDt2rFBJUm49SR4eHoiKinruE1EQGRkZ2LVrFzp27AgjI6MXL0CUDY8fKiweO1QUZfH4SU8HjhxRYccOqbfoyhVlb5Gjo9Rb1KmTBh07Cjg66ilQKpPHD5UfZen4iY+Ph4ODwwuTJL0Ot3NxcUFAQIBiWq1atbBhwwYAgLOzMwDg0aNHiiTp0aNHqF+/fq7rNDExgYmJSY7pRkZGxf6ilMQ6qfLg8UOFxWOHikLfx8+dO7pri/bsARITdW1qNdCkiXTPoi5dgMBAFdRqFcpAMV76j76PHyrfysLxk9/t6zVJatGiBUJDQxXTrl+/Dk9PTwBSEQdnZ2fs2bNHTori4+Nx4sQJjBo1qrTDJSIiogJKSwMOHZKSom3bgGvXlO1OTrqkqGNHwN5eP3ESEWWn1yRp/PjxaN68OebPn4/+/fvj5MmTWLJkCZYsWQIAUKlUGDduHObOnYsaNWrIJcBdXV3Rq1cvfYZOREREeQgP1yVFe/cCycm6NrUaaNZMV4mufn1pGhFRWaLXJOnll1/GX3/9hcmTJ2P27Nnw9vbGwoUL8eqrr8rzTJw4EUlJSXj77bcRGxuLli1bYvv27bxHEhERURmRmgocOKBLjK5fV7a7uOh6izp0ALLdDpGIqEzS+10Eunfvju7du+fZrlKpMHv2bMyePbsUoyIiIqLnuXFDlxTt3w+kpOjaDAyAFi2kpKhzZ6BePUClynNVRERljt6TJCIiIir7kpOlZGjbNqnwwo0bynY3N2VvkY2NXsIkIioWTJKIiIgoByGkYXPaSnQHDkjD6rQMDYGWLXXXFr30EnuLiKjiYJJEREREAICkJGDfPt0wuvBwZbuHhy4pat8esLLST5xERCWNSRIREVElJQQQEqJLig4elG7wqmVkBLRurUuMatVibxERVQ5MkoiIiCqRhATdfYu2b5du7pqdl5cuKWrbFrC01EuYRER6xSSJiIioAhMCuHIF+PdfNVatao6QEENkZOjaTUyAoCBdJTo/P/YWERExSSIiIqpg4uOB3bulnqLt24F79wDAAIAjAKB6dV1vUZs2gIWFHoMlIiqDmCQRERGVc0IAFy/qKtEdOQJkZuraTU2BoCANPDyuYPx4fwQEGOkvWCKicoBJEhERUTkUGyv1FmmvLXrwQNleo4autygoCDA0zMLWrbdQo4a/XuIlIipPmCQRERGVA0IA58/rKtEdOwZkZenazcyAdu101xb5+CiXz34dEhERPR+TJCIiojLq6VNg1y4pKdqxA3j4UNnu76/rLWrVShpWR0RERcckiYiIqIzQaICzZ3VD6I4fl6ZpWVhIN3HV9hZ5eektVCKiCo1JEhERkR5FRQE7d0pJ0Y4dwOPHyvbataWEqEsXoGVLqWQ3ERGVLCZJREREpSgrCzh9WleJ7uRJ6XojLUtLoEMHXW9RtWr6i5WIqLJikkRERFTCnjyReom01xZFRyvb69TRXVvUvDlgbKyfOImISMIkiYiIqJhlZUk9RNpKdGfOKHuLrK2Bjh2lpCg4GHB311+sRESUE5MkIiKiYvDokW4I3c6dQEyMsr1+fd0QumbNACPez5WIqMxikkRERFQImZlS9TltJbqzZ5XttrZAp05SUtS5M+DiopcwiYioEJgkERER5dODB7pri3btAmJjle2BgbpKdE2aAIb8lCUiKpd4+iYiIspDRgZw9KhuGN2FC8p2Ozupt0h7bVHVqvqJk4iIiheTJCIiomzu39clRbt3A/HxujaVCmjUSFeJ7uWXAQMD/cVKREQlg0kSERFVaunpwJEjukp0ly8r2x0cpF6iLl2kXiNHR/3ESUREpYdJEhERVTp37+qSoj17gMREXZtKJV1PpK1EFxjI3iIiosqGSRIREVV4aWnAoUO6SnRXryrbnZx0Veg6dQLs7fUTJxERlQ1MkoiIqEIKD9ddW7R3L5CUpGtTq6V7FWkr0TVoIE0jIiICmCQREVEFkZoKHDyoG0YXGqpsd3bWJUUdOwJVqugnTiIiKvuYJBERUbl186YuKdq3D0hJ0bUZGADNm+sq0dWrJ11vRERE9CJMkoiIqNxISQH279clRjduKNtdXXVJUfv2gK2tPqIkIqLyjkkSERGVWUIAYWG6pOjAAWlYnZahIdCypW4YXZ067C0iIqKiY5JERERlSlKSNHROW4nu1i1lu7u7srfI2lo/cRIRUcXFJImIiPRKCCAkRFeJ7uBBqWS3lpER0KqVLjEKCGBvERERlSwmSUREVOoSE6Wy3NphdHfuKNs9PXVJUbt2gKWlfuIkIqLKiUkSERGVOCGkG7hqk6JDh4CMDF27sTEQFKRLjPz82FtERET6wySJiIhKRHw8sGeP7tqie/eU7dWr65KiNm0ACwu9hElERJQDkyQiIioWQgCXLumSosOHgcxMXbupqZQMaSvR1ajB3iIiIiqbmCQREVGhxcUBu3ZJSdH27UBEhLK9Rg1dUhQUBJib6ydOIiKigmCSRERE+SYEcP68rhLd0aNAVpau3cwMaNtWN4zOx0dvoRIRERUakyQiInqumBipt0g7jO7hQ2W7n58uKWrdWhpWR0REVJ4xSSIiIgWNBjh3TleJ7vhxaZqWubl0E9cuXaShdN7e+ouViIioJDBJIiIiREcDO3dKSdGOHcDjx8r2gABdb1HLloCJiX7iJCIiKg1MkoiIKiGNBjh9WjeE7uRJZW+RpSXQoYPUU9S5s3RzVyIiosqCSRIRUSXx5InUS7R9u/R/VJSyvU4dXSW6Fi2kG7wSERFVRkySiIgqqKwsqYdIW4nu9GmpOp2WtbXUW6S9tsjdXX+xEhERlSVMkoiIKpBHj6Reom3bpGuMnj5Vtterp7u2qFkzwMhIP3ESERGVZUySiIjKscxM4MQJXSW6s2eV7TY2QKdOUlIUHAy4uuonTiIiovKESRIRUTkTGQns2SMlRbt2AbGxyvaGDXVD6Jo2BQx5piciIioQfnQSEZVxGRnAsWPAv/+qsX59EMLDlWPkqlRR9hY5O+spUCIiogqCSRIRURkUEaEruLBrFxAfDwAGAGyhUgk0aqSSK9E1bgwYGOg5YCIiogqESRIRURmQng4cOaJLjC5dUrbb2wMdO2rg7HwOH31UF25urLhARETlw57wPRhzbQyW1lqKzjU76zucfGGSRESkJ/fu6Qou7NkDJCTo2lQqqYdIW4kuMBDQaLKwdet9ODnV1V/QREREBSCEwNT9U3E/7T6m7p+K4BrBUKlU+g7rhZgkERGVkrQ04PBhXWJ09aqy3dFRdzPXjh0BBwdlu0ZTerESEREVh503d+JM5BkAwJnIM9h5cyeCfYP1HNWLMUkiIipBt2/rkqK9e4GkJF2bWi1Vn9NWomvYUJpGRERUXggh8CjpEUKjQhESFYLQaOn/OW3noKFLQ0zbNw0GKgNkiSwYqAwwbd80dPLpVOZ7k5gkEREVo9RU4OBBKSnavh0ICVG2V62q7C2ys9NPnERERAWRnpUOjdDA1NAUALA3fC8+2fMJQqJCEJcWl2P+PrX6ICo5CqcenJKnZYksnHpwqlz0JjFJIiIqops3dQUX9u0DkpN1bQYGQPPmusSoXj32FhERUdkVlRwl9Qj91zMUEi09vhVzC7/+71cMqTdEnvdExAkAgAoqeFfxhp+9H/wd/OHv4I/Wnq3x6sZX5V4krfLSm8QkiYiogFJSgAMHdMPowsKU7a6uuqSoQwfA1lYvYRIREeUqIysDt2JuISQqBDXsayDAMQAAsOvmLnT6o1Oey4VF6z7wGro0xLp+6+Bn74ca9jXkHiatHTd2KHqRtMpLbxKTJCKifAgL0yVF+/dLw+q0DA2BFi10lejq1JGq0xEREelbTEoMNoVskq8VCokKwc2Ym8jUZAIAprWehtltZwMAatrXBAB42njCz8EP/vZSr5Cfg9RD5GLpIq/X1tQWfQP65rpNIQSm7ZsGNdTQIGfVITXUZb43iUkSEVEukpOloXPaa4tu3lS2u7vrkqL27QFra/3ESURElVumJhO3Y28rhsi1rNYSQ+sPBQBEp0Rj+ObhOZYzNzKHv4M/HMx1pVSr2VRD0idJMDcyL1JM6VnpuBt3N9cECQA00OBe/D2kZ6XDxNCkSNsqKUySiIgACAGEhup6iw4elEp2axkZAa1a6YbR1a7N3iIiIio9mZpMGKqlr+7RydF4+9+3ERIVghtPbyA9K10xb3Jmspwkedl6IdgnGL52vvL1Qn72fnCzdoNapbxIVqVSFTlBAgATQxOcGnEKT5KfSLFnZuLw4cNo2bIlDA2lfXCycCqzCRLAJImIKrHERKkst7a36PZtZXu1arreonbtACsrvYRJRESVRJYmC3fj7srD4rIPkevs2xnLey0HAFiZWOHvkL/lggimhqbws/eTh8g192gur9NQbYjtr20v9X3xsPGAh40HACAjIwOR5pFo4NwARkZGpR5LYTBJIqJKQwjpBq7aSnSHDgHp2X58MzYGWrfWJUb+/uwtIiKi4peQloDQ6FBkajLR1L0pAGmIWpXPqiA5IznXZa5FXZMfGxsYY2mPpXC1coWfgx+q2VTL0StERcMkiYgqtPh4ZW/R3bvKdm9vXVLUpg1gaamXMImIqILadXMXrkVdk64XipZ6hR4kPAAAtKzWEofeOARASnyqWlRFREIEatrXlIfFaYfIaYsqaL3R4I1S35fKhEkSEVUoQgCXL+uuLTp8GMjM1LWbmEjJUJcu0vVFNWuyt4iIiAovKT0J16Ovy8PiDNQGmB40XW4fvnk47sffz7FcVYuqcDR3VEw7+uZROJo7wkBtUOJx0/MxSSKici8uDti9W9dbFBGhbPf11SVFbdoA5kW/JpWIiCqxGftm4Nj9YwiJCsG9+HuKNhdLF0WS1NmnM6JTohU9Q34OfrA1tc2xXmdL55IOnfKJSRIRlTtCABcu6JKio0eVvUVmZkDbtrpKdL6++ouViIjKj5SMFIQ9DctROCElIwVX370qz3fw7kHsv71f/tvB3EGRBGmERr5GaGnPpaW9G1QMmCQRUbkQEwPs2iUlRdu3A5GRynY/P11S1Lq1lCgRERE9SwiByMRI3I69ragC129dP2y4ugECItflktKTYGFsAQB4r/F7eL3u63JiZG9uXyqxU+nRa5I0c+ZMzJo1SzHNz88PISEhAICHDx9iwoQJ2LVrFxISEuDn54cpU6agT58++giXiEqRRgOcO6erRHf8OJCVpWs3N5fKcmuH0VWvrr9YiYiobLr59CbOPzwv9QxF6262mpCeALVKjaRPkmBqaAoAsDa2hoBAFdMqivsJaR+bGel+fetdq7e+dolKid57kmrXro3du3fLf2tvMAUAQ4YMQWxsLDZv3gwHBwesWrUK/fv3x+nTp9GgQQN9hEtEJejpU2DnTikp2rEDePRI2V6rlq4SXcuWgKmpfuIkIqKyQQiBJ8lPpKFx/yVAn3b4FEYG0r14Zh+cjd8v/J5jObVKDW9bbzxKfARPW09p3raz8WmHT+Fg7gAVK/pUenpPkgwNDeHsnPtFakePHsWiRYvQuHFjAMDUqVPxzTff4MyZM0ySiCoAjQY4c0ZXie7kSWmalqUl0L69rrfI01N/sRIRUdmwOXQzNl7bKF8vFJsaq2h/O/Bt+Dn4AQACXQIREhWiLJpg7wdfO1+YGJoolnOzdiutXaByQO9JUlhYGFxdXWFqaopmzZphwYIFqFatGgCgefPmWLNmDbp16wZbW1usXbsWqampaNOmTZ7rS0tLQ1pamvx3fHw8AOlOvxkZGcUSs3Y9xbU+qlwq+/ETFQXs3KnCjh1q7NqlQlSU8te62rUFgoM1CA4WaNFCwNhY11ZJnzJZZT92qGh4/FBRlNbxE5UchevR1xEaHYrQp6EIjQ7F9ejr+GfAP6heRRpXfTriNH678Ju8jAoqeNl6oaZdTfjZ+8EABnKcoxqOwqiGo3JuSPC9UJrK0vknvzGohBC5X51WCrZt24bExET4+fkhMjISs2bNQkREBC5fvgwrKyvExsZiwIAB2LlzJwwNDWFubo5169ahU6dOea4zt+ucAGDVqlUwZ91folKXlQXcuFEFZ8864ezZqrhxwxZC6BIjM7MM1Kv3BA0bPkaDBo/g6Jiqx2iJiKikZYksPEx7CHsje5gaSOOmd0TtwB+RfyAhKyHXZaZWn4pG1o0AAKFJobiQcAFupm5wM3GDi4kLTNQmuS5H9Kzk5GQMHjwYcXFxsLa2znM+vSZJz4qNjYWnpye+/vprvPnmm3jvvfdw8uRJzJ8/Hw4ODti0aRO++eYbHDp0CHXq1Ml1Hbn1JHl4eCAqKuq5T0RBZGRkYNeuXejYsSOMjIyKZZ1UeVSG4+fRI2DXLqm3aPduFaKjlb1FdesKdOqkQefOAs2aCVTQp6HYVYZjh0oOjx8qisIcPwlpCbjy5AquP72OkOgQuYfoVswtZGgysHXQVnTw7gAAWHV5FYZtHgYAqGZdDX72fqhpL/UM1bSriUCXQNiY2pTU7lEJK0vnn/j4eDg4OLwwSdL7cLvsbG1tUbNmTdy4cQM3b97EDz/8gMuXL6N27doAgHr16uHQoUP4v//7PyxevDjXdZiYmMDEJOevCUZGRsX+opTEOqnyqEjHT2YmcOKErhLdmTPKdhsboGNH3bVFrq4qALybeGFVpGOHSh+PHyqKZ4+fLE0Wbsfelu8p1LVGV/g7+AMANl/ZjDf+fiPX9ZgbmSMmLUZeV3e/7jg38hxq2NWQy2xTxVMWzj/53X6ZSpISExNx8+ZNvP7660hOTgYAqNVqxTwGBgbQZL+ym4j04uFDXVK0a5d0H6PsGjTQVaJr2hQwLFNnGyIiKoywp2FYeXmlXE477GkY0rPS5XZzI3M5SfJ38Ie7tbuiYIK/gz/8HPzgbu0u32wVAOzN7XmvISpT9Pq15aOPPkKPHj3g6emJBw8eYMaMGTAwMMCgQYNga2sLX19fjBw5El9++SXs7e2xadMm7Nq1C//++68+wyaqlDIzgWPHdJXozp9XtlepAnTqJCVFwcFAHkUriYiojNIIDe7G3VWU0w6JDsE7ge+gt590X6CHiQ8x//B8xXKmhqby0LhqNtXk6U3dm+Le+Hulug9ExUWvSdL9+/cxaNAgREdHw9HRES1btsTx48fh6OgIANi6dSsmTZqEHj16IDExEb6+vvjtt9/QtWtXfYZNVGlEROh6i3bvBuLilO2NGknD57p0ARo3Zm8REVF5kJieiPSsdNiZ2QEArjy+gsEbB+N69HWkZuYsntPIpZGcJAU4BGBk4EjFzVar2VSDgZpDqKli0etXmtWrVz+3vUaNGtiwYUMpRUNEGRnAkSNSUrR9O3DxorLd3l7ZW+TkpJ84iYjo+YQQuB9/X+oN+u96Ie3jiIQITGoxCQs6LAAA2Jra4uIj6YRvbGCMGnY14OfgB397KRFq7NZYXq+9uT0Wd8/9unCiioS/+xJVcvfuKXuLErJVX1WpgJdf1l1b1KgRYMAfC4mIyozkjGRcj76OkKgQVLWoirbebQEAd+LuwPtb7zyXe5D4QH7sauWKfwf9C38Hf3jaesJQnfPrYVm4vw1RaWKSRFTJpKUBhw/rEqMrV5Ttjo5SL1GXLlKvkYODfuIkIiKl1MxU/HruV0XP0N24u3J7/9r95SSpmk01WJtYw9XKVVE0Qfu4ilkVeTmVSoVuNbuV+v4QlWVMkogqgTt3dAUX9uwBkpJ0bWo10KSJrreoYUNpGhERla7UzFSERYcphshVr1Ids9vOBgAYqg0xfsd4RTU5ALA3s4e/gz8CHALkaWqVGk8nPuW1QkSFxCSJqAJKSwMOHtQlRiEhyvaqVaWCC507S71Fdnb6iZOIqLIRQiAxPRFWJlby3/9b/T9cfnwZt2NvQ0Ao5g90CVQkSW81eEsus60tp+1gnnuXPxMkosJjkkRUQdy6pUuK9u0D/rvVGADpOqJmzXSV6OrXZ28REVFJSstMw42nNxQFE7SPAxwDcOzNYwCkoW6h0aEIjw0HIBVRyD4srm7Vuor1/l+3/yv1fSGqjJgkEZVTKSnAgQO6SnTXryvbXVx0SVGHDtJ9jIiIqPgIIfAk+QlCo0IRkxqDnn495baXFr2EG09v5LpcWHQYhBBQqVQAgG87fyv3DjmaO8rTiUh/mCQRlSNhYbqCC/v3S4mSloEB0KKF7tqiunWl6nRERFQ8dt3chbORZxESrbvZakxqDADAwdwBTyY8keetYVcDj5Me5yiY4O/gD187X0Ui1Nm3c6nvCxE9H5MkojIsOVlKhrTD6G7eVLa7uemSovbtARsbvYRJRFQhRCdHK4bFPUp6hN96/Sa3f370c+y+tVuxjAoqeNp6wt/BH2mZaTAxNAEArO23FhZGFuwVIiqnmCQRlbIzZ1SYNq05qlZVoWlTZZsQ0rA5bVJ04IBUhEHLyAho2VKXGNWuzd4iIqKCyNJkKQoafHn0S2wK2YTQ6FBEJUflmP/7Lt/D2sQaABDsEwwnCyf420sFE/wd/FHDrgbMjMxyLGdpbFlyO0FEJY5JElEp++MPFS5dcsTKlVlo2lQqx713r+7aovBw5fzVqkkJUefOUm+RlZV+4iYiKk9iU2OlXqH/hsVph8jdjLmJpxOfwsLYAgBw4+kNHLl3RF7Ow9pDMTxOBd0vUR81/6jU94OI9INJElEpuHMHiIqSen3WrpXKyi1bpsaJE8C5c0Bmpm5eY2OgdWtd0YVatdhbRESUmyxNFu7E3UFIVAg6VO8AYwNjAMDYbWPx3cnv8lwu7GkY6jvXBwAMrTcUbbzawM/eDzXta8rJExFVbkySiEqBl1fOaUlJKpw6pft71CgpKWrbFrDkKA0iIoWbT2/i2P1jinLaYdFhSMuSxiRfHnUZtZ1qAwDcrN0AAK5WroqCCdr/PWw85PU282iGZh7NSn+HiKhMY5JEVAr++AMYNkzbY6TsFjIwAJYvB157TQ+BERGVERqhwd24u/LwuNDoUHzc4mN42noCANZcWYMpe6fkWM7EwAQ17GsgIT1BnjYycCRGNRol37CViKigmCQRlYJXXwUiIoCPP87ZdvIk0LBh6cdERKRv+2/vx6LTixASFYKw6DCkZKYo2oN9guUkqaFLQwR5Bil7hhz84GnjqSjEAAA2piz1SURFwySJqBRkZgKLFmn/EgBUUKsFNBpebEREFY8QAvfj7yvKaWv//6n7T+haoysA4FHiI6y9slZezkhthBr2NeQkyMfOR27r7NuZ9xMiolLDJImoFKxYAdy+LRVgqF9foGnTCzh5si4iIlRwctJ3dEREhZOckYyw6DBUtawKZ0tnAMC/1//FgPUDkJyRnOsyIVEhcpLU1L0pvuz4pVxO28vWC4ZqfjUhIv3jmYiohKWlATNnSo/nzwc++CAL27bdwcKFtSGEGiYmeg2PiOiFEtIScOrBKV1J7f/Kad+JuwMA+K7zd3ivyXsAAGdLZyRnJMNQbQhfO98cRRMCHAPk9XraeuLD5h/qZZ+IiJ6HSRJRCfvpJ+DuXcDVFRg7VlfOW6WSyn0TEZUFqZmpuPH0hpwINXVvivbV2wMALj++jPa/t891uSqmVeQKcwBQx6kOQt4NQfUq1WFkYFQqsRMRFTcmSUQlKDERmDdPejx9OmBmBmRk6DcmIiJAuh7o8yOfIyRaKql9O/Y2NEIjt49tMlZOkvwd/OFTxQe1HGvJPULa3iEHcweost3MzcTQBH4OfqW+P0RExYlJElEJ+vZb4PFjwMcHGD5c39EQUWWRnpWOm09vKu4pdO3JNVTXVEdXSNcDqVQqfH38a8VyNiY2ctW45h7N5elVzKrgxvs3SnUfiIj0iUkSUQl5+hT44gvp8ezZgBFHnRBRMYtKjkJyRjKq2VQDAMSkxKDJz01wK+YWskRWjvk11rqeIkdzR3zc4mN423rLPUNOFk6KXiEiosqKSRJRCfn8cyAuDqhTBxg4UN/REFF5JYTA9ejrcgnt7OW0n6Y8xSv+r2DjgI0AAFtTW0QmRiJLZMHS2FIxLM7X1hdPrz2V16tSqfBph0/1tVtERGUakySiEhAZCXz3nfR43jxArdZvPERU9j1NeSpVjosKgbGBMV6t+yoAQECgwU8NctxoVSshPUF+rFKpsGfIHrhbu8PF0kXRK5SRkYGt4VtLdieIiCoIJklEJWDePCAlBWjWDOjeXd/REFFZ9P2J73Hx0UW5V+hJ8hO5rW7VunKSpFap0cClAVIyUhQ9Q/4O/qhhXwPmRuaK9TZ2a1yq+0FEVBExSSIqZuHhwJIl0uP583Ulv4mo8ohNjUVoVKicAIVGh8JQbYg1fdfI8yw+sxhXn1xVLOdu7Q5/B3/Ur1pfMf3I8COlETYREf2HSRJRMZs5Uyrz3akT0KaNvqMhopKSpcnCo6RHcLVylacN3TQUO2/uxMPEhznmtzS2hBBCHgL3ZoM3EZcaBz8HqVeopn1NWBpbllr8RESUNyZJRMXoyhVgxQrpsfb+SERUviWkJSA0OlS+XigkWrrZ6vXo6zAzMsPTiU/lxCcmJUZOkFytXHPcU0gjNDBQGQAAPmj2gd72iYiIno9JElExmjYNEALo0wdo1Ejf0RBRfmmEBvfi7iE0OhS3Ym7hnUbvyG391/fH9hvb81w2JjUGdmZ2AICZbWZiWutp8HPwg7WJdYnHTUREJYNJElExOXkS+OsvqZLdnDn6joaInmf/7f3Yf3u/XFL7evR1RfW4fgH9YG9uDwDwt/fHuchzioIJ2iFynjaeMFAbyMs1dGlY6vtCRETFj0kSUTGZMkX6f8gQoFYt/cZCVJkJIRCRECEPj9MWT1jXbx1sTG0AAOuvrsf/nfo/xXJGaiP42vnC38EfSRlJsIeUJH3Z6Ut80/mbUt8PIiLSHyZJRMVg715g927AyAiYMUPf0RBVDikZKTA2MJZ7cn45+wt+PP0jrkdfR2J6Yo75r0dfx8tuLwMA2nm3Q2pmquJ6Ie8q3jBU5/xYzN5TRERElQOTJKIiEgL45BPp8ciRgJeXXsMhqlCEEHiY+FDRI6T9/07sHZwdeRb1nesDAOLT4nE28iwAwEBlAB87H8UQOU9bT3m9vWv1Ru9avfWxS0REVA4wSSIqos2bgRMnAHNz3ZA7IiqYtMw03Hh6AyFRIWhZrSWqWlYFAHxz/Bt8uPPDPJe7Hn1dTpJ6+vVE9SrV4efgh+pVqsPYwLg0QiciogqISRJREWRlAVOnSo/HjgWcnfUbD1F5cCf2Dnbc3CFdM/RfOe3w2HBohAYAsL7fevQJ6AMA8LXzhVqllpIfbdGEbMUTHM0d5fX62PnAx85HL/tEREQVC5MkoiL480/g8mXA1haYMEHf0RCVDelZ6bj59KZieNzw+sPRyrMVAOBM5BmM/HdkjuWsTazh7+APIwMjeVpn385I/iQZJoYmpRY/ERERkySiQkpP1xVpmDgRqFJFv/EQlbYsTZZc1ODCwwuYtm8aQqJCcCvmFrJElmLeWg615CSpjlMddPHtkqOcdlWLqvJNWbU4ZI6IiPSBSRJRIf3yC3DrFlC1KvD++/qOhqhkZGRlIDw2XOoReqak9pRWUzC+2Xh53n+u/yM/tjS2VAyPa+PVRm6rYV8DW1/dWpq7QUREVCBMkogKITlZd8PYqVMBCwv9xkNUVDEpMQiNDoWNiQ1qOUo3+rr06BIaLmmITE1mrsuERIXIj2va18T/df0/OSlytXLN0StERERUXjBJIiqEH34AIiOlct9vv63vaIjyLyUjBftu70NIVIiiV+hx0mMAwLsvv4sfuv4AAPC09USmJhPmRuaoaV9TUTTB38EfNexqyOs1MzLD6JdH62WfiIiIihuTJKICiosDPv1UejxzJmDMSyaojIlPi5eHxoVEhaCGfQ0Mqz8MAJCSmYJuq7rlupyblRvMDM3kv61NrHF33F24WbtBrVKXRuhERERlApMkogL66isgJgaoVQt47TV9R0MkVZMbu22s3CsUmRipaO/s21lOkuzM7BDkGQQnCydFz1BN+5qwMrHKsW4PG4/S2AUiIqIyhUkSUQE8fgx8/bX0eO5cwMBAv/FQxZeYnojQqFCERofiyqMr2H97P6b9PA21HGthTd81AAAjtRFWX1mN2NRYeTkXSxepapy9P5q6N1Wsc/+w/aW4B0REROUPkySiAliwAEhKAho1Al55Rd/RUEWhERrcj7+PmJQY1HOuJ08P+L8AXIu6lusyqZmp8mOVSoX57eZLFeUc/OBn7wcbU5sSj5uIiKiiYpJElE937wI//ig9nj8fYOEuKoxLjy7h6pOr0vVC0SFyL1FyRjICHANwZfQVeV4LY6lsopOFE/zs/VDTriY0jzX4X8v/4aWqLynWO+rlUaW6H0RERBUZkySifJo9W7qBbNu2QIcO+o6GyiohBB4kPJArx8WlxmFyq8ly++t/vY4Ljy7kWM5QbQhDtSGEEHLp7D/7/Ak7MzvYmdkBADIyMrB161Z09e0KIyOj0tkhIiKiSohJElE+hIYCy5ZJj9mLRM9aemYpDtw5ICdGiemJcpupoSk+bvmxXB2uqXtT5Y1WHaT/vW29YWSgTHx87XxLdT+IiIhIwiSJKB+mTwc0GqBnT6Bp0xfPTxWDEAKPkh5JyY+2pHZ0CO7H38fFdy7KPT7bb27Hxmsb5eUMVAbwsfORE6HUzFSYG5kDABZ3X6yXfSEiIqL8Y5JE9AJnzwJr10q9R3Pn6jsaKglpmWm4GXMTtRxqyYnPRzs/wtKzSxGfFp/rMg8SHsDN2g0AMPilwXjZ9WW5pLaPnQ+MDXgDLSIiovKKSRLRC0ydKv0/eDBQp45+Y6GieZryFFceX5GHxWlvthoeGw6N0ODhhw9R1bIqAEAFFeLT4qFWqeFt6y2X09YOkbM3t5fX2yegj752iYiIiEoAkySi5zh0CNi2DTA0BGbO1Hc0lB8ZWRm4FXNLToDeafSOXA57zoE5WHhiYa7LWZtYIyIhQk6S3m38LobVHwZfO1+YGJqUVvhERERUBjBJIsqDEMAnn0iP33wT8OU19GXSsXvHsClkk1xO+2bMTWRqMuX21p6t0cyjGQAgwDEAXrZe8rA4fwd/+bGzpbM81A4AvGy9SntXiIiIqIxgkkSUh23bgMOHAVNTYNo0fUdTOWVqMhEeEy4PjwuNCkVIdAi+7/I96jvXBwCciTyDz49+rljOwshCvqmqmZGZPH1E4AiMCBxRmrtARERE5RCTJKJcaDTAlCnS4zFjADc3/cZT0cWmxsLYwFiuAPdP6D/4ePfHuPH0BjI0GTnmv/z4spwkNfdojjEvj1GU03azclP0ChEREREVBJMkolysWwecPw9YWQGTJuk7moohS5OF27G35YIJ2l6h0KhQPEp6hNV9VmPASwMASDdWvRZ1DQBgZmgm9wpph8a18mwlr7ehS0M0dGmol30iIiKiiolJEtEzMjN1w+s++giwt3/+/KQUnxaP0KhQhEaHor5zfbzk9BIAYEvYFvxv9f/yXO5u3F35cVP3ptjx2g74O/jD3dpdvhErERERUWlgkkT0jOXLgbAwwMEBGD9e39GUbY8SH2H15dWKctqRiZFy+9y2c+Ukyd/BHyYGJqhpX1Mup60dHlfTviasTazl5aqYVUEnn06lvj9EREREAJMkIoXUVGDWLOnxJ59Iw+0qs8T0RFyPvq4YHtetRjcMqTcEABCVHIVxO8blWM7Z0hl+9n5wtXKVp9Wwq4GkT5JgoDYorfCJiIiICoVJElE2ixcD9+8D7u7AqFH6jqZ0CCGQkpkiF014kPAAQ/4agtDoUNyPv59jfksjSzlJ8rXzRe9avXP0Ctma2uZYTqVSwUDFBImIiIjKPiZJRP9JSADmzZMez5ghlf6uSFIyUnA9+rpiaJy2rPardV7FTz1+AgDYmtpiT/geeTlHc0fF8Lhm7s3kNhNDE2zov6HU94WIiIioJDFJIvrPwoVAVBRQowYwbJi+oykcIQQiEyMRGhUKQ7WhXAUuMT0R1gusISByXS7saZj82NzIHH/2+RPVbKrBz94P9uasXEFERESVC5MkIgDR0cCXX0qP58wBDMvBO0MIgQ3XNihKaYdEhSAhPQEA0N67PXYP2Q0AsDS2hLOlM1IzU+Hv4C//05bVrl6lumLdA18aWOr7Q0RERFRWlIOvgkQl77PPgPh4oH59oF+/kt3WnvA9GHNtDJbWWorONTvnOZ8QAo+THsvD4kKiQmBpbInZbWcDkK7xGb1lNJ4kP1Esp1apUb1KdXjaeCqmh4wJgZWxFW+ySkRERPQCTJKo0ouIAL7/Xno8bx6gLsFb8gghMHX/VNxPu4+p+6ciuEYwBITiPkDvb3sfJyNOIjQ6FLGpsYrlvWy95CQJAPrU6oPkzGT42//XM+TgB58qPjAxNMmx7ewltomIiIgob0ySqNKbO1cq/d2yJdClS8lu69/r/+JM5BkAwJnIM3D/2h02pja4+u5VeZ5TD07hRMQJAIAKKnhX8ZaHxdVyqKVY36Lui0o2YCIiIqJKiEkSVWo3bwI//yw9nj8fKMmRaEIIvLPlHcW0B4kP8DDxIdKz0mFsYAwAmNxyMtKz0uFn74ca9jVgaljByuwRERERlXElOLDoxWbOnAmVSqX45+/vr5jn2LFjaNeuHSwsLGBtbY3WrVsjJSVFTxFTRTNjBpCZKfUgtWpVstvafmM7HiQ8yDF9Re8VMFIbyX/39OuJvgF9UadqHSZIRERERHqg1yQJAGrXro3IyEj53+HDh+W2Y8eOoXPnzujUqRNOnjyJU6dOYcyYMVCX5EUjVGlcugSsWiU91t4fqaQIIfDBjg9yTDdQGWDh8YUlu3EiIiIiKhC9D7czNDSEs7Nzrm3jx4/H+++/j0mTJsnT/Pz8Sis0quCmTgWEAPr3Bxo0KNlt7by5EyHRITmmZ4ksnHpwCjtv7kSwb3DJBkFERERE+aL3JCksLAyurq4wNTVFs2bNsGDBAlSrVg2PHz/GiRMn8Oqrr6J58+a4efMm/P39MW/ePLRs2TLP9aWlpSEtLU3+Oz4+HgCQkZGBjIyMYolZu57iWh+VvuPHVdi82RBqtcC0aZkoyZdSCIEpe6dADTU00ORoV0ONKXunoG21tizPTc/Fcw8VBY8fKgoeP1QUZen4yW8MKiGEKOFY8rRt2zYkJibCz88PkZGRmDVrFiIiInD58mVcuXIFzZo1g52dHb788kvUr18fv//+O3788UdcvnwZNWrUyHWdM2fOxKxZs3JMX7VqFczNzUt6l6gcEAKYNq05Ll92RPv2d/Dee+dLdHsZmgyMuDoCsZmxec5ja2iLpQFLFdcmEREREVHxSk5OxuDBgxEXFwdr67xvj6LXJOlZsbGx8PT0xNdff41atWqhRYsWmDx5MubPny/PU7duXXTr1g0LFizIdR259SR5eHggKirquU9EQWRkZGDXrl3o2LEjjIz4pba82b1bha5dDWFsLHD1aiaqVSv5bf5+8Xe4W7mjilkVZGRm4MTxE2jStAmMDKXjx9HcEe7W7iUfCJVrPPdQUfD4oaLg8UNFUZaOn/j4eDg4OLwwSdL7cLvsbG1tUbNmTdy4cQPt2rUDAAQEBCjmqVWrFu7evZvnOkxMTGBikvNGmkZGRsX+opTEOqlkCQFMny49HjVKBR+fkn/9YlJiMHrbaGiEBmHvhcHNwg1R5lFo7N6Yxw8VCs89VBQ8fqgoePxQUZSF4ye/2y9TZeISExNx8+ZNuLi4wMvLC66urggNDVXMc/36dXh6euopQirv/voLOH0asLAAPvmkdLa5/up6pGelo5ZDLXjZepXORomIiIio0PTak/TRRx+hR48e8PT0xIMHDzBjxgwYGBhg0KBBUKlUmDBhAmbMmIF69eqhfv36+O233xASEoL169frM2wqp7KypIp2ADB+PODkVDrbXXFxBQDgtbqvlc4GiYiIiKhI9Jok3b9/H4MGDUJ0dDQcHR3RsmVLHD9+HI6OjgCAcePGITU1FePHj8fTp09Rr1497Nq1Cz4+PvoMm8qplSuBa9eAKlWAjz4qnW3ejr2NQ3cPQQUVBtcZXDobJSIiIqIi0WuStHr16hfOM2nSJMV9kogKIz0dmDFDejxpEmBjUzrbXXVJulttW++2LMxAREREVE6UqWuSiErK0qXA7duAiwswZkzpbFMIoRtqV4dD7YiIiIjKCyZJVOElJQFz5kiPp00DSut2WbdibuHG0xswNTRFn4A+pbNRIiIiIiqyMlUCnKgkfP898OgRUL068OabpbddHzsfRH4YidMPTsPapHju0UVEREREJY89SVShxcQAn30mPZ41CzA2Lt3tO5g7oLNv59LdKBEREREVCZMkqtC+/BKIjQVeegkYNKj0tpupySy9jRERERFRsWKSRBXWw4fAwoXS47lzAQOD0tv28L+Ho9WyVjh893DpbZSIiIiIigWvSaIKa/58IDkZaNIE6Nmz9LabmJ6IDdc2IDkjGYZqvsWIiIiIyhv2JFGFdPs2sHix9Hj+fEClKr1tbwrZhOSMZPja+aKJW5PS2zARERERFQsmSVQhzZoFZGQAHToA7dqV7rb/uPgHAOneSKrSzM6IiIiIqFgwSaIK5+pV4Pffpcfz5pXutiMTIrHr1i4AwKt1Xy3djRMRERFRsWCSRBXO9OmARgP06gU0bly62159eTU0QoOm7k3ha+dbuhsnIiIiomLBJIkqlNOngQ0bpGuQ5s4t/e3/cUkaavd63ddLf+NEREREVCyYJFGFMmWK9P9rrwG1a5futoUQ+KjZR+hWoxv61+5fuhsnIiIiomLD+sRUYezfD+zcCRgZSYUbSptKpcKgOoMwqE4p3rWWiIiIiIode5KoQhAC+OQT6fGIEYC3t37jISIiIqLyi0kSVQhbtgDHjgFmZsDUqaW//dMPTuPTw5/ibtzd0t84ERERERUrDrejck+j0V2L9P77gItL6cew5MwSLD27FNejr+PX//1a+gEQERERUbFhTxKVe2vWABcvAjY2wMSJpb/91MxUrL2yFgCr2hERERFVBEySqFzLyACmTZMeT5gA2NmVfgxbw7YiLi0O7tbuCPIKKv0AiIiIiKhYMUmicm3ZMuDmTcDJCRg7Vj8xrLi4AgAw+KXBUKv4liIiIiIq7/iNjsqtlBRdqe8pUwBLy9KP4WnKU2y5vgUA8Frd10o/ACIiIiIqdkySqNz68UfgwQOgWjVg5Ej9xLDuyjpkaDJQr2o91KlaRz9BEBEREVGxYpJE5VJ8PLBggfR45kzAxEQ/cUQlR8HM0Iy9SEREREQVCEuAU7n09ddAdDTg7w+8rseCclNaT8H7Td6HgNBfEERERERUrJgkUbnz5Anw1VfS4zlzAEM9H8VWJlb6DYCIiIiIihWH21G58+mnQGIiEBgI9OmjnxiEELj25Jp+Nk5EREREJYpJEpUr9+4B//d/0uN58wCVSj9xnIk8g4AfA9Dsl2bQCI1+giAiIiKiEsEkicqVOXOAtDQgKAjo1El/cfxx8Q8AgJetF++NRERERFTB8NsdlRvXrwO//io91mcvUqYmE39e/hMA8FodVrUjIiIiqmiYJFG5MWMGkJUFdOsGtGihvzh239qNx0mP4WjuiE4+euzOIiIiIqISwSSJyoULF4DVq6XH8+bpNxbtULuBLw2EkYGRfoMhIiIiomLHJInKhSlTpP8HDgTq1dNfHInpifgr5C8A4A1kiYiIiCqoYkmS4uPjsWnTJly7xpLIVPyOHAG2bAEMDIDZs/Uby98hfyM5Ixk17GrgZdeX9RsMEREREZWIQt2Gs3///mjdujXGjBmDlJQUNGrUCLdv34YQAqtXr0Yffd28hiocIYBPPpEeDx8O1Kih33j61+4PaxNrpGelQ6WvyhFEREREVKIK1ZN08OBBtGrVCgDw119/QQiB2NhYfPfdd5g7d26xBkiV286dwMGDgIkJMH26vqMBjAyM0MOvB/oE8IcAIiIiooqqUElSXFwc7OzsAADbt29Hnz59YG5ujm7duiEsLKxYA6TKS6PR9SK9+y7g7q7feIiIiIiocihUkuTh4YFjx44hKSkJ27dvR6f/7uoZExMDU1PTYg2QKq+NG4GzZwFLS2DyZH1HA/Ra3QtT9kzBk6Qn+g6FiIiIiEpQoZKkcePG4dVXX4W7uztcXFzQpk0bANIwvDp16hRnfFRJZWYCU6dKjz/8EHBw0G88Vx5fwd+hf+Pzo59DrWJRSCIiIqKKrFCFG0aPHo3GjRvj3r176NixI9Rq6Utj9erVeU0SFYsVK4DQUMDeHvjgA31HA6y8tBIA0LVGV9ib2+s5GiIiIiIqSYVKkgCgUaNGqFu3LsLDw+Hj4wNDQ0N069atOGOjSiotDZg5U3o8eTJgba3XcKARGjlJer3u6/oNhoiIiIhKXKHGDSUnJ+PNN9+Eubk5ateujbt37wIA3nvvPXz66afFGiBVPj/9BNy9C7i5AaNH6zsa4PDdw7gbdxfWJtboXrO7vsMhIiIiohJWqCRp8uTJuHDhAvbv368o1NChQwesWbOm2IKjyicxEdCO2Jw+HTAz0288ALDiwgoAQL+AfjA1ZGESIiIiooquUMPtNm3ahDVr1qBp06aKG2rWrl0bN2/eLLbgqPL59lvgyRPA1xd44w19RwOkZqZi3dV1AIDX6r6m52iIiIiIqDQUqifpyZMncHJyyjE9KSlJkTQRFcTTp8AXX0iPZ88GjIz0Gw8AJKYnYuBLA1Gvaj209myt73CIiIiIqBQUKklq1KgRtmzZIv+tTYx+/vlnNGvWrHgio0rn88+BuDigbl1gwAB9RyNxMHfA4u6LcW7kOZb+JiIiIqokCjXcbv78+ejSpQuuXr2KzMxMfPvtt7h69SqOHj2KAwcOFHeMVAlERgLffSc9njcPUJexfIQ9pERERESVR6G+irZs2RIXLlxAZmYm6tSpg507d8LJyQnHjh1DYGBgccdIlcDcuUBKCtCsGVBWKskfunMIx+4dgxBC36EQERERUSkqcE9SRkYGRo4ciWnTpmHp0qUlERNVMrduAUuWSI8XLADKSqfN5D2TceTeESzqtgjvNHpH3+EQERERUSkpcE+SkZERNmzYUBKxUCU1cyaQmQl06gQEBek7GsmtmFs4cu8I1Co1evr11Hc4RERERFSKCjXcrlevXti0aVMxh0KV0ZUrwB9/SI/nz9dvLNmtvLgSANDeuz1crVz1HA0RERERlaZCFW6oUaMGZs+ejSNHjiAwMBAWFhaK9vfff79YgqOKb+pUQAigTx+grFzOJoTAH5ekzI33RiIiIiKqfAqVJP3yyy+wtbXFmTNncObMGUWbSqVikkT5cvIksGmTVMluzhx9R6Nz+sFpXI++DjNDM7zi/4q+wyEiIiKiUlaoJCk8PLy446BK6JNPpP+HDAFq1dJvLNn9cVHqRerl3wtWJlZ6joaIiIiISluR70YjhGCJZCqwPXukf0ZGUuGGsuTIvSMAgNfrvq7nSIiIiIhIHwqdJP3++++oU6cOzMzMYGZmhrp162LFihXFGRtVUELoepHeeQfw9NRvPM86OeIk9g3dhw7VO+g7FCIiIiLSg0INt/v6668xbdo0jBkzBi1atAAAHD58GO+88w6ioqIwfvz4Yg2SKpbNm6XrkczNgSlT9B1NTmqVGm282ug7DCIiIiLSk0IlSd9//z0WLVqEIUOGyNN69uyJ2rVrY+bMmUySKE9ZWbrEaNw4oGpVvYajkJ6VDrVKDUN1od4WRERERFRBFGq4XWRkJJo3b55jevPmzREZGVnkoKji+vNP6d5ItrbAhAn6jkZp9eXVcPvaDV8c+ULfoRARERGRHhUqSfL19cXatWtzTF+zZg1q1KhR5KCoYkpPB6ZPlx5//LGUKJUlf1z8A4+THiMtK03foRARERGRHhVqXNGsWbMwYMAAHDx4UL4m6ciRI9izZ0+uyRMRAPzyCxAeDjg7A++9p+9olB4kPMCe8D0AgMF1Bus5GiIiIiLSp0L1JPXp0wcnTpyAg4MDNm3ahE2bNsHBwQEnT57EK6/w5puUU3Ky7oaxU6cCFhb6jedZqy+vhkZo0MKjBapXqa7vcIiIiIhIjwp9hXpgYCD++OOP4oyFKrAffgAiIwEvL2DECH1Hk9OKi1L5+tfqvqbnSIiIiIhI3wrVk7R161bs2LEjx/QdO3Zg27ZtRQ6KKpbYWODTT6XHs2YBxsZ6DSeHy48v4/zD8zBSG6FfQD99h0NEREREelaoJGnSpEnIysrKMV0IgUmTJhU5KKpYvvoKiIkBAgKAV1/VdzQ5rby4EgDQtUZX2Jvb6zkaIiIiItK3Qg23CwsLQ0BAQI7p/v7+uHHjRpGDoorj8WPgm2+kx3PnAgYG+o0nN//f3p3HR1Xd/x9/TyYrBBLWhJSQIAHCErYoEAoulR1RcGdVRLFfra1f5Ve01S+g3xZrcXlUrRVEoFBEK0rRohKp0CoRIvtmgACyJewQQiDb3N8f801MTAJJZrl3Zl7PxyOP3Llz59xPwnkob86554xNGatiR7Fubnuz2aUAAADAAuo1khQVFaX9+/dXOb9v3z41rMMT+TNmzJDNZqv0lZycXOU6wzA0bNgw2Ww2LV++vD4lwyS//7108aJ03XXSqFFmV1O9lJgUzR48W8PaDzO7FAAAAFhAvULSbbfdpscff1zZ2dnl5/bt26cnn3xSt956a53a6tKli3Jycsq/vvrqqyrXvPrqq7LZbPUpFSY6dEh6803n8e9/L/FHCAAAAF9Qr5D04osvqmHDhkpOTlbbtm3Vtm1bJScnq1mzZpo9e3ad2goODlZsbGz5V/PmzSu9v2XLFr300kt655136lMqTDRzpnMD2Ztukm624Ey2yyWX9eCKB7Uqe5UchsPscgAAAGAR9XomKSoqSuvWrVN6erq2bt2qiIgIde/eXQMGDKhzW3v37lVcXJzCw8OVlpamWbNmqU2bNpKkgoICjR07Vm+88YZiY2Nr1V5hYaEKCwvLX+fl5UmSiouLVVxcXOf6qlPWjrva80dZWdKCBcGSbHruuRKVlBhml1TF8t3LNW/zPKVnp2vPo3sUZKvXvxnUGf0H9UXfgSvoP3AF/QeusFL/qW0NNsMwav2314yMDJ0+fVq33HJL+bmFCxdq+vTpKigo0KhRo/Taa68pLCysVu19+umnys/PV8eOHZWTk6OZM2fq6NGj2rFjhxo1aqSHH35YpaWlevvtt53F2mz66KOPNOoKD7fMmDFDM2fOrHJ+yZIlatCgQW1/VLhg375oPfdcH+Xlhat37xz95jcbzC6pWr/f/3ttyNugO1reoQlxE8wuBwAAAB5WNghz/vx5NW7cuMbr6hSShg0bphtvvFHTpk2TJG3fvl2pqam677771KlTJ/3xj3/Uww8/rBkzZtSr6HPnzikhIUEvv/yyWrRooSeffFKbN29WZGSks9hahKTqRpLi4+N16tSpK/4i6qK4uFjp6ekaNGiQQkJC3NKmPxk/Pkjvv2+XZGjjxhKlpJhdUVWnCk6pzZ/aqMRRoi0PbVHnFlVXa/QU+g/qi74DV9B/4Ar6D1xhpf6Tl5en5s2bXzUk1Wm63ZYtW/T888+Xv166dKl69+6tuXPnSpLi4+M1ffr0eoek6OhodejQQfv27dP27duVnZ2t6OjoStfccccdGjBggNasWVNtG2FhYdWOZIWEhLj9D8UTbfqq77+XTp1yLs5QtgBhWJhNUoi2bZOaN5cSEsyssLLle5arxFGinrE91T2uuyk10H9QX/QduIL+A1fQf+AKK/Sf2t6/TiHp7NmziomJKX+9du1aDRv2w7LJ1113nQ4fPlyXJivJz89Xdna2JkyYoLvvvlsPPvhgpfdTUlL0yiuvaOTIkfW+BzwjMbHqucJCKTX1h9e1H7P0vMXbF0uSxncbb3IlAAAAsJo6PakeExOjAwcOSJKKioq0adMm9e3bt/z9Cxcu1CkdTp06VWvXrtXBgwe1bt06jR49Wna7XWPGjFFsbKy6du1a6UuS2rRpo7Zt29albHjB4sVScA2ROzjY+b5V7D+7X+sOr1OQLUj3dr3X7HIAAABgMXUaSRo+fLieeuop/eEPf9Dy5cvVoEGDSivabdu2Te3atat1e0eOHNGYMWN0+vRptWjRQv3799c333yjFi1a1KUsWMC4cVKnTpVHjsqsXy/16uX9mmpyNO+oOjbrqDZRbRTXKM7scgAAAGAxdQpJzz//vG6//XbdcMMNioyM1MKFCxUaGlr+/jvvvKPBgwfXur2lS5fW5faqwxoTMMGPV1QMCpIcFtx+aEDCAO1+dLfOF543uxQAAABYUJ1CUvPmzfXvf/9b58+fV2RkpOx2e6X3//73v5evRIfAc+KE87vdLr3+uvTOO9Lhw1LLlubWVR2bzabo8GizywAAAIAF1Wv3zKioqCoBSZKaNm1aaWQJgWXvXuf3YcOkn//cOc3u4EGpdWtTy6pkc85mXSq+ZHYZAAAAsLB6hSSgOl9/7fzev7/zu80m1XJfYa8oLi3WkMVDFPtSrHac2GF2OQAAALAoQhLcwjCkdeucxz/9qbm11GRV9iqdLDip8OBwJTdPNrscAAAAWBQhCW5x4ICUmyuFhFS/wp0VlO2NNKbrGAUH1elxPAAAAAQQQhLcomyqXWqqFBFhbi3VySvM0/LvlktiA1kAAABcGSEJbmH1qXYf7f5Il0suq2OzjkptZdGhLgAAAFgCIQluUTaS1K+fuXXUZNG2RZKkCd0myGazmVwNAAAArIyQBJedOyft+L/F4qw4knTy4kl9efBLSdLYlLEmVwMAAACr4+l1uGz9eufqdu3aSTExZldTVYuGLZT1iyytObhGbZu0NbscAAAAWBwhCS6z+lQ7SUpqmqSkpklmlwEAAAAfwHQ7uKwsJFlxqh0AAABQV4QkuKSkxDndTrJmSPqfL/9Ho98brYzDGWaXAgAAAB9BSIJLtm2TLl6UoqKkzp3NrqYyh+HQO5vf0fLvluvYhWNmlwMAAAAfQUiCS8qm2qWlSUEW601rD67V0QtHFR0erREdRphdDgAAAHyExf5aC19j5U1kF29bLEm6q/NdCg8ON7kaAAAA+ApCElxi1ZXtLhVf0ge7P5Akje823uRqAAAA4EsISai3w4edX3a71KeP2dVU9vGej5VXmKeEqAT1b9Pf7HIAAADgQwhJqLeyUaQePaSGDU0tpYqyqXbjUsYpyEY3BwAAQO2xmSzqrex5JKtNtZOkoUlDlZOfo3HdxpldCgAAAHwMIQn1ZuVNZB+57hE9ct0jZpcBAAAAH8Q8JNRLfr60davz2IohCQAAAKgvQhLqZcMGqbRUio+XWrc2u5ofHDx3UPM2zdO5y+fMLgUAAAA+ipCEerHqVLuFWxbqwY8f1PgPWfYbAAAA9UNIQr1YMSQZhqHF252r2t3b9V6TqwEAAICvIiShzhwOKSPDeWylle02HN2gfWf2qUFIA41KHmV2OQAAAPBRhCTU2c6dUl6ec2+kbt3MruYHi7YtkiSNTh6tyNBIk6sBAACAryIkoc7Kptr17SsFW2QR+eLSYi3dsVSSNKHbBJOrAQAAgC8jJKHOyjaRtdLzSJ9nf67Tl04rpmGMbr7mZrPLAQAAgA8jJKHOykaSrPQ80tbcrQqyBWlM1zEKDrLI8BYAAAB8En+bRJ3k5kr790s2m3O6nVX89vrfalLPSTIMw+xSAAAA4OMISaiTsql2KSlSVJS5tfxYXKM4s0sAAACAH2C6HerEilPtzlw6Y3YJAAAA8COEJNSJ1TaRPZJ3RDGzYzR40WAVlRaZXQ4AAAD8ACEJtXbpkrRpk/PYKiHp3e3vqsRRossllxVqDzW7HAAAAPgBQhJq7dtvpeJiKTZWSkw0uxqnsg1kx3cbb3IlAAAA8BeEJNRaxal2Npu5tUjStuPbtP3EdoXaQ3VX57vMLgcAAAB+gpCEWrPaJrKLty2WJN3S4RY1iWhicjUAAADwF4Qk1Iph/BCSrLCyXamjVEu2L5EkjU9hqh0AAADch5CEWsnKkk6flsLDpZ49za5GWnNwjY5eOKom4U00vP1ws8sBAACAH2EzWdRK2ShS795SqAUWkbs27lrNu3WeLhReUFhwmNnlAAAAwI8QklArVttENio8Sg/0fMDsMgAAAOCHmG6HWrHaJrIAAACApxCScFWnTjmfSZKktDRza5Gkqaum6tVvXtWZS2fMLgUAAAB+iOl2uKqMDOf35GSpWTNzazl58aRe/eZVlRqlGpo0VE0jmppbEAAAAPwOI0m4KitNtXtv53sqNUp1bdy1Sm6ebHY5AAAA8EOEJFyVlTaRLdtAlr2RAAAA4CmEJFxRUZGUmek8Nntlu72n92r90fWy2+y6t+u95hYDAAAAv0VIwhVt2iRdviw1by516GBuLWWjSIPaDVJMZIy5xQAAAMBvEZJwRRX3R7LZzKvDMAwt3s5UOwAAAHgeq9vhisqeRzJ7ql1eYZ66x3TXucvnNCp5lLnFAAAAwK8RklAjw7DOynZR4VH68J4PdbnkssKDw80tBgAAAH6N6Xao0f790vHjUkiIdO21ZlfjREACAACApxGSUKOyqXapqVK4idlk98nd2ndmn3kFAAAAIKAQklAjq0y1m75mutq/1l6vZLxibiEAAAAICIQk1MgKIen85fNakbVCknRj4o3mFQIAAICAQUhCtc6dk3budB6bubLdst3LVFhaqM4tOqtHbA/zCgEAAEDAICShWt9841zdrl07KcbEfVsXbVskybk3ks3MjZoAAAAQMAhJqJYVptodOn9Iaw6ukSSNTRlrXiEAAAAIKIQkVKtsZTszQ9K729+VJN2QcIMSohPMKwQAAAABhZCEKkpKpPXrncdmPo/0j6x/SJLGdxtvXhEAAAAIOMFmFwDr2bpVunhRio6WOnc2r47VE1frkz2faFC7QeYVAQAAgIBDSEIVZVPt0tKkIBPHGiNCInRXl7vMKwAAAAABiel2qKJs0QazptoZhiHDMMy5OQAAAAIeIQlVmL2y3eoDq9XpjU760/o/mVMAAAAAApqpIWnGjBmy2WyVvpKTkyVJZ86c0WOPPaaOHTsqIiJCbdq00S9/+UudP3/ezJL93uHD0pEjkt0u9e5tTg2Lty1W1uks7T6525wCAAAAENBMfyapS5cu+uKLL8pfBwc7Szp27JiOHTum2bNnq3Pnzvr+++/185//XMeOHdMHH3xgVrl+r2wUqUcPqWFD79+/oLhAy3Yvk8SqdgAAADCH6SEpODhYsbGxVc537dpVy5YtK3/drl07/e53v9P48eNVUlJSHqbgXmZPtVuRtUL5RflqG91W/eJNXH8cAAAAAcv0pLF3717FxcUpPDxcaWlpmjVrltq0aVPttefPn1fjxo2vGJAKCwtVWFhY/jovL0+SVFxcrOLiYrfUXNaOu9qzkq+/DpZkU58+JSou9v7iCYu2LpIkjekyRiUlJV6/vzf4c/+BZ9F34Ar6D1xB/4ErrNR/aluDzTBxGbFPP/1U+fn56tixo3JycjRz5kwdPXpUO3bsUKNGjSpde+rUKaWmpmr8+PH63e9+V2ObM2bM0MyZM6ucX7JkiRo0aOD2n8GfXLpk17hxw+VwBOnttz9X8+aXvXr/8yXnNWnHJDnk0BvJb+gn4T/x6v0BAADg3woKCjR27NjywZeamBqSfuzcuXNKSEjQyy+/rMmTJ5efz8vL06BBg9S0aVOtWLFCISEhNbZR3UhSfHy8Tp06dcVfRF0UFxcrPT1dgwYNumItvuZf/7Jp6NBgtWljaN8+74/i/PnbP+vxVY/r2lbXat2kdV6/v7f4a/+B59F34Ar6D1xB/4ErrNR/8vLy1Lx586uGJNOn21UUHR2tDh06aN++feXnLly4oKFDh6pRo0b66KOPrvqLDQsLU1hYWJXzISEhbv9D8USbZtqwwfn9pz+1mfJz9Y3vq4ndJ6p/fH+/+r3WxN/6D7yHvgNX0H/gCvoPXGGF/lPb+1sqJOXn5ys7O1sTJkyQ5Ex6Q4YMUVhYmFasWKHw8HCTK/RvZm8i26d1H/Vp3cecmwMAAAD/x9R9kqZOnaq1a9fq4MGDWrdunUaPHi273a4xY8YoLy9PgwcP1sWLFzVv3jzl5eUpNzdXubm5Ki0tNbNsv1RaKmVkOI/NWtkOAAAAsAJTR5KOHDmiMWPG6PTp02rRooX69++vb775Ri1atNCaNWu0fv16SVJSUlKlzx04cECJiYkmVOy/du2S8vKkyEgpJcW79zYMQ8//+3nd2vFWdY/pLpvN5t0CAAAAgApMDUlLly6t8b0bb7xRFlpTwu+VTbXr00fy9hZUGUcyNH3NdP1x3R91fOpxNQhhFUIAAACYx9TpdrAOMzeRXbxtsSTp9k63E5AAAABgOkISJJkXkopKi/TezvckSRO6TfDuzQEAAIBqEJKgnBzpwAHJZnNOt/OmT/d+qjOXzqhVZCvdlHiTd28OAAAAVIOQBK37v31bU1KkqCjv3nvxdudUu7EpY2UPsnv35gAAAEA1CEkwbarducvn9HHWx5Kk8d3Ge/fmAAAAQA0stZkszFE2kuTtTWS/O/WdosKj1LJhS3WP6e7dmwMAAAA1ICQFuEuXpE2bnMfeHknq27qvjvz3ER3JO8LeSAAAALAMptsFuMxMqbhYatVKMmN/3hB7iNo2aev9GwMAAAA1ICQFuIpT7bw5mHMk74gchsN7NwQAAABqiZAU4MxYtMEwDA1ZPEQJryYo82im924MAAAA1ALPJAUwh+OHkSRvhqStx7dq18ldCrOHqX2z9t67MQAAAFALjCQFsD17pDNnpPBwqUcP79130dZFkqRbO96q6PBo790YAAAAqAVCUgArm2rXu7cUGuqde5Y6SrVkxxJJ7I0EAAAAayIkBTAznkf614F/KTc/V80immlo0lDv3RgAAACoJUJSADPjeaTF2xdLku7pco9C7V4avgIAAADqgJAUoE6dkrKynMdpad65Z0FxgT7c/aEkptoBAADAuljdLkCVjSJ16iQ1beqde0YERyh9Qro+2fOJ+rbu652bAgAAAHVESApQZky1s9ls6tu6LwEJAAAAlsZ0uwBVtmhDv37m1gEAAABYDSEpABUWSpmZzmNvjSS9s/kdTfl4ijblbPLODQEAAIB6YrpdANq82RmUmjeX2rf3zj3/8u1flHksU91iuqlXq17euSkAAABQD4wkBaCKU+1sNs/fL+tUljKPZcpus+ueLvd4/oYAAACACwhJAcjbm8gu3ubcG2lo0lC1aNjCOzcFAAAA6omQFGAMw7sr2xmGUb6BLHsjAQAAwBcQkgLM/v3S8eNSaKiUmur5+607vE4Hzx1UZGikbu14q+dvCAAAALiIkBRgyqbapaZK4eGev1/ZVLs7Ot2hBiENPH9DAAAAwEWEpADj7U1kr2lyjRKiEphqBwAAAJ/BEuABxtubyP6/n/4/PdnvSe/cDAAAAHADQlIAOXdO2rnTeeytkCRJQTYGLAEAAOA7+NtrAMnIcK5ul5QkxcR49l7nLp/TiqwVKiot8uyNAAAAADcjJAWQsueRvDGK9MGuD3Tb0ts0eNFgz98MAAAAcCNCUgDx5iayi7YtkiQNbz/c8zcDAAAA3IiQFCCKi6X1653Hng5Jf9v2N/37+39LksZ0HePZmwEAAABuRkgKENu2SQUFUnS01KmT5+5jGIamfTFNktQotJFaN27tuZsBAAAAHkBIChBlU+3S0qQgD/6pf77vcx29cFSSdKHoglZlr/LczQAAAAAPICQFCG88j2QYhp5M/2FPJLvNrme/fFaGYXjupgAAAICbEZIChDdWtluVvUq7Tu4qf11qlCrzWCajSQAAAPAphKQAcOiQdOSIZLdLvXt75h6GYejZL5+V3WavdJ7RJAAAAPgaQlIAKJtq17On1LChZ+6xKnuVMo9lqtQorXSe0SQAAAD4GkJSAPD0VLuyUaSgGrpTkIIYTQIAAIDPICQFAE8v2lBUWqT9Z/fLIUe17zvk0OG8wyoqLfJMAQAAAIAbBZtdADzrwgVp61bnsadGksKCwzSyw0gt2LpANyXepNmDZ1e5pmXDlgoLDvNMAQAAAIAbEZL83IYNksMhtWkjtfbQvq6Xii9pedZySdK0n05Tr1a9PHMjAAAAwAuYbufnvLE/0ge7PtC5y+eUEJWgQe0Gee5GAAAAgBcQkvycN0LSnE1zJEkP9XpIQTa6FAAAAHwbf6P1Y6Wl0jffOI89FZJ2ndylrw59JbvNrkk9J3nmJgAAAIAXEZL82M6dUl6eFBkpde3qmXvM3ThXknRLh1sU1yjOMzcBAAAAvIiFG/xY2VS7vn2lYA/9SU/rP00xkTFKa53mmRsAAAAAXkZI8mNlm8h68nmk2MhYPdX/Kc/dAAAAAPAyptv5sbKRJE/tjwQAAAD4I0KSn8rJkQ4ckIKCnNPt3C3rVJZu/uvN+mDXB+5vHAAAADARIclPlU21S0mRGjd2f/tzN83Vvw78S3/d+lf3Nw4AAACYiJDkpzw51a6wpFALtiyQJE1JneL+GwAAAAAmIiT5KU9uIvvRdx/p9KXTat24tYYmDXX/DQAAAAATEZL80KVL0qZNzmNPhKQ5G+dIkib3nKzgIBZIBAAAgH8hJPmhzEyppERq1UpKSHBv23tO79GXB79UkC1ID/R8wL2NAwAAABZASPJDFafa2WzubfvtTW9LkoYlDVObqDbubRwAAACwAEKSH/LkJrJ9W/dV/zb9WbABAAAAfosHSvyMw/FDSPLEyna3d7pdt3e6XYZhuL9xAAAAwAIYSfIzWVnSmTNSRITUs6fn7mNz9zw+AAAAwCIISX6m7Hmk3r2lkBD3tbv/7H69nPGyThWccl+jAAAAgAURkvyMp6bazdk4R0+uelL3L7/fvQ0DAAAAFkNI8jOe2ES2qLRI87fMl+TcGwkAAADwZ4QkP3LypLRnj/M4Lc197a7IWqETF08oNjJWt3S4xX0NAwAAABZESPIjGRnO7506SU2buq/duZvmSpIe6PGAQuxufNAJAAAAsCBTQ9KMGTNks9kqfSUnJ5e/f/nyZT366KNq1qyZIiMjdccdd+j48eMmVmxtnphqd+DsAa3KXiVJerDXg+5rGAAAALAo00eSunTpopycnPKvr776qvy9//7v/9bHH3+sv//971q7dq2OHTum22+/3cRqrc0TIentTW9Lkga3G6y2Tdq6r2EAAADAokzfTDY4OFixsbFVzp8/f17z5s3TkiVL9LOf/UySNH/+fHXq1EnffPON+vbt6+1SLa2wUPr2W+exO1e2u1B0QSFBIZrSa4r7GgUAAAAszPSQtHfvXsXFxSk8PFxpaWmaNWuW2rRpo40bN6q4uFgDBw4svzY5OVlt2rRRRkZGjSGpsLBQhYWF5a/z8vIkScXFxSouLnZLzWXtuKs9d9iwwabCwmC1aGEoMbFE7irtpYEv6am0pxQdHm2pn9eXWbH/wDfQd+AK+g9cQf+BK6zUf2pbg6khqU+fPlqwYIE6duyonJwczZw5UwMGDNCOHTuUm5ur0NBQRUdHV/pMTEyMcnNza2xz1qxZmjlzZpXzq1atUoMGDdxaf3p6ulvbc8Xy5e0kdVXbtrn69NMNZpeDWrBS/4Fvoe/AFfQfuIL+A1dYof8UFBTU6jpTQ9KwYcPKj7t166Y+ffooISFB77//viIiIurV5tNPP60nnnii/HVeXp7i4+M1ePBgNW7c2OWaJWcCTU9P16BBgxQSYo3V3ubPt0uSRo1qqeHDh7vc3vH84zpz+Yw6Ne/kcluozIr9B76BvgNX0H/gCvoPXGGl/lM2y+xqTJ9uV1F0dLQ6dOigffv2adCgQSoqKtK5c+cqjSYdP3682meYyoSFhSksLKzK+ZCQELf/oXiizfowjB+W/77+ertCQuwutzlnyxw9/+/n9UTfJ/TSkJdcbg9VWaX/wPfQd+AK+g9cQf+BK6zQf2p7f9NXt6soPz9f2dnZatWqlVJTUxUSEqLVq1eXv5+VlaVDhw4pzZ07pfqB7GzpxAkpNFRKTXW9vRJHieZtnidJ6tuaBTIAAAAQWEwdSZo6dapGjhyphIQEHTt2TNOnT5fdbteYMWMUFRWlyZMn64knnlDTpk3VuHFjPfbYY0pLS2Nlux9Zt875PTVVCg93vb2Ve1fq2IVjatGghW5Lvs31BgEAAAAfYmpIOnLkiMaMGaPTp0+rRYsW6t+/v7755hu1aNFCkvTKK68oKChId9xxhwoLCzVkyBD9+c9/NrNkS3L3/khzNs6RJN3f436F2kPd0ygAAADgI0wNSUuXLr3i++Hh4XrjjTf0xhtveKki3+TOkHTo/CF9uu9TSdKDvR50vUEAAADAx1jqmSTU3blz0s6dzmN3bCL7zuZ35DAcuinxJnVo1sH1BgEAAAAfQ0jycWWr2iUlSS1but7eP7L+IUmakjrF9cYAAAAAH2SpJcBRd+5+HiljcoaWf7dco5NHu6dBAAAAwMcQknxc2cp27gpJ4cHhurfrve5pDAAAAPBBTLfzYcXF0vr1zmNXn0e6XHJZDsPhelEAAACAjyMk+bCtW6WCAik6WurUybW2Xvz6RXV4rYOW7rjyioMAAACAv2O6nQ8rm2rXr58U5ELcLXWU6u1Nb+tw3mGVOkrdUxwAAADgoxhJ8mFliza4OtXu8+zPdTjvsJqEN9Edne9wvTAAAADAhxGSfJRhuG9luzkb50iS7ut+n8KDw12sDAAAAPBthCQfdfiwdPSoZLdLvXvXv52jeUf1yZ5PJEkPpT7kpuoAAAAA30VI8lFlo0g9e0oNGtS/nflb5qvUKFX/Nv3VuUVn9xQHAAAA+DBCko9yx1S7sgUbJGlKryluqAoAAADwfaxu56PcEZKCbEFaNHqRFm5dqDs73+mewgAAAAAfR0jyQRcuSNu2OY9dWdnOZrNpQMIADUgY4J7CAAAAAD/AdDsftH695HBICQnST35idjUAAACAfyEk+SB3TLV7fcPr+uWnv1TWqSz3FAUAAAD4Cabb+aB165zf6zvVzmE49HLGyzpw7oBSW6WqY/OO7isOAAAA8HGMJPmY0lIpI8N5XN+RpNX7V+vAuQOKCovSXV3ucl9xAAAAgB8gJPmYHTucCzdERkopKfVrY+6muZKkCd0mqEGIC5ssAQAAAH6IkORjyqba9e0r2e11//zx/OP66LuPJElTUtkbCQAAAPgxQpKPcXXRhoVbF6rEUaK+rfsqJaaeQ1EAAACAHyMk+RhXQpLDcJRPtZvSi1EkAAAAoDqEJB9y7Jh08KAUFCT16VP3zxeWFOqOTneofdP2urvL3W6vDwAAAPAHhCQfUvY8UkqK1Lhx3T8fERKhFwa+oKxfZKlhaEP3FgcAAAD4CUKSD3HHJrKSZLPZXC8GAAAA8FOEJB/iyiayK7JW6LN9n8lhONxbFAAAAOBnCEk+oqBA2rTJeVzXkSTDMDR11VQN+9swLd622P3FAQAAAH6EkOQjMjOlkhIpLk5KSKjbZ9d+v1Z7z+xVZGikbu90u2cKBAAAAPwEIclHVJxqV9dHiuZsnCNJGtt1rCJDI91cGQAAAOBfCEk+or6LNpwqOKVlu5dJkqaksjcSAAAAcDWEJB/gcPwwklTXkPTXrX9VUWmRerXqpdS4VPcXBwAAAPgZQpIPyMqSzp6VIiKkHj1q/znDMMqn2k3pxSgSAAAAUBuEJB9QNtWud28pJKT2nztx8YRC7CFqGNJQY1LGeKY4AAAAwM8Em10Arq6+zyPFRMZo28+36eC5g2oc1tj9hQEAAAB+iJEkH1Df55EkyWazqW2Ttu4tCAAAAPBjhCSLO3lS2rPHedy3b+0/t+vkLuUX5XumKAAAAMCPEZIsrmwUqXNnqWnT2n3GMAzd9fe7FPdSnNYeXOu54gAAAAA/REiyuPpMtVt3eJ12ndylUqNUPWJ7eKQuAAAAwF8RkiyubNGGfv1q/5k5m5zLft/b5V5FhUd5oCoAAADAfxGSLKywUPr2W+dxbUeSzl46q/d3vi9JmpLK3kgAAABAXRGSLGzjRmdQatFCSkqq3WcWb1usyyWX1S2mm3r/pLdnCwQAAAD8ECHJwsqeR+rXT7LZrn69YRiau2muJGlKrymy1eZDAAAAACohJFlYXTeR/e7Ud9pxYocigiM0rts4zxUGAAAA+LFgswtA9Qyj7iGpU4tO2v+r/dp4bKOiw6M9VhsAAADgzwhJFpWd7dxINjRU6tWr9p9LjE5UYnSix+oCAAAA/B3T7SyqbBTp2mul8PCrX19UWuTZggAAAIAAQUiyqLpMtTMMQ2nz0nTru7dq/9n9ni0MAAAA8HNMt7OoiivbXU3msUxtytmkXSd38SwSAAAA4CJGkizo7Flp507ncW1C0pyNcyRJd3W+S00jmnqwMgAAAMD/EZIsKCPD+b19e6llyytfm1eYp3d3vCtJmpI6xcOVAQAAAP6PkGRBdZlqt2T7EhUUF6hT8076aXwt1woHAAAAUCNCkgXVdtEGwzD01sa3JEkP9XpINpvNw5UBAAAA/o+QZDHFxdL69c7jq4WkjTkbtSV3i0LtoZrYfaLniwMAAAACAKvbWczWrdKlS1J0tJScfOVrOzTroDdHvKmcCzlq1qCZV+oDAAAA/B0hyWLKptr16ycFXWWcr3FYY/382p97vigAAAAggDDdzmLqsoksAAAAAPcjJFmIYVQeSbqS+5ffr798+xddLLro+cIAAACAAEJIspBDh6Rjx6TgYKl375qv25SzSQu3LtSvPvuVLpVc8l6BAAAAQAAgJFlI2ShSz55SgwY1Xzd341xJ0u2dblfzBs29UBkAAAAQOAhJFlKbTWTzi/L1t+1/kyRN6TXFC1UBAAAAgYWQZCG1WbThvR3v6ULRBSU1TdKNiTd6pS4AAAAgkBCSLOLCBWnbNufxlULSnE1zJDlHkWw2mxcqAwAAAAILIcki1q+XHA4pIUGKi6v+mi25W7Th6AaFBIXovh73ebdAAAAAIECwmaxF1GaqnU023dLhFjUKbaSWDVt6pzAAAAAgwBCSLKI2Ial7bHd9POZjlTpKvVMUAAAAEIAsM93uhRdekM1m0+OPP15+Ljc3VxMmTFBsbKwaNmyoXr16admyZeYV6SGlpdI33ziPrxSSytiD7J4tCAAAAAhglghJmZmZeuutt9StW7dK5ydOnKisrCytWLFC27dv1+233667775bmzdvNqlSz9ixw7lwQ6NGUteu1V/zZuab+v7c994tDAAAAAhApoek/Px8jRs3TnPnzlWTJk0qvbdu3To99thj6t27t6655ho988wzio6O1saNG02q1jPKptr17SvZqxkk2nZ8mx5Z+Yg6vt5R5y+f925xAAAAQIAx/ZmkRx99VCNGjNDAgQP1v//7v5Xe69evn9577z2NGDFC0dHRev/993X58mXdeOONNbZXWFiowsLC8td5eXmSpOLiYhUXF7ul5rJ23NXeV1/ZJQWpb99SFRc7qrz/VuZbkqQR7Ueogb2B2+4Lc7i7/yBw0HfgCvoPXEH/gSus1H9qW4OpIWnp0qXatGmTMjMzq33//fff1z333KNmzZopODhYDRo00EcffaSkpKQa25w1a5ZmzpxZ5fyqVavUoEEDt9UuSenp6W5pZ/XqgZIaym5fr5UrT1Z6r9BRqAU7FkiSUopStHLlSrfcE+ZzV/9B4KHvwBX0H7iC/gNXWKH/FBQU1Oo600LS4cOH9atf/Urp6ekKDw+v9ppnn31W586d0xdffKHmzZtr+fLluvvuu/Wf//xHKSkp1X7m6aef1hNPPFH+Oi8vT/Hx8Ro8eLAaN27sltqLi4uVnp6uQYMGKSQkxKW2jh2TTpwIUVCQocceu06NGlV+f9H2RSrYVqDEqEQ9fc/TCrKZPkMSLnJn/0Fgoe/AFfQfuIL+A1dYqf+UzTK7GtNC0saNG3XixAn16tWr/Fxpaan+/e9/6/XXX1dWVpZef/117dixQ126dJEkde/eXf/5z3/0xhtv6C9/+Uu17YaFhSksLKzK+ZCQELf/obijzQ0bnN+7dbOpadOqbb2z5R1J0kOpDykstOrPBd/liT6JwEDfgSvoP3AF/QeusEL/qe39TQtJN998s7Zv317p3KRJk5ScnKxp06aVD4UFBVUeObHb7XI4qj6346vWrXN+79ev6ns7T+zU14e/lt1m16Qek7xbGAAAABCgTAtJjRo1UtcfrXfdsGFDNWvWTF27dlVxcbGSkpL08MMPa/bs2WrWrJmWL1+u9PR0ffLJJyZV7X5X2kR258mdigyN1KBrBqlVo1beLQwAAAAIUKavbleTkJAQrVy5Uk899ZRGjhyp/Px8JSUlaeHChRo+fLjZ5blFQYFUtuVTdSHp7i53a3j74Tpz6Yx3CwMAAAACmKVC0po1ayq9bt++vZYtW2ZOMV6QmSmVlEhxcVKbNtVfExkaqcjQSO8WBgAAAAQwlkozUcWpdjZb5fd2nNghwzC8XxQAAAAQ4AhJJqrpeaTdJ3cr5c0UXTv3WhWVFnm/MAAAACCAEZJM4nBIGRnO4x+vbDd301xJUnzjeIXaQ71cGQAAABDYCEkm+e476exZqUEDqUePH85fLrmshVsXSpKmpE4xpzgAAAAggBGSTFI21a53b6ninlYf7v5QZy6dUXzjeA1pN8Sc4gAAAIAARkgySU2byM7ZOEeSNLnnZNmD7F6uCgAAAAAhySTVLdqw5/Qerf1+rYJsQXqg5wPmFAYAAAAEOEKSCU6ckPbudR6npf1w/t3t70qShrcfrvioeBMqAwAAAGCpzWQDRdmqdp07S02a/HD+meufUe+f9FbTiKbmFAYAAACAkGSGmvZHsgfZNaz9MO8XBAAAAKAc0+1MUF1IKnWUmlMMAAAAgEoISV5WWCh9+63zuGxlu72n9yr+lXg9869nZBiGecUBAAAAICR528aNUlGR1KKFlJTkPPf2preVk5+jzbmbZbPZzC0QAAAACHCEJC+rONXOZpOKSos0f8t8SdKUXlNMrAwAAACAREjyuh9vIvuP7/6hkwUn1SqylUZ0GGFeYQAAAAAkEZK8yjCqLtowZ9McSdLknpMVHMRigwAAAIDZCEle9NFH0smTUnCwlJoqZZ/J1hf7v5BNNk3uNdns8gAAAACIkORVb77p/N6ihRQW5lywQZIGtxusxOhE8woDAAAAUI75XR72/ffSqVPORRq++sp57vx5adMmqYd9nO5LztddPYeaWyQAAACAcoQkD0tMrHquoMA53U7qKuk1LWBrJAAAAMAymG7nYYsXO59Bqk5wsPN9AAAAANZBSPKwceOk9et/dDL6gDR6ov6y8iuNG2dKWQAAAABqQEjyoqCy33bqPKn7Is3d85yp9QAAAACoipDkBS1bSrGxzueQ3nizWCHXvSNJmtRtismVAQAAAPgxQpIXtG4tHTzonHYXd+M/VRyeo5YNWmpSv1vNLg0AAADAjxCSvCQsTFp94AuN/3C8JGlSz0kKtYeaXBUAAACAHyMkeYlhGHpy1ZO6WHxRkjS552STKwIAAABQHUKSl6zKXqVtx7eVv95/dr+J1QAAAACoCSHJCwzD0LNfPiubbJKkIFuQnv3yWRkGu8gCAAAAVkNI8oJV2auUeSxThpyhyGE4lHksU6uyV5lcGQAAAIAfIyR5WNkokt1mr3TebrMzmgQAAABYECHJw8pGkUqN0krnS41SRpMAAAAACyIkeVDZKFJQDb/mIPFsEgAAAGA1hCQPKiot0qHzh+SQo9r3HXLocN5hFZUWebkyAAAAADUJNrsAfxYWHKbMhzJ1suBkjde0bNhSYcFhXqwKAAAAwJUQkjwsPipe8VHxZpcBAAAAoJaYbgcAAAAAFRCSAAAAAKACQhIAAAAAVEBIAgAAAIAKCEkAAAAAUAEhCQAAAAAqICQBAAAAQAWEJAAAAACogJAEAAAAABUQkgAAAACgAkISAAAAAFRASAIAAACACghJAAAAAFABIQkAAAAAKiAkAQAAAEAFhCQAAAAAqICQBAAAAAAVEJIAAAAAoAJCEgAAAABUQEgCAAAAgAqCzS7A0wzDkCTl5eW5rc3i4mIVFBQoLy9PISEhbmsXgYH+g/qi78AV9B+4gv4DV1ip/5RlgrKMUBO/D0kXLlyQJMXHx5tcCQAAAAAruHDhgqKiomp832ZcLUb5OIfDoWPHjqlRo0ay2WxuaTMvL0/x8fE6fPiwGjdu7JY2ETjoP6gv+g5cQf+BK+g/cIWV+o9hGLpw4YLi4uIUFFTzk0d+P5IUFBSk1q1be6Ttxo0bm/4HDd9F/0F90XfgCvoPXEH/gSus0n+uNIJUhoUbAAAAAKACQhIAAAAAVEBIqoewsDBNnz5dYWFhZpcCH0T/QX3Rd+AK+g9cQf+BK3yx//j9wg0AAAAAUBeMJAEAAABABYQkAAAAAKiAkAQAAAAAFRCSAAAAAKACQlIN3njjDSUmJio8PFx9+vTRhg0brnj93//+dyUnJys8PFwpKSlauXKllyqF1dSl7+zcuVN33HGHEhMTZbPZ9Oqrr3qvUFhSXfrP3LlzNWDAADVp0kRNmjTRwIEDr/rfKvi3uvSfDz/8UNdee62io6PVsGFD9ejRQ4sWLfJitbCauv7dp8zSpUtls9k0atQozxYIS6tL/1mwYIFsNlulr/DwcC9We3WEpGq89957euKJJzR9+nRt2rRJ3bt315AhQ3TixIlqr1+3bp3GjBmjyZMna/PmzRo1apRGjRqlHTt2eLlymK2ufaegoEDXXHONXnjhBcXGxnq5WlhNXfvPmjVrNGbMGH355ZfKyMhQfHy8Bg8erKNHj3q5clhBXftP06ZN9dvf/lYZGRnatm2bJk2apEmTJunzzz/3cuWwgrr2nzIHDx7U1KlTNWDAAC9VCiuqT/9p3LixcnJyyr++//57L1ZcCwaq6N27t/Hoo4+Wvy4tLTXi4uKMWbNmVXv93XffbYwYMaLSuT59+hgPP/ywR+uE9dS171SUkJBgvPLKKx6sDlbnSv8xDMMoKSkxGjVqZCxcuNBTJcLCXO0/hmEYPXv2NJ555hlPlAeLq0//KSkpMfr162e8/fbbxn333WfcdtttXqgUVlTX/jN//nwjKirKS9XVDyNJP1JUVKSNGzdq4MCB5eeCgoI0cOBAZWRkVPuZjIyMStdL0pAhQ2q8Hv6pPn0HKOOO/lNQUKDi4mI1bdrUU2XColztP4ZhaPXq1crKytL111/vyVJhQfXtP88995xatmypyZMne6NMWFR9+09+fr4SEhIUHx+v2267TTt37vRGubVGSPqRU6dOqbS0VDExMZXOx8TEKDc3t9rP5Obm1ul6+Kf69B2gjDv6z7Rp0xQXF1flH23g/+rbf86fP6/IyEiFhoZqxIgReu211zRo0CBPlwuLqU//+eqrrzRv3jzNnTvXGyXCwurTfzp27Kh33nlH//jHP7R48WI5HA7169dPR44c8UbJtRJsdgEAANe98MILWrp0qdasWWO5h19hXY0aNdKWLVuUn5+v1atX64knntA111yjG2+80ezSYGEXLlzQhAkTNHfuXDVv3tzscuCD0tLSlJaWVv66X79+6tSpk9566y09//zzJlb2A0LSjzRv3lx2u13Hjx+vdP748eM1PlgfGxtbp+vhn+rTd4AyrvSf2bNn64UXXtAXX3yhbt26ebJMWFR9+09QUJCSkpIkST169NDu3bs1a9YsQlKAqWv/yc7O1sGDBzVy5Mjycw6HQ5IUHBysrKwstWvXzrNFwzLc8fefkJAQ9ezZU/v27fNEifXCdLsfCQ0NVWpqqlavXl1+zuFwaPXq1ZUSb0VpaWmVrpek9PT0Gq+Hf6pP3wHK1Lf/vPjii3r++ef12Wef6dprr/VGqbAgd/33x+FwqLCw0BMlwsLq2n+Sk5O1fft2bdmypfzr1ltv1U033aQtW7YoPj7em+XDZO74709paam2b9+uVq1aearMujN75QgrWrp0qREWFmYsWLDA2LVrlzFlyhQjOjrayM3NNQzDMCZMmGA89dRT5dd//fXXRnBwsDF79mxj9+7dxvTp042QkBBj+/btZv0IMEld+05hYaGxefNmY/PmzUarVq2MqVOnGps3bzb27t1r1o8AE9W1/7zwwgtGaGio8cEHHxg5OTnlXxcuXDDrR4CJ6tp/fv/73xurVq0ysrOzjV27dhmzZ882goODjblz55r1I8BEde0/P8bqdoGtrv1n5syZxueff25kZ2cbGzduNO69914jPDzc2Llzp1k/QhVMt6vGPffco5MnT+p//ud/lJubqx49euizzz4rfyDt0KFDCgr6YRCuX79+WrJkiZ555hn95je/Ufv27bV8+XJ17drVrB8BJqlr3zl27Jh69uxZ/nr27NmaPXu2brjhBq1Zs8bb5cNkde0/b775poqKinTnnXdWamf69OmaMWOGN0uHBdS1/1y8eFGPPPKIjhw5ooiICCUnJ2vx4sW65557zPoRYKK69h+gorr2n7Nnz+qhhx5Sbm6umjRpotTUVK1bt06dO3c260eowmYYhmF2EQAAAABgFfyTAAAAAABUQEgCAAAAgAoISQAAAABQASEJAAAAACogJAEAAABABYQkAAAAAKiAkAQAAAAAFRCSAAAAAKACQhIAAAAAVEBIAgC43f333y+bzSabzabQ0FAlJSXpueeeU0lJidmlXZHNZtPy5cvNLgMAYLJgswsAAPinoUOHav78+SosLNTKlSv16KOPKiQkRE8//XSd2iktLZXNZlNQEP+uBwDwDv6PAwDwiLCwMMXGxiohIUH/9V//pYEDB2rFihUqLCzU1KlT9ZOf/EQNGzZUnz59tGbNmvLPLViwQNHR0VqxYoU6d+6ssLAwHTp0SIWFhZo2bZri4+MVFhampKQkzZs3r/xzO3bs0LBhwxQZGamYmBhNmDBBp06dKn//xhtv1C9/+Uv9+te/VtOmTRUbG6sZM2aUv5+YmChJGj16tGw2W/nr7Oxs3XbbbYqJiVFkZKSuu+46ffHFF5V+1pycHI0YMUIRERFq27atlixZosTERL366qvl15w7d04PPvigWrRoocaNG+tnP/uZtm7d6rbfNwDAfQhJAACviIiIUFFRkX7xi18oIyNDS5cu1bZt23TXXXdp6NCh2rt3b/m1BQUF+sMf/qC3335bO3fuVMuWLTVx4kS9++67+tOf/qTdu3frrbfeUmRkpCRnAPnZz36mnj176ttvv9Vnn32m48eP6+67765Uw8KFC9WwYUOtX79eL774op577jmlp6dLkjIzMyVJ8+fPV05OTvnr/Px8DR8+XKtXr9bmzZs1dOhQjRw5UocOHSpvd+LEiTp27JjWrFmjZcuWac6cOTpx4kSle9911106ceKEPv30U23cuFG9evXSzTffrDNnzrj/lw0AcI0BAICb3XfffcZtt91mGIZhOBwOIz093QgLCzPuv/9+w263G0ePHq10/c0332w8/fTThmEYxvz58w1JxpYtW8rfz8rKMiQZ6enp1d7v+eefNwYPHlzp3OHDhw1JRlZWlmEYhnHDDTcY/fv3r3TNddddZ0ybNq38tSTjo48+uurP16VLF+O1114zDMMwdu/ebUgyMjMzy9/fu3evIcl45ZVXDMMwjP/85z9G48aNjcuXL1dqp127dsZbb7111fsBALyLZ5IAAB7xySefKDIyUsXFxXI4HBo7dqzuvPNOLViwQB06dKh0bWFhoZo1a1b+OjQ0VN26dSt/vWXLFtntdt1www3V3mvr1q368ssvy0eWKsrOzi6/X8U2JalVq1ZVRnx+LD8/XzNmzNA///lP5eTkqKSkRJcuXSofScrKylJwcLB69epV/pmkpCQ1adKkUn35+fmVfkZJunTpkrKzs694fwCA9xGSAAAecdNNN+nNN99UaGio4uLiFBwcrPfee092u10bN26U3W6vdH3FgBMRESGbzVbp9ZXk5+dr5MiR+sMf/lDlvVatWpUfh4SEVHrPZrPJ4XBcse2pU6cqPT1ds2fPVlJSkiIiInTnnXeqqKjoip/7cX2tWrWq9OxVmejo6Fq3AwDwDkISAMAjGjZsqKSkpErnevbsqdLSUp04cUIDBgyodVspKSlyOBxau3atBg4cWOX9Xr16admyZUpMTFRwcP3/1xYSEqLS0tJK577++mvdf//9Gj16tCRn4Dl48GD5+x07dlRJSYk2b96s1NRUSdK+fft09uzZSvXl5uYqODi4fEEIAIB1sXADAMBrOnTooHHjxmnixIn68MMPdeDAAW3YsEGzZs3SP//5zxo/l5iYqPvuu08PPPCAli9frgMHDmjNmjV6//33JUmPPvqozpw5ozFjxigzM1PZ2dn6/PPPNWnSpCqh50oSExO1evVq5ebmloec9u3b68MPP9SWLVu0detWjR07ttLoU3JysgYOHKgpU6Zow4YN2rx5s6ZMmVJpNGzgwIFKS0vTqFGjtGrVKh08eFDr1q3Tb3/7W3377bf1+VUCADyIkAQA8Kr58+dr4sSJevLJJ9WxY0eNGjVKmZmZatOmzRU/9+abb+rOO+/UI488ouTkZD300EO6ePGiJCkuLk5ff/21SktLNXjwYKWkpOjxxx9XdHR0nfZXeumll5Senq74+Hj17NlTkvTyyy+rSZMm6tevn0aOHKkhQ4ZUev5Ikv76178qJiZG119/vUaPHq2HHnpIjRo1Unh4uCTntL6VK1fq+uuv16RJk9ShQwfde++9+v777xUTE1OXXx8AwAtshmEYZhcBAIA/OXLkiOLj4/XFF1/o5ptvNrscAEAdEZIAAHDRv/71L+Xn5yslJUU5OTn69a9/raNHj2rPnj1VFosAAFgfCzcAAOCi4uJi/eY3v9H+/fvVqFEj9evXT3/7298ISADgoxhJAgAAAIAKWLgBAAAAACogJAEAAABABYQkAAAAAKiAkAQAAAAAFRCSAAAAAKACQhIAAAAAVEBIAgAAAIAKCEkAAAAAUMH/B9UfuMCjHFNqAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"markdown","source":"### Define Adapter Model","metadata":{}},{"cell_type":"code","source":"from transformers import BertModel,BertForSequenceClassification\nclass AdapterLayer(nn.Module):\n    def __init__(self, input_size, adapter_size):\n        super(AdapterLayer, self).__init__()\n        self.down_project = nn.Linear(input_size, adapter_size)\n        self.up_project = nn.Linear(adapter_size, input_size)\n\n    def forward(self, x):\n        down_projected = self.down_project(x)\n        activated = nn.functional.relu(down_projected)\n        up_projected = self.up_project(activated)\n        return x + up_projected\n\nclass BertWithAdapters(BertModel):\n    def __init__(self, config):\n        super(BertWithAdapters, self).__init__(config)\n        self.adapters = nn.ModuleList([AdapterLayer(config.hidden_size, adapter_size=64) for _ in range(config.num_hidden_layers)])\n        self.logit = nn.Linear(768, 6)\n        self.softmax = nn.Softmax(dim=-1)\n        \n    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n        outputs = super().forward(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        sequence_output = outputs.last_hidden_state\n\n        for adapter_layer in self.adapters:\n            sequence_output = adapter_layer(sequence_output)\n        output = sequence_output.mean(dim = 1 )\n        output = self.logit(output)\n        return self.softmax(output)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T14:34:08.886356Z","iopub.execute_input":"2024-02-02T14:34:08.887180Z","iopub.status.idle":"2024-02-02T14:34:08.899873Z","shell.execute_reply.started":"2024-02-02T14:34:08.887139Z","shell.execute_reply":"2024-02-02T14:34:08.898862Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Bert Classifier With Adapter","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW, BertConfig, BertForSequenceClassification, BertTokenizer\nfrom sklearn.metrics import accuracy_score,f1_score, classification_report\nimport time\nimport warnings\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n### Deffine Bert Tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\ncriterion = nn.CrossEntropyLoss()\n### Hyper Parameters \npercentages = [0.01, 0.05, 0.1, 0.5]\nbatch_size = 16\nnum_epochs = 10\nprinter_controler = 0\naccuracies = []\nbest_accuracy = 0\nweighted_f1s = []\nbest_weighted_f1 = 0\nnum_workers = 2\n### Using 1,5,10,50 %  of Training Data\nfor percentage in percentages:\n    printer_controler += 1 \n    print(\"#\"* 80)\n    print(f\"\\033[1m Percentage of training data = {percentage * 100 } % \\033[0m\") \n    ### Load Bert classifier and optimizer \n    model = BertWithAdapters.from_pretrained('bert-base-cased', num_labels = 6 ).to(device)\n    optimizer = AdamW(model.parameters(), lr=1e-5)\n    max_length = 256\n    ### Define Train and Validation Dataset\n    train_dataset = CustomDataset(data_list, tokenizer = tokenizer, max_length = max_length, percentage = percentage )\n    test_dataset = CustomDataset(test_list, tokenizer = tokenizer, max_length = max_length, percentage = 1)\n    # Create Train & Validation DataLoader \n    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n    valid_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=True)\n    \n    # Training loop\n    ### Calculate Time\n    start_time = time.time() \n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        train_labels = []\n        train_predictions = []\n        for (idx,batch) in enumerate(dataloader):\n            ### Using Gpu Device\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            optimizer.zero_grad()\n            ### Define loss of Classifier and EBP\n            outputs = model(input_ids = input_ids ,attention_mask = attention_mask)\n            predictions = torch.argmax(outputs, dim=1)\n            loss = criterion(outputs, labels)\n            ### Calculate Accuracy on Train Data\n            train_labels.extend(labels.cpu().numpy())\n            train_predictions.extend(predictions.cpu().numpy())\n            total_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            if (idx+1) % ( 10 * printer_controler )  == 0 :\n                end_time = time.time()  \n                training_time = end_time - start_time \n                training_time = str(datetime.timedelta(seconds=int(training_time)))\n                print(f\"Epoch = {epoch+1}, Iteration = {idx + 1 }/ {len(dataloader)}  ===> Average training loss = , {'{:.3f}'.format(total_loss/(idx )) }, Training Time: {training_time}\" ) \n        \n        train_accuracy = accuracy_score(train_labels, train_predictions)\n\n        print(f\"Epoch = {epoch+1} ===> training_accuracy ={'{:.3f}'.format(train_accuracy) } \" )\n        \n        model.eval()\n        all_labels = []\n        all_predictions = []\n        with torch.no_grad():\n            for batch in valid_dataloader:\n                input_ids, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n                outputs = model(input_ids, attention_mask=attention_mask)\n                predictions = torch.argmax(outputs, dim=1)\n                all_labels.extend(labels.cpu().numpy())\n                all_predictions.extend(predictions.cpu().numpy())\n            accuracy = accuracy_score(all_labels, all_predictions)\n            best_accuracy = max(accuracy, best_accuracy)\n            if accuracy == best_accuracy :\n                output_dir = f\"/kaggle/working/best_model_for_{percentage*100}_percentage\"\n                model.save_pretrained(output_dir)\n        weighted_f1 = f1_score(all_labels, all_predictions, average='weighted')\n        print(f'Weighted F1 Score: {weighted_f1:.4f}')\n        best_weighted_f1 = max(weighted_f1, best_weighted_f1)\n        f1_per_class = f1_score(all_labels, all_predictions, average = None)\n        print(f\"\\033[1mEpoch = {epoch+1} ====> Accuracy On Validation Dataset={'{:.3f}'.format(accuracy) }\\033[0m\")\n        \n        for class_idx, f1 in enumerate(f1_per_class):\n            print(f'F1 Score (Class {inverted_label_map[class_idx]}): {f1:.4f}')\n        print()\n    accuracies.append(best_accuracy)\n    weighted_f1s.append(best_weighted_f1)\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-02-02T14:34:13.671055Z","iopub.execute_input":"2024-02-02T14:34:13.671408Z","iopub.status.idle":"2024-02-02T18:15:26.750615Z","shell.execute_reply.started":"2024-02-02T14:34:13.671379Z","shell.execute_reply":"2024-02-02T18:15:26.749563Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"################################################################################\n\u001b[1m Percentage of training data = 1.0 % \u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8851a2b877be4f609eea27c31b169768"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertWithAdapters were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['bert.adapters.0.down_project.bias', 'bert.adapters.0.down_project.weight', 'bert.adapters.0.up_project.bias', 'bert.adapters.0.up_project.weight', 'bert.adapters.1.down_project.bias', 'bert.adapters.1.down_project.weight', 'bert.adapters.1.up_project.bias', 'bert.adapters.1.up_project.weight', 'bert.adapters.10.down_project.bias', 'bert.adapters.10.down_project.weight', 'bert.adapters.10.up_project.bias', 'bert.adapters.10.up_project.weight', 'bert.adapters.11.down_project.bias', 'bert.adapters.11.down_project.weight', 'bert.adapters.11.up_project.bias', 'bert.adapters.11.up_project.weight', 'bert.adapters.2.down_project.bias', 'bert.adapters.2.down_project.weight', 'bert.adapters.2.up_project.bias', 'bert.adapters.2.up_project.weight', 'bert.adapters.3.down_project.bias', 'bert.adapters.3.down_project.weight', 'bert.adapters.3.up_project.bias', 'bert.adapters.3.up_project.weight', 'bert.adapters.4.down_project.bias', 'bert.adapters.4.down_project.weight', 'bert.adapters.4.up_project.bias', 'bert.adapters.4.up_project.weight', 'bert.adapters.5.down_project.bias', 'bert.adapters.5.down_project.weight', 'bert.adapters.5.up_project.bias', 'bert.adapters.5.up_project.weight', 'bert.adapters.6.down_project.bias', 'bert.adapters.6.down_project.weight', 'bert.adapters.6.up_project.bias', 'bert.adapters.6.up_project.weight', 'bert.adapters.7.down_project.bias', 'bert.adapters.7.down_project.weight', 'bert.adapters.7.up_project.bias', 'bert.adapters.7.up_project.weight', 'bert.adapters.8.down_project.bias', 'bert.adapters.8.down_project.weight', 'bert.adapters.8.up_project.bias', 'bert.adapters.8.up_project.weight', 'bert.adapters.9.down_project.bias', 'bert.adapters.9.down_project.weight', 'bert.adapters.9.up_project.bias', 'bert.adapters.9.up_project.weight', 'bert.logit.bias', 'bert.logit.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch = 1, Iteration = 10/ 45  ===> Average training loss = , 1.989, Training Time: 0:00:05\nEpoch = 1, Iteration = 20/ 45  ===> Average training loss = , 1.886, Training Time: 0:00:09\nEpoch = 1, Iteration = 30/ 45  ===> Average training loss = , 1.850, Training Time: 0:00:13\nEpoch = 1, Iteration = 40/ 45  ===> Average training loss = , 1.835, Training Time: 0:00:16\nEpoch = 1 ===> training_accuracy =0.179 \nWeighted F1 Score: 0.0529\n\u001b[1mEpoch = 1 ====> Accuracy On Validation Dataset=0.156\u001b[0m\nF1 Score (Class bloomz): 0.0310\nF1 Score (Class chatGPT): 0.0040\nF1 Score (Class cohere): 0.0157\nF1 Score (Class davinci): 0.0000\nF1 Score (Class dolly): 0.0000\nF1 Score (Class human): 0.2667\n\nEpoch = 2, Iteration = 10/ 45  ===> Average training loss = , 1.968, Training Time: 0:01:11\nEpoch = 2, Iteration = 20/ 45  ===> Average training loss = , 1.853, Training Time: 0:01:15\nEpoch = 2, Iteration = 30/ 45  ===> Average training loss = , 1.813, Training Time: 0:01:19\nEpoch = 2, Iteration = 40/ 45  ===> Average training loss = , 1.782, Training Time: 0:01:22\nEpoch = 2 ===> training_accuracy =0.335 \nWeighted F1 Score: 0.3819\n\u001b[1mEpoch = 2 ====> Accuracy On Validation Dataset=0.452\u001b[0m\nF1 Score (Class bloomz): 0.7644\nF1 Score (Class chatGPT): 0.5127\nF1 Score (Class cohere): 0.3744\nF1 Score (Class davinci): 0.0000\nF1 Score (Class dolly): 0.0000\nF1 Score (Class human): 0.6398\n\nEpoch = 3, Iteration = 10/ 45  ===> Average training loss = , 1.746, Training Time: 0:02:17\nEpoch = 3, Iteration = 20/ 45  ===> Average training loss = , 1.638, Training Time: 0:02:21\nEpoch = 3, Iteration = 30/ 45  ===> Average training loss = , 1.578, Training Time: 0:02:25\nEpoch = 3, Iteration = 40/ 45  ===> Average training loss = , 1.552, Training Time: 0:02:29\nEpoch = 3 ===> training_accuracy =0.579 \nWeighted F1 Score: 0.4721\n\u001b[1mEpoch = 3 ====> Accuracy On Validation Dataset=0.529\u001b[0m\nF1 Score (Class bloomz): 0.7886\nF1 Score (Class chatGPT): 0.6034\nF1 Score (Class cohere): 0.3384\nF1 Score (Class davinci): 0.0000\nF1 Score (Class dolly): 0.4507\nF1 Score (Class human): 0.6515\n\nEpoch = 4, Iteration = 10/ 45  ===> Average training loss = , 1.541, Training Time: 0:03:23\nEpoch = 4, Iteration = 20/ 45  ===> Average training loss = , 1.448, Training Time: 0:03:27\nEpoch = 4, Iteration = 30/ 45  ===> Average training loss = , 1.411, Training Time: 0:03:31\nEpoch = 4, Iteration = 40/ 45  ===> Average training loss = , 1.406, Training Time: 0:03:35\nEpoch = 4 ===> training_accuracy =0.696 \nWeighted F1 Score: 0.3706\n\u001b[1mEpoch = 4 ====> Accuracy On Validation Dataset=0.436\u001b[0m\nF1 Score (Class bloomz): 0.8287\nF1 Score (Class chatGPT): 0.5241\nF1 Score (Class cohere): 0.3883\nF1 Score (Class davinci): 0.0000\nF1 Score (Class dolly): 0.1541\nF1 Score (Class human): 0.3284\n\nEpoch = 5, Iteration = 10/ 45  ===> Average training loss = , 1.429, Training Time: 0:04:28\nEpoch = 5, Iteration = 20/ 45  ===> Average training loss = , 1.359, Training Time: 0:04:32\nEpoch = 5, Iteration = 30/ 45  ===> Average training loss = , 1.335, Training Time: 0:04:36\nEpoch = 5, Iteration = 40/ 45  ===> Average training loss = , 1.318, Training Time: 0:04:40\nEpoch = 5 ===> training_accuracy =0.796 \nWeighted F1 Score: 0.4372\n\u001b[1mEpoch = 5 ====> Accuracy On Validation Dataset=0.486\u001b[0m\nF1 Score (Class bloomz): 0.7899\nF1 Score (Class chatGPT): 0.5262\nF1 Score (Class cohere): 0.2627\nF1 Score (Class davinci): 0.0447\nF1 Score (Class dolly): 0.3298\nF1 Score (Class human): 0.6700\n\nEpoch = 6, Iteration = 10/ 45  ===> Average training loss = , 1.433, Training Time: 0:05:34\nEpoch = 6, Iteration = 20/ 45  ===> Average training loss = , 1.372, Training Time: 0:05:37\nEpoch = 6, Iteration = 30/ 45  ===> Average training loss = , 1.337, Training Time: 0:05:41\nEpoch = 6, Iteration = 40/ 45  ===> Average training loss = , 1.306, Training Time: 0:05:45\nEpoch = 6 ===> training_accuracy =0.801 \nWeighted F1 Score: 0.4750\n\u001b[1mEpoch = 6 ====> Accuracy On Validation Dataset=0.480\u001b[0m\nF1 Score (Class bloomz): 0.8851\nF1 Score (Class chatGPT): 0.6203\nF1 Score (Class cohere): 0.4341\nF1 Score (Class davinci): 0.0586\nF1 Score (Class dolly): 0.3615\nF1 Score (Class human): 0.4903\n\nEpoch = 7, Iteration = 10/ 45  ===> Average training loss = , 1.316, Training Time: 0:06:39\nEpoch = 7, Iteration = 20/ 45  ===> Average training loss = , 1.238, Training Time: 0:06:43\nEpoch = 7, Iteration = 30/ 45  ===> Average training loss = , 1.208, Training Time: 0:06:47\nEpoch = 7, Iteration = 40/ 45  ===> Average training loss = , 1.198, Training Time: 0:06:51\nEpoch = 7 ===> training_accuracy =0.889 \nWeighted F1 Score: 0.4413\n\u001b[1mEpoch = 7 ====> Accuracy On Validation Dataset=0.464\u001b[0m\nF1 Score (Class bloomz): 0.8828\nF1 Score (Class chatGPT): 0.6490\nF1 Score (Class cohere): 0.4444\nF1 Score (Class davinci): 0.0455\nF1 Score (Class dolly): 0.3083\nF1 Score (Class human): 0.3177\n\nEpoch = 8, Iteration = 10/ 45  ===> Average training loss = , 1.289, Training Time: 0:07:44\nEpoch = 8, Iteration = 20/ 45  ===> Average training loss = , 1.213, Training Time: 0:07:48\nEpoch = 8, Iteration = 30/ 45  ===> Average training loss = , 1.184, Training Time: 0:07:52\nEpoch = 8, Iteration = 40/ 45  ===> Average training loss = , 1.160, Training Time: 0:07:56\nEpoch = 8 ===> training_accuracy =0.920 \nWeighted F1 Score: 0.4987\n\u001b[1mEpoch = 8 ====> Accuracy On Validation Dataset=0.497\u001b[0m\nF1 Score (Class bloomz): 0.8772\nF1 Score (Class chatGPT): 0.5362\nF1 Score (Class cohere): 0.4499\nF1 Score (Class davinci): 0.0658\nF1 Score (Class dolly): 0.4457\nF1 Score (Class human): 0.6172\n\nEpoch = 9, Iteration = 10/ 45  ===> Average training loss = , 1.242, Training Time: 0:08:49\nEpoch = 9, Iteration = 20/ 45  ===> Average training loss = , 1.169, Training Time: 0:08:53\nEpoch = 9, Iteration = 30/ 45  ===> Average training loss = , 1.144, Training Time: 0:08:57\nEpoch = 9, Iteration = 40/ 45  ===> Average training loss = , 1.135, Training Time: 0:09:01\nEpoch = 9 ===> training_accuracy =0.948 \nWeighted F1 Score: 0.4064\n\u001b[1mEpoch = 9 ====> Accuracy On Validation Dataset=0.445\u001b[0m\nF1 Score (Class bloomz): 0.8816\nF1 Score (Class chatGPT): 0.2721\nF1 Score (Class cohere): 0.4202\nF1 Score (Class davinci): 0.0112\nF1 Score (Class dolly): 0.4239\nF1 Score (Class human): 0.4292\n\nEpoch = 10, Iteration = 10/ 45  ===> Average training loss = , 1.216, Training Time: 0:09:55\nEpoch = 10, Iteration = 20/ 45  ===> Average training loss = , 1.142, Training Time: 0:09:58\nEpoch = 10, Iteration = 30/ 45  ===> Average training loss = , 1.122, Training Time: 0:10:02\nEpoch = 10, Iteration = 40/ 45  ===> Average training loss = , 1.115, Training Time: 0:10:06\nEpoch = 10 ===> training_accuracy =0.963 \nWeighted F1 Score: 0.4122\n\u001b[1mEpoch = 10 ====> Accuracy On Validation Dataset=0.436\u001b[0m\nF1 Score (Class bloomz): 0.8696\nF1 Score (Class chatGPT): 0.5594\nF1 Score (Class cohere): 0.4313\nF1 Score (Class davinci): 0.0423\nF1 Score (Class dolly): 0.2286\nF1 Score (Class human): 0.3421\n\n################################################################################\n\u001b[1m Percentage of training data = 5.0 % \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertWithAdapters were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['bert.adapters.0.down_project.bias', 'bert.adapters.0.down_project.weight', 'bert.adapters.0.up_project.bias', 'bert.adapters.0.up_project.weight', 'bert.adapters.1.down_project.bias', 'bert.adapters.1.down_project.weight', 'bert.adapters.1.up_project.bias', 'bert.adapters.1.up_project.weight', 'bert.adapters.10.down_project.bias', 'bert.adapters.10.down_project.weight', 'bert.adapters.10.up_project.bias', 'bert.adapters.10.up_project.weight', 'bert.adapters.11.down_project.bias', 'bert.adapters.11.down_project.weight', 'bert.adapters.11.up_project.bias', 'bert.adapters.11.up_project.weight', 'bert.adapters.2.down_project.bias', 'bert.adapters.2.down_project.weight', 'bert.adapters.2.up_project.bias', 'bert.adapters.2.up_project.weight', 'bert.adapters.3.down_project.bias', 'bert.adapters.3.down_project.weight', 'bert.adapters.3.up_project.bias', 'bert.adapters.3.up_project.weight', 'bert.adapters.4.down_project.bias', 'bert.adapters.4.down_project.weight', 'bert.adapters.4.up_project.bias', 'bert.adapters.4.up_project.weight', 'bert.adapters.5.down_project.bias', 'bert.adapters.5.down_project.weight', 'bert.adapters.5.up_project.bias', 'bert.adapters.5.up_project.weight', 'bert.adapters.6.down_project.bias', 'bert.adapters.6.down_project.weight', 'bert.adapters.6.up_project.bias', 'bert.adapters.6.up_project.weight', 'bert.adapters.7.down_project.bias', 'bert.adapters.7.down_project.weight', 'bert.adapters.7.up_project.bias', 'bert.adapters.7.up_project.weight', 'bert.adapters.8.down_project.bias', 'bert.adapters.8.down_project.weight', 'bert.adapters.8.up_project.bias', 'bert.adapters.8.up_project.weight', 'bert.adapters.9.down_project.bias', 'bert.adapters.9.down_project.weight', 'bert.adapters.9.up_project.bias', 'bert.adapters.9.up_project.weight', 'bert.logit.bias', 'bert.logit.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch = 1, Iteration = 20/ 222  ===> Average training loss = , 1.884, Training Time: 0:00:08\nEpoch = 1, Iteration = 40/ 222  ===> Average training loss = , 1.832, Training Time: 0:00:15\nEpoch = 1, Iteration = 60/ 222  ===> Average training loss = , 1.813, Training Time: 0:00:23\nEpoch = 1, Iteration = 80/ 222  ===> Average training loss = , 1.796, Training Time: 0:00:31\nEpoch = 1, Iteration = 100/ 222  ===> Average training loss = , 1.767, Training Time: 0:00:39\nEpoch = 1, Iteration = 120/ 222  ===> Average training loss = , 1.741, Training Time: 0:00:46\nEpoch = 1, Iteration = 140/ 222  ===> Average training loss = , 1.712, Training Time: 0:00:54\nEpoch = 1, Iteration = 160/ 222  ===> Average training loss = , 1.686, Training Time: 0:01:02\nEpoch = 1, Iteration = 180/ 222  ===> Average training loss = , 1.663, Training Time: 0:01:10\nEpoch = 1, Iteration = 200/ 222  ===> Average training loss = , 1.645, Training Time: 0:01:17\nEpoch = 1, Iteration = 220/ 222  ===> Average training loss = , 1.628, Training Time: 0:01:25\nEpoch = 1 ===> training_accuracy =0.424 \nWeighted F1 Score: 0.4211\n\u001b[1mEpoch = 1 ====> Accuracy On Validation Dataset=0.486\u001b[0m\nF1 Score (Class bloomz): 0.8658\nF1 Score (Class chatGPT): 0.5573\nF1 Score (Class cohere): 0.3986\nF1 Score (Class davinci): 0.0000\nF1 Score (Class dolly): 0.1709\nF1 Score (Class human): 0.5341\n\nEpoch = 2, Iteration = 20/ 222  ===> Average training loss = , 1.468, Training Time: 0:02:22\nEpoch = 2, Iteration = 40/ 222  ===> Average training loss = , 1.416, Training Time: 0:02:29\nEpoch = 2, Iteration = 60/ 222  ===> Average training loss = , 1.399, Training Time: 0:02:37\nEpoch = 2, Iteration = 80/ 222  ===> Average training loss = , 1.398, Training Time: 0:02:45\nEpoch = 2, Iteration = 100/ 222  ===> Average training loss = , 1.410, Training Time: 0:02:53\nEpoch = 2, Iteration = 120/ 222  ===> Average training loss = , 1.403, Training Time: 0:03:00\nEpoch = 2, Iteration = 140/ 222  ===> Average training loss = , 1.397, Training Time: 0:03:08\nEpoch = 2, Iteration = 160/ 222  ===> Average training loss = , 1.393, Training Time: 0:03:16\nEpoch = 2, Iteration = 180/ 222  ===> Average training loss = , 1.391, Training Time: 0:03:24\nEpoch = 2, Iteration = 200/ 222  ===> Average training loss = , 1.390, Training Time: 0:03:31\nEpoch = 2, Iteration = 220/ 222  ===> Average training loss = , 1.383, Training Time: 0:03:39\nEpoch = 2 ===> training_accuracy =0.676 \nWeighted F1 Score: 0.4667\n\u001b[1mEpoch = 2 ====> Accuracy On Validation Dataset=0.483\u001b[0m\nF1 Score (Class bloomz): 0.8811\nF1 Score (Class chatGPT): 0.6123\nF1 Score (Class cohere): 0.4462\nF1 Score (Class davinci): 0.0635\nF1 Score (Class dolly): 0.3121\nF1 Score (Class human): 0.4853\n\nEpoch = 3, Iteration = 20/ 222  ===> Average training loss = , 1.413, Training Time: 0:04:36\nEpoch = 3, Iteration = 40/ 222  ===> Average training loss = , 1.353, Training Time: 0:04:43\nEpoch = 3, Iteration = 60/ 222  ===> Average training loss = , 1.318, Training Time: 0:04:51\nEpoch = 3, Iteration = 80/ 222  ===> Average training loss = , 1.310, Training Time: 0:04:59\nEpoch = 3, Iteration = 100/ 222  ===> Average training loss = , 1.309, Training Time: 0:05:07\nEpoch = 3, Iteration = 120/ 222  ===> Average training loss = , 1.312, Training Time: 0:05:14\nEpoch = 3, Iteration = 140/ 222  ===> Average training loss = , 1.306, Training Time: 0:05:22\nEpoch = 3, Iteration = 160/ 222  ===> Average training loss = , 1.300, Training Time: 0:05:30\nEpoch = 3, Iteration = 180/ 222  ===> Average training loss = , 1.293, Training Time: 0:05:38\nEpoch = 3, Iteration = 200/ 222  ===> Average training loss = , 1.291, Training Time: 0:05:45\nEpoch = 3, Iteration = 220/ 222  ===> Average training loss = , 1.289, Training Time: 0:05:53\nEpoch = 3 ===> training_accuracy =0.767 \nWeighted F1 Score: 0.3936\n\u001b[1mEpoch = 3 ====> Accuracy On Validation Dataset=0.461\u001b[0m\nF1 Score (Class bloomz): 0.9325\nF1 Score (Class chatGPT): 0.5757\nF1 Score (Class cohere): 0.4492\nF1 Score (Class davinci): 0.0000\nF1 Score (Class dolly): 0.2946\nF1 Score (Class human): 0.1096\n\nEpoch = 4, Iteration = 20/ 222  ===> Average training loss = , 1.282, Training Time: 0:06:50\nEpoch = 4, Iteration = 40/ 222  ===> Average training loss = , 1.239, Training Time: 0:06:57\nEpoch = 4, Iteration = 60/ 222  ===> Average training loss = , 1.239, Training Time: 0:07:05\nEpoch = 4, Iteration = 80/ 222  ===> Average training loss = , 1.232, Training Time: 0:07:13\nEpoch = 4, Iteration = 100/ 222  ===> Average training loss = , 1.225, Training Time: 0:07:21\nEpoch = 4, Iteration = 120/ 222  ===> Average training loss = , 1.228, Training Time: 0:07:28\nEpoch = 4, Iteration = 140/ 222  ===> Average training loss = , 1.226, Training Time: 0:07:36\nEpoch = 4, Iteration = 160/ 222  ===> Average training loss = , 1.228, Training Time: 0:07:44\nEpoch = 4, Iteration = 180/ 222  ===> Average training loss = , 1.226, Training Time: 0:07:51\nEpoch = 4, Iteration = 200/ 222  ===> Average training loss = , 1.225, Training Time: 0:07:59\nEpoch = 4, Iteration = 220/ 222  ===> Average training loss = , 1.219, Training Time: 0:08:07\nEpoch = 4 ===> training_accuracy =0.837 \nWeighted F1 Score: 0.5231\n\u001b[1mEpoch = 4 ====> Accuracy On Validation Dataset=0.524\u001b[0m\nF1 Score (Class bloomz): 0.9042\nF1 Score (Class chatGPT): 0.5624\nF1 Score (Class cohere): 0.4880\nF1 Score (Class davinci): 0.1307\nF1 Score (Class dolly): 0.4668\nF1 Score (Class human): 0.5866\n\nEpoch = 5, Iteration = 20/ 222  ===> Average training loss = , 1.221, Training Time: 0:09:03\nEpoch = 5, Iteration = 40/ 222  ===> Average training loss = , 1.186, Training Time: 0:09:11\nEpoch = 5, Iteration = 60/ 222  ===> Average training loss = , 1.177, Training Time: 0:09:19\nEpoch = 5, Iteration = 80/ 222  ===> Average training loss = , 1.178, Training Time: 0:09:27\nEpoch = 5, Iteration = 100/ 222  ===> Average training loss = , 1.171, Training Time: 0:09:34\nEpoch = 5, Iteration = 120/ 222  ===> Average training loss = , 1.172, Training Time: 0:09:42\nEpoch = 5, Iteration = 140/ 222  ===> Average training loss = , 1.176, Training Time: 0:09:50\nEpoch = 5, Iteration = 160/ 222  ===> Average training loss = , 1.178, Training Time: 0:09:58\nEpoch = 5, Iteration = 180/ 222  ===> Average training loss = , 1.175, Training Time: 0:10:05\nEpoch = 5, Iteration = 200/ 222  ===> Average training loss = , 1.173, Training Time: 0:10:13\nEpoch = 5, Iteration = 220/ 222  ===> Average training loss = , 1.171, Training Time: 0:10:21\nEpoch = 5 ===> training_accuracy =0.882 \nWeighted F1 Score: 0.4892\n\u001b[1mEpoch = 5 ====> Accuracy On Validation Dataset=0.502\u001b[0m\nF1 Score (Class bloomz): 0.8666\nF1 Score (Class chatGPT): 0.5974\nF1 Score (Class cohere): 0.4953\nF1 Score (Class davinci): 0.0944\nF1 Score (Class dolly): 0.4674\nF1 Score (Class human): 0.4142\n\nEpoch = 6, Iteration = 20/ 222  ===> Average training loss = , 1.201, Training Time: 0:11:17\nEpoch = 6, Iteration = 40/ 222  ===> Average training loss = , 1.169, Training Time: 0:11:25\nEpoch = 6, Iteration = 60/ 222  ===> Average training loss = , 1.167, Training Time: 0:11:33\nEpoch = 6, Iteration = 80/ 222  ===> Average training loss = , 1.164, Training Time: 0:11:41\nEpoch = 6, Iteration = 100/ 222  ===> Average training loss = , 1.164, Training Time: 0:11:48\nEpoch = 6, Iteration = 120/ 222  ===> Average training loss = , 1.158, Training Time: 0:11:56\nEpoch = 6, Iteration = 140/ 222  ===> Average training loss = , 1.162, Training Time: 0:12:04\nEpoch = 6, Iteration = 160/ 222  ===> Average training loss = , 1.163, Training Time: 0:12:12\nEpoch = 6, Iteration = 180/ 222  ===> Average training loss = , 1.163, Training Time: 0:12:19\nEpoch = 6, Iteration = 200/ 222  ===> Average training loss = , 1.159, Training Time: 0:12:27\nEpoch = 6, Iteration = 220/ 222  ===> Average training loss = , 1.156, Training Time: 0:12:35\nEpoch = 6 ===> training_accuracy =0.898 \nWeighted F1 Score: 0.5255\n\u001b[1mEpoch = 6 ====> Accuracy On Validation Dataset=0.539\u001b[0m\nF1 Score (Class bloomz): 0.9328\nF1 Score (Class chatGPT): 0.5662\nF1 Score (Class cohere): 0.4659\nF1 Score (Class davinci): 0.0644\nF1 Score (Class dolly): 0.4543\nF1 Score (Class human): 0.6691\n\nEpoch = 7, Iteration = 20/ 222  ===> Average training loss = , 1.204, Training Time: 0:13:32\nEpoch = 7, Iteration = 40/ 222  ===> Average training loss = , 1.178, Training Time: 0:13:40\nEpoch = 7, Iteration = 60/ 222  ===> Average training loss = , 1.149, Training Time: 0:13:48\nEpoch = 7, Iteration = 80/ 222  ===> Average training loss = , 1.135, Training Time: 0:13:55\nEpoch = 7, Iteration = 100/ 222  ===> Average training loss = , 1.133, Training Time: 0:14:03\nEpoch = 7, Iteration = 120/ 222  ===> Average training loss = , 1.129, Training Time: 0:14:11\nEpoch = 7, Iteration = 140/ 222  ===> Average training loss = , 1.132, Training Time: 0:14:19\nEpoch = 7, Iteration = 160/ 222  ===> Average training loss = , 1.131, Training Time: 0:14:26\nEpoch = 7, Iteration = 180/ 222  ===> Average training loss = , 1.128, Training Time: 0:14:34\nEpoch = 7, Iteration = 200/ 222  ===> Average training loss = , 1.127, Training Time: 0:14:42\nEpoch = 7, Iteration = 220/ 222  ===> Average training loss = , 1.127, Training Time: 0:14:50\nEpoch = 7 ===> training_accuracy =0.926 \nWeighted F1 Score: 0.4119\n\u001b[1mEpoch = 7 ====> Accuracy On Validation Dataset=0.453\u001b[0m\nF1 Score (Class bloomz): 0.9412\nF1 Score (Class chatGPT): 0.5187\nF1 Score (Class cohere): 0.4215\nF1 Score (Class davinci): 0.0095\nF1 Score (Class dolly): 0.3461\nF1 Score (Class human): 0.2343\n\nEpoch = 8, Iteration = 20/ 222  ===> Average training loss = , 1.205, Training Time: 0:15:46\nEpoch = 8, Iteration = 40/ 222  ===> Average training loss = , 1.158, Training Time: 0:15:54\nEpoch = 8, Iteration = 60/ 222  ===> Average training loss = , 1.156, Training Time: 0:16:02\nEpoch = 8, Iteration = 80/ 222  ===> Average training loss = , 1.148, Training Time: 0:16:10\nEpoch = 8, Iteration = 100/ 222  ===> Average training loss = , 1.136, Training Time: 0:16:17\nEpoch = 8, Iteration = 120/ 222  ===> Average training loss = , 1.128, Training Time: 0:16:25\nEpoch = 8, Iteration = 140/ 222  ===> Average training loss = , 1.124, Training Time: 0:16:33\nEpoch = 8, Iteration = 160/ 222  ===> Average training loss = , 1.123, Training Time: 0:16:41\nEpoch = 8, Iteration = 180/ 222  ===> Average training loss = , 1.123, Training Time: 0:16:48\nEpoch = 8, Iteration = 200/ 222  ===> Average training loss = , 1.121, Training Time: 0:16:56\nEpoch = 8, Iteration = 220/ 222  ===> Average training loss = , 1.120, Training Time: 0:17:04\nEpoch = 8 ===> training_accuracy =0.930 \nWeighted F1 Score: 0.5085\n\u001b[1mEpoch = 8 ====> Accuracy On Validation Dataset=0.542\u001b[0m\nF1 Score (Class bloomz): 0.8764\nF1 Score (Class chatGPT): 0.6452\nF1 Score (Class cohere): 0.4885\nF1 Score (Class davinci): 0.0443\nF1 Score (Class dolly): 0.5637\nF1 Score (Class human): 0.4329\n\nEpoch = 9, Iteration = 20/ 222  ===> Average training loss = , 1.163, Training Time: 0:18:01\nEpoch = 9, Iteration = 40/ 222  ===> Average training loss = , 1.129, Training Time: 0:18:09\nEpoch = 9, Iteration = 60/ 222  ===> Average training loss = , 1.138, Training Time: 0:18:17\nEpoch = 9, Iteration = 80/ 222  ===> Average training loss = , 1.135, Training Time: 0:18:25\nEpoch = 9, Iteration = 100/ 222  ===> Average training loss = , 1.128, Training Time: 0:18:32\nEpoch = 9, Iteration = 120/ 222  ===> Average training loss = , 1.124, Training Time: 0:18:40\nEpoch = 9, Iteration = 140/ 222  ===> Average training loss = , 1.119, Training Time: 0:18:48\nEpoch = 9, Iteration = 160/ 222  ===> Average training loss = , 1.117, Training Time: 0:18:56\nEpoch = 9, Iteration = 180/ 222  ===> Average training loss = , 1.114, Training Time: 0:19:03\nEpoch = 9, Iteration = 200/ 222  ===> Average training loss = , 1.111, Training Time: 0:19:11\nEpoch = 9, Iteration = 220/ 222  ===> Average training loss = , 1.109, Training Time: 0:19:19\nEpoch = 9 ===> training_accuracy =0.941 \nWeighted F1 Score: 0.4893\n\u001b[1mEpoch = 9 ====> Accuracy On Validation Dataset=0.523\u001b[0m\nF1 Score (Class bloomz): 0.9138\nF1 Score (Class chatGPT): 0.6550\nF1 Score (Class cohere): 0.4713\nF1 Score (Class davinci): 0.0873\nF1 Score (Class dolly): 0.5141\nF1 Score (Class human): 0.2943\n\nEpoch = 10, Iteration = 20/ 222  ===> Average training loss = , 1.129, Training Time: 0:20:15\nEpoch = 10, Iteration = 40/ 222  ===> Average training loss = , 1.105, Training Time: 0:20:23\nEpoch = 10, Iteration = 60/ 222  ===> Average training loss = , 1.106, Training Time: 0:20:31\nEpoch = 10, Iteration = 80/ 222  ===> Average training loss = , 1.099, Training Time: 0:20:39\nEpoch = 10, Iteration = 100/ 222  ===> Average training loss = , 1.095, Training Time: 0:20:46\nEpoch = 10, Iteration = 120/ 222  ===> Average training loss = , 1.096, Training Time: 0:20:54\nEpoch = 10, Iteration = 140/ 222  ===> Average training loss = , 1.096, Training Time: 0:21:02\nEpoch = 10, Iteration = 160/ 222  ===> Average training loss = , 1.100, Training Time: 0:21:10\nEpoch = 10, Iteration = 180/ 222  ===> Average training loss = , 1.101, Training Time: 0:21:17\nEpoch = 10, Iteration = 200/ 222  ===> Average training loss = , 1.102, Training Time: 0:21:25\nEpoch = 10, Iteration = 220/ 222  ===> Average training loss = , 1.102, Training Time: 0:21:33\nEpoch = 10 ===> training_accuracy =0.948 \nWeighted F1 Score: 0.5229\n\u001b[1mEpoch = 10 ====> Accuracy On Validation Dataset=0.553\u001b[0m\nF1 Score (Class bloomz): 0.9307\nF1 Score (Class chatGPT): 0.7133\nF1 Score (Class cohere): 0.4904\nF1 Score (Class davinci): 0.0485\nF1 Score (Class dolly): 0.4974\nF1 Score (Class human): 0.4571\n\n################################################################################\n\u001b[1m Percentage of training data = 10.0 % \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertWithAdapters were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['bert.adapters.0.down_project.bias', 'bert.adapters.0.down_project.weight', 'bert.adapters.0.up_project.bias', 'bert.adapters.0.up_project.weight', 'bert.adapters.1.down_project.bias', 'bert.adapters.1.down_project.weight', 'bert.adapters.1.up_project.bias', 'bert.adapters.1.up_project.weight', 'bert.adapters.10.down_project.bias', 'bert.adapters.10.down_project.weight', 'bert.adapters.10.up_project.bias', 'bert.adapters.10.up_project.weight', 'bert.adapters.11.down_project.bias', 'bert.adapters.11.down_project.weight', 'bert.adapters.11.up_project.bias', 'bert.adapters.11.up_project.weight', 'bert.adapters.2.down_project.bias', 'bert.adapters.2.down_project.weight', 'bert.adapters.2.up_project.bias', 'bert.adapters.2.up_project.weight', 'bert.adapters.3.down_project.bias', 'bert.adapters.3.down_project.weight', 'bert.adapters.3.up_project.bias', 'bert.adapters.3.up_project.weight', 'bert.adapters.4.down_project.bias', 'bert.adapters.4.down_project.weight', 'bert.adapters.4.up_project.bias', 'bert.adapters.4.up_project.weight', 'bert.adapters.5.down_project.bias', 'bert.adapters.5.down_project.weight', 'bert.adapters.5.up_project.bias', 'bert.adapters.5.up_project.weight', 'bert.adapters.6.down_project.bias', 'bert.adapters.6.down_project.weight', 'bert.adapters.6.up_project.bias', 'bert.adapters.6.up_project.weight', 'bert.adapters.7.down_project.bias', 'bert.adapters.7.down_project.weight', 'bert.adapters.7.up_project.bias', 'bert.adapters.7.up_project.weight', 'bert.adapters.8.down_project.bias', 'bert.adapters.8.down_project.weight', 'bert.adapters.8.up_project.bias', 'bert.adapters.8.up_project.weight', 'bert.adapters.9.down_project.bias', 'bert.adapters.9.down_project.weight', 'bert.adapters.9.up_project.bias', 'bert.adapters.9.up_project.weight', 'bert.logit.bias', 'bert.logit.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch = 1, Iteration = 30/ 444  ===> Average training loss = , 1.850, Training Time: 0:00:11\nEpoch = 1, Iteration = 60/ 444  ===> Average training loss = , 1.812, Training Time: 0:00:23\nEpoch = 1, Iteration = 90/ 444  ===> Average training loss = , 1.790, Training Time: 0:00:35\nEpoch = 1, Iteration = 120/ 444  ===> Average training loss = , 1.748, Training Time: 0:00:46\nEpoch = 1, Iteration = 150/ 444  ===> Average training loss = , 1.703, Training Time: 0:00:58\nEpoch = 1, Iteration = 180/ 444  ===> Average training loss = , 1.670, Training Time: 0:01:10\nEpoch = 1, Iteration = 210/ 444  ===> Average training loss = , 1.636, Training Time: 0:01:21\nEpoch = 1, Iteration = 240/ 444  ===> Average training loss = , 1.614, Training Time: 0:01:33\nEpoch = 1, Iteration = 270/ 444  ===> Average training loss = , 1.597, Training Time: 0:01:44\nEpoch = 1, Iteration = 300/ 444  ===> Average training loss = , 1.579, Training Time: 0:01:56\nEpoch = 1, Iteration = 330/ 444  ===> Average training loss = , 1.561, Training Time: 0:02:08\nEpoch = 1, Iteration = 360/ 444  ===> Average training loss = , 1.546, Training Time: 0:02:19\nEpoch = 1, Iteration = 390/ 444  ===> Average training loss = , 1.533, Training Time: 0:02:31\nEpoch = 1, Iteration = 420/ 444  ===> Average training loss = , 1.522, Training Time: 0:02:42\nEpoch = 1 ===> training_accuracy =0.540 \nWeighted F1 Score: 0.4584\n\u001b[1mEpoch = 1 ====> Accuracy On Validation Dataset=0.461\u001b[0m\nF1 Score (Class bloomz): 0.9171\nF1 Score (Class chatGPT): 0.4892\nF1 Score (Class cohere): 0.4154\nF1 Score (Class davinci): 0.0977\nF1 Score (Class dolly): 0.2090\nF1 Score (Class human): 0.6217\n\nEpoch = 2, Iteration = 30/ 444  ===> Average training loss = , 1.388, Training Time: 0:03:51\nEpoch = 2, Iteration = 60/ 444  ===> Average training loss = , 1.350, Training Time: 0:04:03\nEpoch = 2, Iteration = 90/ 444  ===> Average training loss = , 1.333, Training Time: 0:04:15\nEpoch = 2, Iteration = 120/ 444  ===> Average training loss = , 1.324, Training Time: 0:04:26\nEpoch = 2, Iteration = 150/ 444  ===> Average training loss = , 1.314, Training Time: 0:04:38\nEpoch = 2, Iteration = 180/ 444  ===> Average training loss = , 1.307, Training Time: 0:04:49\nEpoch = 2, Iteration = 210/ 444  ===> Average training loss = , 1.313, Training Time: 0:05:01\nEpoch = 2, Iteration = 240/ 444  ===> Average training loss = , 1.312, Training Time: 0:05:13\nEpoch = 2, Iteration = 270/ 444  ===> Average training loss = , 1.308, Training Time: 0:05:24\nEpoch = 2, Iteration = 300/ 444  ===> Average training loss = , 1.305, Training Time: 0:05:36\nEpoch = 2, Iteration = 330/ 444  ===> Average training loss = , 1.299, Training Time: 0:05:47\nEpoch = 2, Iteration = 360/ 444  ===> Average training loss = , 1.296, Training Time: 0:05:59\nEpoch = 2, Iteration = 390/ 444  ===> Average training loss = , 1.292, Training Time: 0:06:11\nEpoch = 2, Iteration = 420/ 444  ===> Average training loss = , 1.290, Training Time: 0:06:22\nEpoch = 2 ===> training_accuracy =0.760 \nWeighted F1 Score: 0.4035\n\u001b[1mEpoch = 2 ====> Accuracy On Validation Dataset=0.449\u001b[0m\nF1 Score (Class bloomz): 0.8919\nF1 Score (Class chatGPT): 0.3097\nF1 Score (Class cohere): 0.4248\nF1 Score (Class davinci): 0.0234\nF1 Score (Class dolly): 0.3699\nF1 Score (Class human): 0.4013\n\nEpoch = 3, Iteration = 30/ 444  ===> Average training loss = , 1.321, Training Time: 0:07:31\nEpoch = 3, Iteration = 60/ 444  ===> Average training loss = , 1.272, Training Time: 0:07:43\nEpoch = 3, Iteration = 90/ 444  ===> Average training loss = , 1.251, Training Time: 0:07:54\nEpoch = 3, Iteration = 120/ 444  ===> Average training loss = , 1.243, Training Time: 0:08:06\nEpoch = 3, Iteration = 150/ 444  ===> Average training loss = , 1.240, Training Time: 0:08:18\nEpoch = 3, Iteration = 180/ 444  ===> Average training loss = , 1.233, Training Time: 0:08:29\nEpoch = 3, Iteration = 210/ 444  ===> Average training loss = , 1.229, Training Time: 0:08:41\nEpoch = 3, Iteration = 240/ 444  ===> Average training loss = , 1.231, Training Time: 0:08:52\nEpoch = 3, Iteration = 270/ 444  ===> Average training loss = , 1.228, Training Time: 0:09:04\nEpoch = 3, Iteration = 300/ 444  ===> Average training loss = , 1.224, Training Time: 0:09:16\nEpoch = 3, Iteration = 330/ 444  ===> Average training loss = , 1.222, Training Time: 0:09:27\nEpoch = 3, Iteration = 360/ 444  ===> Average training loss = , 1.220, Training Time: 0:09:39\nEpoch = 3, Iteration = 390/ 444  ===> Average training loss = , 1.216, Training Time: 0:09:50\nEpoch = 3, Iteration = 420/ 444  ===> Average training loss = , 1.215, Training Time: 0:10:02\nEpoch = 3 ===> training_accuracy =0.839 \nWeighted F1 Score: 0.5613\n\u001b[1mEpoch = 3 ====> Accuracy On Validation Dataset=0.577\u001b[0m\nF1 Score (Class bloomz): 0.8937\nF1 Score (Class chatGPT): 0.6703\nF1 Score (Class cohere): 0.4778\nF1 Score (Class davinci): 0.1240\nF1 Score (Class dolly): 0.6105\nF1 Score (Class human): 0.5919\n\nEpoch = 4, Iteration = 30/ 444  ===> Average training loss = , 1.209, Training Time: 0:11:12\nEpoch = 4, Iteration = 60/ 444  ===> Average training loss = , 1.192, Training Time: 0:11:23\nEpoch = 4, Iteration = 90/ 444  ===> Average training loss = , 1.177, Training Time: 0:11:35\nEpoch = 4, Iteration = 120/ 444  ===> Average training loss = , 1.173, Training Time: 0:11:47\nEpoch = 4, Iteration = 150/ 444  ===> Average training loss = , 1.170, Training Time: 0:11:58\nEpoch = 4, Iteration = 180/ 444  ===> Average training loss = , 1.169, Training Time: 0:12:10\nEpoch = 4, Iteration = 210/ 444  ===> Average training loss = , 1.169, Training Time: 0:12:21\nEpoch = 4, Iteration = 240/ 444  ===> Average training loss = , 1.170, Training Time: 0:12:33\nEpoch = 4, Iteration = 270/ 444  ===> Average training loss = , 1.167, Training Time: 0:12:45\nEpoch = 4, Iteration = 300/ 444  ===> Average training loss = , 1.166, Training Time: 0:12:56\nEpoch = 4, Iteration = 330/ 444  ===> Average training loss = , 1.166, Training Time: 0:13:08\nEpoch = 4, Iteration = 360/ 444  ===> Average training loss = , 1.165, Training Time: 0:13:19\nEpoch = 4, Iteration = 390/ 444  ===> Average training loss = , 1.163, Training Time: 0:13:31\nEpoch = 4, Iteration = 420/ 444  ===> Average training loss = , 1.166, Training Time: 0:13:43\nEpoch = 4 ===> training_accuracy =0.880 \nWeighted F1 Score: 0.4883\n\u001b[1mEpoch = 4 ====> Accuracy On Validation Dataset=0.527\u001b[0m\nF1 Score (Class bloomz): 0.9208\nF1 Score (Class chatGPT): 0.3528\nF1 Score (Class cohere): 0.4380\nF1 Score (Class davinci): 0.0000\nF1 Score (Class dolly): 0.5401\nF1 Score (Class human): 0.6779\n\nEpoch = 5, Iteration = 30/ 444  ===> Average training loss = , 1.190, Training Time: 0:14:51\nEpoch = 5, Iteration = 60/ 444  ===> Average training loss = , 1.163, Training Time: 0:15:03\nEpoch = 5, Iteration = 90/ 444  ===> Average training loss = , 1.147, Training Time: 0:15:15\nEpoch = 5, Iteration = 120/ 444  ===> Average training loss = , 1.154, Training Time: 0:15:26\nEpoch = 5, Iteration = 150/ 444  ===> Average training loss = , 1.158, Training Time: 0:15:38\nEpoch = 5, Iteration = 180/ 444  ===> Average training loss = , 1.157, Training Time: 0:15:50\nEpoch = 5, Iteration = 210/ 444  ===> Average training loss = , 1.153, Training Time: 0:16:01\nEpoch = 5, Iteration = 240/ 444  ===> Average training loss = , 1.153, Training Time: 0:16:13\nEpoch = 5, Iteration = 270/ 444  ===> Average training loss = , 1.151, Training Time: 0:16:24\nEpoch = 5, Iteration = 300/ 444  ===> Average training loss = , 1.149, Training Time: 0:16:36\nEpoch = 5, Iteration = 330/ 444  ===> Average training loss = , 1.149, Training Time: 0:16:48\nEpoch = 5, Iteration = 360/ 444  ===> Average training loss = , 1.148, Training Time: 0:16:59\nEpoch = 5, Iteration = 390/ 444  ===> Average training loss = , 1.147, Training Time: 0:17:11\nEpoch = 5, Iteration = 420/ 444  ===> Average training loss = , 1.146, Training Time: 0:17:22\nEpoch = 5 ===> training_accuracy =0.904 \nWeighted F1 Score: 0.4909\n\u001b[1mEpoch = 5 ====> Accuracy On Validation Dataset=0.506\u001b[0m\nF1 Score (Class bloomz): 0.9307\nF1 Score (Class chatGPT): 0.5731\nF1 Score (Class cohere): 0.4561\nF1 Score (Class davinci): 0.0659\nF1 Score (Class dolly): 0.4361\nF1 Score (Class human): 0.4835\n\nEpoch = 6, Iteration = 30/ 444  ===> Average training loss = , 1.165, Training Time: 0:18:31\nEpoch = 6, Iteration = 60/ 444  ===> Average training loss = , 1.149, Training Time: 0:18:43\nEpoch = 6, Iteration = 90/ 444  ===> Average training loss = , 1.142, Training Time: 0:18:54\nEpoch = 6, Iteration = 120/ 444  ===> Average training loss = , 1.136, Training Time: 0:19:06\nEpoch = 6, Iteration = 150/ 444  ===> Average training loss = , 1.135, Training Time: 0:19:18\nEpoch = 6, Iteration = 180/ 444  ===> Average training loss = , 1.136, Training Time: 0:19:29\nEpoch = 6, Iteration = 210/ 444  ===> Average training loss = , 1.134, Training Time: 0:19:41\nEpoch = 6, Iteration = 240/ 444  ===> Average training loss = , 1.135, Training Time: 0:19:52\nEpoch = 6, Iteration = 270/ 444  ===> Average training loss = , 1.134, Training Time: 0:20:04\nEpoch = 6, Iteration = 300/ 444  ===> Average training loss = , 1.132, Training Time: 0:20:16\nEpoch = 6, Iteration = 330/ 444  ===> Average training loss = , 1.131, Training Time: 0:20:27\nEpoch = 6, Iteration = 360/ 444  ===> Average training loss = , 1.130, Training Time: 0:20:39\nEpoch = 6, Iteration = 390/ 444  ===> Average training loss = , 1.132, Training Time: 0:20:50\nEpoch = 6, Iteration = 420/ 444  ===> Average training loss = , 1.132, Training Time: 0:21:02\nEpoch = 6 ===> training_accuracy =0.915 \nWeighted F1 Score: 0.5619\n\u001b[1mEpoch = 6 ====> Accuracy On Validation Dataset=0.569\u001b[0m\nF1 Score (Class bloomz): 0.9217\nF1 Score (Class chatGPT): 0.6101\nF1 Score (Class cohere): 0.5168\nF1 Score (Class davinci): 0.2876\nF1 Score (Class dolly): 0.5739\nF1 Score (Class human): 0.4611\n\nEpoch = 7, Iteration = 30/ 444  ===> Average training loss = , 1.153, Training Time: 0:22:11\nEpoch = 7, Iteration = 60/ 444  ===> Average training loss = , 1.116, Training Time: 0:22:23\nEpoch = 7, Iteration = 90/ 444  ===> Average training loss = , 1.116, Training Time: 0:22:34\nEpoch = 7, Iteration = 120/ 444  ===> Average training loss = , 1.116, Training Time: 0:22:46\nEpoch = 7, Iteration = 150/ 444  ===> Average training loss = , 1.112, Training Time: 0:22:57\nEpoch = 7, Iteration = 180/ 444  ===> Average training loss = , 1.108, Training Time: 0:23:09\nEpoch = 7, Iteration = 210/ 444  ===> Average training loss = , 1.108, Training Time: 0:23:21\nEpoch = 7, Iteration = 240/ 444  ===> Average training loss = , 1.107, Training Time: 0:23:32\nEpoch = 7, Iteration = 270/ 444  ===> Average training loss = , 1.108, Training Time: 0:23:44\nEpoch = 7, Iteration = 300/ 444  ===> Average training loss = , 1.109, Training Time: 0:23:55\nEpoch = 7, Iteration = 330/ 444  ===> Average training loss = , 1.111, Training Time: 0:24:07\nEpoch = 7, Iteration = 360/ 444  ===> Average training loss = , 1.113, Training Time: 0:24:19\nEpoch = 7, Iteration = 390/ 444  ===> Average training loss = , 1.112, Training Time: 0:24:30\nEpoch = 7, Iteration = 420/ 444  ===> Average training loss = , 1.113, Training Time: 0:24:42\nEpoch = 7 ===> training_accuracy =0.934 \nWeighted F1 Score: 0.4542\n\u001b[1mEpoch = 7 ====> Accuracy On Validation Dataset=0.492\u001b[0m\nF1 Score (Class bloomz): 0.9346\nF1 Score (Class chatGPT): 0.4332\nF1 Score (Class cohere): 0.4484\nF1 Score (Class davinci): 0.0476\nF1 Score (Class dolly): 0.5043\nF1 Score (Class human): 0.3568\n\nEpoch = 8, Iteration = 30/ 444  ===> Average training loss = , 1.150, Training Time: 0:25:51\nEpoch = 8, Iteration = 60/ 444  ===> Average training loss = , 1.124, Training Time: 0:26:02\nEpoch = 8, Iteration = 90/ 444  ===> Average training loss = , 1.114, Training Time: 0:26:14\nEpoch = 8, Iteration = 120/ 444  ===> Average training loss = , 1.106, Training Time: 0:26:25\nEpoch = 8, Iteration = 150/ 444  ===> Average training loss = , 1.103, Training Time: 0:26:37\nEpoch = 8, Iteration = 180/ 444  ===> Average training loss = , 1.101, Training Time: 0:26:49\nEpoch = 8, Iteration = 210/ 444  ===> Average training loss = , 1.100, Training Time: 0:27:00\nEpoch = 8, Iteration = 240/ 444  ===> Average training loss = , 1.100, Training Time: 0:27:12\nEpoch = 8, Iteration = 270/ 444  ===> Average training loss = , 1.101, Training Time: 0:27:24\nEpoch = 8, Iteration = 300/ 444  ===> Average training loss = , 1.102, Training Time: 0:27:35\nEpoch = 8, Iteration = 330/ 444  ===> Average training loss = , 1.102, Training Time: 0:27:47\nEpoch = 8, Iteration = 360/ 444  ===> Average training loss = , 1.101, Training Time: 0:27:58\nEpoch = 8, Iteration = 390/ 444  ===> Average training loss = , 1.102, Training Time: 0:28:10\nEpoch = 8, Iteration = 420/ 444  ===> Average training loss = , 1.102, Training Time: 0:28:22\nEpoch = 8 ===> training_accuracy =0.945 \nWeighted F1 Score: 0.5122\n\u001b[1mEpoch = 8 ====> Accuracy On Validation Dataset=0.544\u001b[0m\nF1 Score (Class bloomz): 0.9217\nF1 Score (Class chatGPT): 0.4451\nF1 Score (Class cohere): 0.4684\nF1 Score (Class davinci): 0.0503\nF1 Score (Class dolly): 0.5817\nF1 Score (Class human): 0.6064\n\nEpoch = 9, Iteration = 30/ 444  ===> Average training loss = , 1.139, Training Time: 0:29:30\nEpoch = 9, Iteration = 60/ 444  ===> Average training loss = , 1.114, Training Time: 0:29:42\nEpoch = 9, Iteration = 90/ 444  ===> Average training loss = , 1.103, Training Time: 0:29:54\nEpoch = 9, Iteration = 120/ 444  ===> Average training loss = , 1.106, Training Time: 0:30:05\nEpoch = 9, Iteration = 150/ 444  ===> Average training loss = , 1.100, Training Time: 0:30:17\nEpoch = 9, Iteration = 180/ 444  ===> Average training loss = , 1.097, Training Time: 0:30:29\nEpoch = 9, Iteration = 210/ 444  ===> Average training loss = , 1.103, Training Time: 0:30:40\nEpoch = 9, Iteration = 240/ 444  ===> Average training loss = , 1.102, Training Time: 0:30:52\nEpoch = 9, Iteration = 270/ 444  ===> Average training loss = , 1.103, Training Time: 0:31:03\nEpoch = 9, Iteration = 300/ 444  ===> Average training loss = , 1.103, Training Time: 0:31:15\nEpoch = 9, Iteration = 330/ 444  ===> Average training loss = , 1.104, Training Time: 0:31:27\nEpoch = 9, Iteration = 360/ 444  ===> Average training loss = , 1.104, Training Time: 0:31:38\nEpoch = 9, Iteration = 390/ 444  ===> Average training loss = , 1.103, Training Time: 0:31:50\nEpoch = 9, Iteration = 420/ 444  ===> Average training loss = , 1.103, Training Time: 0:32:01\nEpoch = 9 ===> training_accuracy =0.943 \nWeighted F1 Score: 0.5299\n\u001b[1mEpoch = 9 ====> Accuracy On Validation Dataset=0.548\u001b[0m\nF1 Score (Class bloomz): 0.9268\nF1 Score (Class chatGPT): 0.4253\nF1 Score (Class cohere): 0.4712\nF1 Score (Class davinci): 0.1448\nF1 Score (Class dolly): 0.5788\nF1 Score (Class human): 0.6327\n\nEpoch = 10, Iteration = 30/ 444  ===> Average training loss = , 1.122, Training Time: 0:33:10\nEpoch = 10, Iteration = 60/ 444  ===> Average training loss = , 1.102, Training Time: 0:33:22\nEpoch = 10, Iteration = 90/ 444  ===> Average training loss = , 1.099, Training Time: 0:33:33\nEpoch = 10, Iteration = 120/ 444  ===> Average training loss = , 1.101, Training Time: 0:33:45\nEpoch = 10, Iteration = 150/ 444  ===> Average training loss = , 1.101, Training Time: 0:33:57\nEpoch = 10, Iteration = 180/ 444  ===> Average training loss = , 1.101, Training Time: 0:34:08\nEpoch = 10, Iteration = 210/ 444  ===> Average training loss = , 1.100, Training Time: 0:34:20\nEpoch = 10, Iteration = 240/ 444  ===> Average training loss = , 1.099, Training Time: 0:34:32\nEpoch = 10, Iteration = 270/ 444  ===> Average training loss = , 1.095, Training Time: 0:34:43\nEpoch = 10, Iteration = 300/ 444  ===> Average training loss = , 1.094, Training Time: 0:34:55\nEpoch = 10, Iteration = 330/ 444  ===> Average training loss = , 1.094, Training Time: 0:35:06\nEpoch = 10, Iteration = 360/ 444  ===> Average training loss = , 1.095, Training Time: 0:35:18\nEpoch = 10, Iteration = 390/ 444  ===> Average training loss = , 1.094, Training Time: 0:35:30\nEpoch = 10, Iteration = 420/ 444  ===> Average training loss = , 1.093, Training Time: 0:35:41\nEpoch = 10 ===> training_accuracy =0.955 \nWeighted F1 Score: 0.4602\n\u001b[1mEpoch = 10 ====> Accuracy On Validation Dataset=0.501\u001b[0m\nF1 Score (Class bloomz): 0.9363\nF1 Score (Class chatGPT): 0.4522\nF1 Score (Class cohere): 0.4590\nF1 Score (Class davinci): 0.0494\nF1 Score (Class dolly): 0.5345\nF1 Score (Class human): 0.3300\n\n################################################################################\n\u001b[1m Percentage of training data = 50.0 % \u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertWithAdapters were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['bert.adapters.0.down_project.bias', 'bert.adapters.0.down_project.weight', 'bert.adapters.0.up_project.bias', 'bert.adapters.0.up_project.weight', 'bert.adapters.1.down_project.bias', 'bert.adapters.1.down_project.weight', 'bert.adapters.1.up_project.bias', 'bert.adapters.1.up_project.weight', 'bert.adapters.10.down_project.bias', 'bert.adapters.10.down_project.weight', 'bert.adapters.10.up_project.bias', 'bert.adapters.10.up_project.weight', 'bert.adapters.11.down_project.bias', 'bert.adapters.11.down_project.weight', 'bert.adapters.11.up_project.bias', 'bert.adapters.11.up_project.weight', 'bert.adapters.2.down_project.bias', 'bert.adapters.2.down_project.weight', 'bert.adapters.2.up_project.bias', 'bert.adapters.2.up_project.weight', 'bert.adapters.3.down_project.bias', 'bert.adapters.3.down_project.weight', 'bert.adapters.3.up_project.bias', 'bert.adapters.3.up_project.weight', 'bert.adapters.4.down_project.bias', 'bert.adapters.4.down_project.weight', 'bert.adapters.4.up_project.bias', 'bert.adapters.4.up_project.weight', 'bert.adapters.5.down_project.bias', 'bert.adapters.5.down_project.weight', 'bert.adapters.5.up_project.bias', 'bert.adapters.5.up_project.weight', 'bert.adapters.6.down_project.bias', 'bert.adapters.6.down_project.weight', 'bert.adapters.6.up_project.bias', 'bert.adapters.6.up_project.weight', 'bert.adapters.7.down_project.bias', 'bert.adapters.7.down_project.weight', 'bert.adapters.7.up_project.bias', 'bert.adapters.7.up_project.weight', 'bert.adapters.8.down_project.bias', 'bert.adapters.8.down_project.weight', 'bert.adapters.8.up_project.bias', 'bert.adapters.8.up_project.weight', 'bert.adapters.9.down_project.bias', 'bert.adapters.9.down_project.weight', 'bert.adapters.9.up_project.bias', 'bert.adapters.9.up_project.weight', 'bert.logit.bias', 'bert.logit.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch = 1, Iteration = 40/ 2220  ===> Average training loss = , 1.832, Training Time: 0:00:15\nEpoch = 1, Iteration = 80/ 2220  ===> Average training loss = , 1.789, Training Time: 0:00:31\nEpoch = 1, Iteration = 120/ 2220  ===> Average training loss = , 1.733, Training Time: 0:00:46\nEpoch = 1, Iteration = 160/ 2220  ===> Average training loss = , 1.690, Training Time: 0:01:02\nEpoch = 1, Iteration = 200/ 2220  ===> Average training loss = , 1.647, Training Time: 0:01:17\nEpoch = 1, Iteration = 240/ 2220  ===> Average training loss = , 1.619, Training Time: 0:01:33\nEpoch = 1, Iteration = 280/ 2220  ===> Average training loss = , 1.588, Training Time: 0:01:48\nEpoch = 1, Iteration = 320/ 2220  ===> Average training loss = , 1.563, Training Time: 0:02:04\nEpoch = 1, Iteration = 360/ 2220  ===> Average training loss = , 1.544, Training Time: 0:02:19\nEpoch = 1, Iteration = 400/ 2220  ===> Average training loss = , 1.525, Training Time: 0:02:35\nEpoch = 1, Iteration = 440/ 2220  ===> Average training loss = , 1.509, Training Time: 0:02:50\nEpoch = 1, Iteration = 480/ 2220  ===> Average training loss = , 1.493, Training Time: 0:03:06\nEpoch = 1, Iteration = 520/ 2220  ===> Average training loss = , 1.483, Training Time: 0:03:21\nEpoch = 1, Iteration = 560/ 2220  ===> Average training loss = , 1.471, Training Time: 0:03:37\nEpoch = 1, Iteration = 600/ 2220  ===> Average training loss = , 1.461, Training Time: 0:03:52\nEpoch = 1, Iteration = 640/ 2220  ===> Average training loss = , 1.451, Training Time: 0:04:08\nEpoch = 1, Iteration = 680/ 2220  ===> Average training loss = , 1.440, Training Time: 0:04:23\nEpoch = 1, Iteration = 720/ 2220  ===> Average training loss = , 1.432, Training Time: 0:04:39\nEpoch = 1, Iteration = 760/ 2220  ===> Average training loss = , 1.427, Training Time: 0:04:54\nEpoch = 1, Iteration = 800/ 2220  ===> Average training loss = , 1.421, Training Time: 0:05:09\nEpoch = 1, Iteration = 840/ 2220  ===> Average training loss = , 1.414, Training Time: 0:05:25\nEpoch = 1, Iteration = 880/ 2220  ===> Average training loss = , 1.409, Training Time: 0:05:40\nEpoch = 1, Iteration = 920/ 2220  ===> Average training loss = , 1.402, Training Time: 0:05:56\nEpoch = 1, Iteration = 960/ 2220  ===> Average training loss = , 1.396, Training Time: 0:06:11\nEpoch = 1, Iteration = 1000/ 2220  ===> Average training loss = , 1.391, Training Time: 0:06:27\nEpoch = 1, Iteration = 1040/ 2220  ===> Average training loss = , 1.386, Training Time: 0:06:42\nEpoch = 1, Iteration = 1080/ 2220  ===> Average training loss = , 1.381, Training Time: 0:06:58\nEpoch = 1, Iteration = 1120/ 2220  ===> Average training loss = , 1.376, Training Time: 0:07:13\nEpoch = 1, Iteration = 1160/ 2220  ===> Average training loss = , 1.371, Training Time: 0:07:29\nEpoch = 1, Iteration = 1200/ 2220  ===> Average training loss = , 1.367, Training Time: 0:07:44\nEpoch = 1, Iteration = 1240/ 2220  ===> Average training loss = , 1.363, Training Time: 0:08:00\nEpoch = 1, Iteration = 1280/ 2220  ===> Average training loss = , 1.359, Training Time: 0:08:15\nEpoch = 1, Iteration = 1320/ 2220  ===> Average training loss = , 1.356, Training Time: 0:08:31\nEpoch = 1, Iteration = 1360/ 2220  ===> Average training loss = , 1.353, Training Time: 0:08:46\nEpoch = 1, Iteration = 1400/ 2220  ===> Average training loss = , 1.350, Training Time: 0:09:01\nEpoch = 1, Iteration = 1440/ 2220  ===> Average training loss = , 1.348, Training Time: 0:09:17\nEpoch = 1, Iteration = 1480/ 2220  ===> Average training loss = , 1.346, Training Time: 0:09:32\nEpoch = 1, Iteration = 1520/ 2220  ===> Average training loss = , 1.343, Training Time: 0:09:48\nEpoch = 1, Iteration = 1560/ 2220  ===> Average training loss = , 1.341, Training Time: 0:10:03\nEpoch = 1, Iteration = 1600/ 2220  ===> Average training loss = , 1.338, Training Time: 0:10:19\nEpoch = 1, Iteration = 1640/ 2220  ===> Average training loss = , 1.336, Training Time: 0:10:34\nEpoch = 1, Iteration = 1680/ 2220  ===> Average training loss = , 1.334, Training Time: 0:10:50\nEpoch = 1, Iteration = 1720/ 2220  ===> Average training loss = , 1.331, Training Time: 0:11:05\nEpoch = 1, Iteration = 1760/ 2220  ===> Average training loss = , 1.328, Training Time: 0:11:21\nEpoch = 1, Iteration = 1800/ 2220  ===> Average training loss = , 1.326, Training Time: 0:11:36\nEpoch = 1, Iteration = 1840/ 2220  ===> Average training loss = , 1.324, Training Time: 0:11:52\nEpoch = 1, Iteration = 1880/ 2220  ===> Average training loss = , 1.322, Training Time: 0:12:07\nEpoch = 1, Iteration = 1920/ 2220  ===> Average training loss = , 1.320, Training Time: 0:12:23\nEpoch = 1, Iteration = 1960/ 2220  ===> Average training loss = , 1.318, Training Time: 0:12:38\nEpoch = 1, Iteration = 2000/ 2220  ===> Average training loss = , 1.315, Training Time: 0:12:53\nEpoch = 1, Iteration = 2040/ 2220  ===> Average training loss = , 1.314, Training Time: 0:13:09\nEpoch = 1, Iteration = 2080/ 2220  ===> Average training loss = , 1.312, Training Time: 0:13:24\nEpoch = 1, Iteration = 2120/ 2220  ===> Average training loss = , 1.310, Training Time: 0:13:40\nEpoch = 1, Iteration = 2160/ 2220  ===> Average training loss = , 1.309, Training Time: 0:13:55\nEpoch = 1, Iteration = 2200/ 2220  ===> Average training loss = , 1.307, Training Time: 0:14:11\nEpoch = 1 ===> training_accuracy =0.740 \nWeighted F1 Score: 0.3870\n\u001b[1mEpoch = 1 ====> Accuracy On Validation Dataset=0.473\u001b[0m\nF1 Score (Class bloomz): 0.9381\nF1 Score (Class chatGPT): 0.0907\nF1 Score (Class cohere): 0.4593\nF1 Score (Class davinci): 0.0036\nF1 Score (Class dolly): 0.5372\nF1 Score (Class human): 0.2930\n\nEpoch = 2, Iteration = 40/ 2220  ===> Average training loss = , 1.260, Training Time: 0:15:22\nEpoch = 2, Iteration = 80/ 2220  ===> Average training loss = , 1.225, Training Time: 0:15:37\nEpoch = 2, Iteration = 120/ 2220  ===> Average training loss = , 1.218, Training Time: 0:15:53\nEpoch = 2, Iteration = 160/ 2220  ===> Average training loss = , 1.211, Training Time: 0:16:08\nEpoch = 2, Iteration = 200/ 2220  ===> Average training loss = , 1.208, Training Time: 0:16:24\nEpoch = 2, Iteration = 240/ 2220  ===> Average training loss = , 1.207, Training Time: 0:16:39\nEpoch = 2, Iteration = 280/ 2220  ===> Average training loss = , 1.203, Training Time: 0:16:55\nEpoch = 2, Iteration = 320/ 2220  ===> Average training loss = , 1.203, Training Time: 0:17:10\nEpoch = 2, Iteration = 360/ 2220  ===> Average training loss = , 1.197, Training Time: 0:17:26\nEpoch = 2, Iteration = 400/ 2220  ===> Average training loss = , 1.196, Training Time: 0:17:41\nEpoch = 2, Iteration = 440/ 2220  ===> Average training loss = , 1.197, Training Time: 0:17:57\nEpoch = 2, Iteration = 480/ 2220  ===> Average training loss = , 1.195, Training Time: 0:18:12\nEpoch = 2, Iteration = 520/ 2220  ===> Average training loss = , 1.196, Training Time: 0:18:28\nEpoch = 2, Iteration = 560/ 2220  ===> Average training loss = , 1.197, Training Time: 0:18:43\nEpoch = 2, Iteration = 600/ 2220  ===> Average training loss = , 1.196, Training Time: 0:18:59\nEpoch = 2, Iteration = 640/ 2220  ===> Average training loss = , 1.194, Training Time: 0:19:14\nEpoch = 2, Iteration = 680/ 2220  ===> Average training loss = , 1.193, Training Time: 0:19:30\nEpoch = 2, Iteration = 720/ 2220  ===> Average training loss = , 1.194, Training Time: 0:19:45\nEpoch = 2, Iteration = 760/ 2220  ===> Average training loss = , 1.195, Training Time: 0:20:01\nEpoch = 2, Iteration = 800/ 2220  ===> Average training loss = , 1.195, Training Time: 0:20:16\nEpoch = 2, Iteration = 840/ 2220  ===> Average training loss = , 1.195, Training Time: 0:20:32\nEpoch = 2, Iteration = 880/ 2220  ===> Average training loss = , 1.194, Training Time: 0:20:47\nEpoch = 2, Iteration = 920/ 2220  ===> Average training loss = , 1.193, Training Time: 0:21:03\nEpoch = 2, Iteration = 960/ 2220  ===> Average training loss = , 1.193, Training Time: 0:21:18\nEpoch = 2, Iteration = 1000/ 2220  ===> Average training loss = , 1.192, Training Time: 0:21:33\nEpoch = 2, Iteration = 1040/ 2220  ===> Average training loss = , 1.192, Training Time: 0:21:49\nEpoch = 2, Iteration = 1080/ 2220  ===> Average training loss = , 1.191, Training Time: 0:22:04\nEpoch = 2, Iteration = 1120/ 2220  ===> Average training loss = , 1.191, Training Time: 0:22:20\nEpoch = 2, Iteration = 1160/ 2220  ===> Average training loss = , 1.191, Training Time: 0:22:35\nEpoch = 2, Iteration = 1200/ 2220  ===> Average training loss = , 1.190, Training Time: 0:22:51\nEpoch = 2, Iteration = 1240/ 2220  ===> Average training loss = , 1.191, Training Time: 0:23:06\nEpoch = 2, Iteration = 1280/ 2220  ===> Average training loss = , 1.191, Training Time: 0:23:22\nEpoch = 2, Iteration = 1320/ 2220  ===> Average training loss = , 1.190, Training Time: 0:23:37\nEpoch = 2, Iteration = 1360/ 2220  ===> Average training loss = , 1.190, Training Time: 0:23:53\nEpoch = 2, Iteration = 1400/ 2220  ===> Average training loss = , 1.190, Training Time: 0:24:08\nEpoch = 2, Iteration = 1440/ 2220  ===> Average training loss = , 1.191, Training Time: 0:24:24\nEpoch = 2, Iteration = 1480/ 2220  ===> Average training loss = , 1.190, Training Time: 0:24:39\nEpoch = 2, Iteration = 1520/ 2220  ===> Average training loss = , 1.190, Training Time: 0:24:55\nEpoch = 2, Iteration = 1560/ 2220  ===> Average training loss = , 1.190, Training Time: 0:25:10\nEpoch = 2, Iteration = 1600/ 2220  ===> Average training loss = , 1.189, Training Time: 0:25:26\nEpoch = 2, Iteration = 1640/ 2220  ===> Average training loss = , 1.188, Training Time: 0:25:41\nEpoch = 2, Iteration = 1680/ 2220  ===> Average training loss = , 1.188, Training Time: 0:25:56\nEpoch = 2, Iteration = 1720/ 2220  ===> Average training loss = , 1.188, Training Time: 0:26:12\nEpoch = 2, Iteration = 1760/ 2220  ===> Average training loss = , 1.187, Training Time: 0:26:27\nEpoch = 2, Iteration = 1800/ 2220  ===> Average training loss = , 1.187, Training Time: 0:26:43\nEpoch = 2, Iteration = 1840/ 2220  ===> Average training loss = , 1.187, Training Time: 0:26:58\nEpoch = 2, Iteration = 1880/ 2220  ===> Average training loss = , 1.187, Training Time: 0:27:14\nEpoch = 2, Iteration = 1920/ 2220  ===> Average training loss = , 1.187, Training Time: 0:27:29\nEpoch = 2, Iteration = 1960/ 2220  ===> Average training loss = , 1.186, Training Time: 0:27:45\nEpoch = 2, Iteration = 2000/ 2220  ===> Average training loss = , 1.186, Training Time: 0:28:00\nEpoch = 2, Iteration = 2040/ 2220  ===> Average training loss = , 1.186, Training Time: 0:28:16\nEpoch = 2, Iteration = 2080/ 2220  ===> Average training loss = , 1.187, Training Time: 0:28:31\nEpoch = 2, Iteration = 2120/ 2220  ===> Average training loss = , 1.186, Training Time: 0:28:47\nEpoch = 2, Iteration = 2160/ 2220  ===> Average training loss = , 1.186, Training Time: 0:29:02\nEpoch = 2, Iteration = 2200/ 2220  ===> Average training loss = , 1.186, Training Time: 0:29:18\nEpoch = 2 ===> training_accuracy =0.858 \nWeighted F1 Score: 0.4665\n\u001b[1mEpoch = 2 ====> Accuracy On Validation Dataset=0.521\u001b[0m\nF1 Score (Class bloomz): 0.9191\nF1 Score (Class chatGPT): 0.4242\nF1 Score (Class cohere): 0.4857\nF1 Score (Class davinci): 0.0249\nF1 Score (Class dolly): 0.5387\nF1 Score (Class human): 0.4063\n\nEpoch = 3, Iteration = 40/ 2220  ===> Average training loss = , 1.185, Training Time: 0:30:29\nEpoch = 3, Iteration = 80/ 2220  ===> Average training loss = , 1.162, Training Time: 0:30:44\nEpoch = 3, Iteration = 120/ 2220  ===> Average training loss = , 1.162, Training Time: 0:31:00\nEpoch = 3, Iteration = 160/ 2220  ===> Average training loss = , 1.161, Training Time: 0:31:15\nEpoch = 3, Iteration = 200/ 2220  ===> Average training loss = , 1.161, Training Time: 0:31:31\nEpoch = 3, Iteration = 240/ 2220  ===> Average training loss = , 1.159, Training Time: 0:31:46\nEpoch = 3, Iteration = 280/ 2220  ===> Average training loss = , 1.160, Training Time: 0:32:02\nEpoch = 3, Iteration = 320/ 2220  ===> Average training loss = , 1.162, Training Time: 0:32:17\nEpoch = 3, Iteration = 360/ 2220  ===> Average training loss = , 1.162, Training Time: 0:32:33\nEpoch = 3, Iteration = 400/ 2220  ===> Average training loss = , 1.164, Training Time: 0:32:48\nEpoch = 3, Iteration = 440/ 2220  ===> Average training loss = , 1.163, Training Time: 0:33:04\nEpoch = 3, Iteration = 480/ 2220  ===> Average training loss = , 1.164, Training Time: 0:33:19\nEpoch = 3, Iteration = 520/ 2220  ===> Average training loss = , 1.165, Training Time: 0:33:34\nEpoch = 3, Iteration = 560/ 2220  ===> Average training loss = , 1.164, Training Time: 0:33:50\nEpoch = 3, Iteration = 600/ 2220  ===> Average training loss = , 1.165, Training Time: 0:34:05\nEpoch = 3, Iteration = 640/ 2220  ===> Average training loss = , 1.168, Training Time: 0:34:21\nEpoch = 3, Iteration = 680/ 2220  ===> Average training loss = , 1.168, Training Time: 0:34:36\nEpoch = 3, Iteration = 720/ 2220  ===> Average training loss = , 1.166, Training Time: 0:34:52\nEpoch = 3, Iteration = 760/ 2220  ===> Average training loss = , 1.166, Training Time: 0:35:07\nEpoch = 3, Iteration = 800/ 2220  ===> Average training loss = , 1.165, Training Time: 0:35:23\nEpoch = 3, Iteration = 840/ 2220  ===> Average training loss = , 1.165, Training Time: 0:35:38\nEpoch = 3, Iteration = 880/ 2220  ===> Average training loss = , 1.165, Training Time: 0:35:54\nEpoch = 3, Iteration = 920/ 2220  ===> Average training loss = , 1.164, Training Time: 0:36:09\nEpoch = 3, Iteration = 960/ 2220  ===> Average training loss = , 1.164, Training Time: 0:36:25\nEpoch = 3, Iteration = 1000/ 2220  ===> Average training loss = , 1.164, Training Time: 0:36:40\nEpoch = 3, Iteration = 1040/ 2220  ===> Average training loss = , 1.163, Training Time: 0:36:56\nEpoch = 3, Iteration = 1080/ 2220  ===> Average training loss = , 1.164, Training Time: 0:37:11\nEpoch = 3, Iteration = 1120/ 2220  ===> Average training loss = , 1.162, Training Time: 0:37:27\nEpoch = 3, Iteration = 1160/ 2220  ===> Average training loss = , 1.161, Training Time: 0:37:42\nEpoch = 3, Iteration = 1200/ 2220  ===> Average training loss = , 1.161, Training Time: 0:37:57\nEpoch = 3, Iteration = 1240/ 2220  ===> Average training loss = , 1.161, Training Time: 0:38:13\nEpoch = 3, Iteration = 1280/ 2220  ===> Average training loss = , 1.160, Training Time: 0:38:28\nEpoch = 3, Iteration = 1320/ 2220  ===> Average training loss = , 1.160, Training Time: 0:38:44\nEpoch = 3, Iteration = 1360/ 2220  ===> Average training loss = , 1.159, Training Time: 0:38:59\nEpoch = 3, Iteration = 1400/ 2220  ===> Average training loss = , 1.159, Training Time: 0:39:15\nEpoch = 3, Iteration = 1440/ 2220  ===> Average training loss = , 1.159, Training Time: 0:39:30\nEpoch = 3, Iteration = 1480/ 2220  ===> Average training loss = , 1.158, Training Time: 0:39:46\nEpoch = 3, Iteration = 1520/ 2220  ===> Average training loss = , 1.158, Training Time: 0:40:01\nEpoch = 3, Iteration = 1560/ 2220  ===> Average training loss = , 1.158, Training Time: 0:40:17\nEpoch = 3, Iteration = 1600/ 2220  ===> Average training loss = , 1.158, Training Time: 0:40:32\nEpoch = 3, Iteration = 1640/ 2220  ===> Average training loss = , 1.158, Training Time: 0:40:48\nEpoch = 3, Iteration = 1680/ 2220  ===> Average training loss = , 1.158, Training Time: 0:41:03\nEpoch = 3, Iteration = 1720/ 2220  ===> Average training loss = , 1.158, Training Time: 0:41:19\nEpoch = 3, Iteration = 1760/ 2220  ===> Average training loss = , 1.158, Training Time: 0:41:34\nEpoch = 3, Iteration = 1800/ 2220  ===> Average training loss = , 1.157, Training Time: 0:41:50\nEpoch = 3, Iteration = 1840/ 2220  ===> Average training loss = , 1.157, Training Time: 0:42:05\nEpoch = 3, Iteration = 1880/ 2220  ===> Average training loss = , 1.157, Training Time: 0:42:21\nEpoch = 3, Iteration = 1920/ 2220  ===> Average training loss = , 1.157, Training Time: 0:42:36\nEpoch = 3, Iteration = 1960/ 2220  ===> Average training loss = , 1.157, Training Time: 0:42:51\nEpoch = 3, Iteration = 2000/ 2220  ===> Average training loss = , 1.157, Training Time: 0:43:07\nEpoch = 3, Iteration = 2040/ 2220  ===> Average training loss = , 1.157, Training Time: 0:43:22\nEpoch = 3, Iteration = 2080/ 2220  ===> Average training loss = , 1.156, Training Time: 0:43:38\nEpoch = 3, Iteration = 2120/ 2220  ===> Average training loss = , 1.156, Training Time: 0:43:53\nEpoch = 3, Iteration = 2160/ 2220  ===> Average training loss = , 1.157, Training Time: 0:44:09\nEpoch = 3, Iteration = 2200/ 2220  ===> Average training loss = , 1.157, Training Time: 0:44:24\nEpoch = 3 ===> training_accuracy =0.886 \nWeighted F1 Score: 0.5889\n\u001b[1mEpoch = 3 ====> Accuracy On Validation Dataset=0.615\u001b[0m\nF1 Score (Class bloomz): 0.9242\nF1 Score (Class chatGPT): 0.7532\nF1 Score (Class cohere): 0.5012\nF1 Score (Class davinci): 0.1494\nF1 Score (Class dolly): 0.6432\nF1 Score (Class human): 0.5622\n\nEpoch = 4, Iteration = 40/ 2220  ===> Average training loss = , 1.176, Training Time: 0:45:36\nEpoch = 4, Iteration = 80/ 2220  ===> Average training loss = , 1.155, Training Time: 0:45:52\nEpoch = 4, Iteration = 120/ 2220  ===> Average training loss = , 1.153, Training Time: 0:46:07\nEpoch = 4, Iteration = 160/ 2220  ===> Average training loss = , 1.145, Training Time: 0:46:23\nEpoch = 4, Iteration = 200/ 2220  ===> Average training loss = , 1.142, Training Time: 0:46:38\nEpoch = 4, Iteration = 240/ 2220  ===> Average training loss = , 1.141, Training Time: 0:46:54\nEpoch = 4, Iteration = 280/ 2220  ===> Average training loss = , 1.140, Training Time: 0:47:09\nEpoch = 4, Iteration = 320/ 2220  ===> Average training loss = , 1.139, Training Time: 0:47:25\nEpoch = 4, Iteration = 360/ 2220  ===> Average training loss = , 1.137, Training Time: 0:47:40\nEpoch = 4, Iteration = 400/ 2220  ===> Average training loss = , 1.138, Training Time: 0:47:56\nEpoch = 4, Iteration = 440/ 2220  ===> Average training loss = , 1.140, Training Time: 0:48:11\nEpoch = 4, Iteration = 480/ 2220  ===> Average training loss = , 1.141, Training Time: 0:48:27\nEpoch = 4, Iteration = 520/ 2220  ===> Average training loss = , 1.140, Training Time: 0:48:42\nEpoch = 4, Iteration = 560/ 2220  ===> Average training loss = , 1.140, Training Time: 0:48:58\nEpoch = 4, Iteration = 600/ 2220  ===> Average training loss = , 1.141, Training Time: 0:49:13\nEpoch = 4, Iteration = 640/ 2220  ===> Average training loss = , 1.141, Training Time: 0:49:29\nEpoch = 4, Iteration = 680/ 2220  ===> Average training loss = , 1.139, Training Time: 0:49:44\nEpoch = 4, Iteration = 720/ 2220  ===> Average training loss = , 1.138, Training Time: 0:50:00\nEpoch = 4, Iteration = 760/ 2220  ===> Average training loss = , 1.140, Training Time: 0:50:15\nEpoch = 4, Iteration = 800/ 2220  ===> Average training loss = , 1.140, Training Time: 0:50:30\nEpoch = 4, Iteration = 840/ 2220  ===> Average training loss = , 1.140, Training Time: 0:50:46\nEpoch = 4, Iteration = 880/ 2220  ===> Average training loss = , 1.141, Training Time: 0:51:01\nEpoch = 4, Iteration = 920/ 2220  ===> Average training loss = , 1.141, Training Time: 0:51:17\nEpoch = 4, Iteration = 960/ 2220  ===> Average training loss = , 1.140, Training Time: 0:51:32\nEpoch = 4, Iteration = 1000/ 2220  ===> Average training loss = , 1.140, Training Time: 0:51:48\nEpoch = 4, Iteration = 1040/ 2220  ===> Average training loss = , 1.140, Training Time: 0:52:03\nEpoch = 4, Iteration = 1080/ 2220  ===> Average training loss = , 1.140, Training Time: 0:52:19\nEpoch = 4, Iteration = 1120/ 2220  ===> Average training loss = , 1.139, Training Time: 0:52:34\nEpoch = 4, Iteration = 1160/ 2220  ===> Average training loss = , 1.139, Training Time: 0:52:50\nEpoch = 4, Iteration = 1200/ 2220  ===> Average training loss = , 1.139, Training Time: 0:53:05\nEpoch = 4, Iteration = 1240/ 2220  ===> Average training loss = , 1.138, Training Time: 0:53:21\nEpoch = 4, Iteration = 1280/ 2220  ===> Average training loss = , 1.138, Training Time: 0:53:36\nEpoch = 4, Iteration = 1320/ 2220  ===> Average training loss = , 1.139, Training Time: 0:53:52\nEpoch = 4, Iteration = 1360/ 2220  ===> Average training loss = , 1.139, Training Time: 0:54:07\nEpoch = 4, Iteration = 1400/ 2220  ===> Average training loss = , 1.140, Training Time: 0:54:23\nEpoch = 4, Iteration = 1440/ 2220  ===> Average training loss = , 1.140, Training Time: 0:54:38\nEpoch = 4, Iteration = 1480/ 2220  ===> Average training loss = , 1.139, Training Time: 0:54:54\nEpoch = 4, Iteration = 1520/ 2220  ===> Average training loss = , 1.139, Training Time: 0:55:09\nEpoch = 4, Iteration = 1560/ 2220  ===> Average training loss = , 1.139, Training Time: 0:55:25\nEpoch = 4, Iteration = 1600/ 2220  ===> Average training loss = , 1.139, Training Time: 0:55:40\nEpoch = 4, Iteration = 1640/ 2220  ===> Average training loss = , 1.139, Training Time: 0:55:56\nEpoch = 4, Iteration = 1680/ 2220  ===> Average training loss = , 1.138, Training Time: 0:56:11\nEpoch = 4, Iteration = 1720/ 2220  ===> Average training loss = , 1.138, Training Time: 0:56:27\nEpoch = 4, Iteration = 1760/ 2220  ===> Average training loss = , 1.138, Training Time: 0:56:42\nEpoch = 4, Iteration = 1800/ 2220  ===> Average training loss = , 1.138, Training Time: 0:56:57\nEpoch = 4, Iteration = 1840/ 2220  ===> Average training loss = , 1.137, Training Time: 0:57:13\nEpoch = 4, Iteration = 1880/ 2220  ===> Average training loss = , 1.137, Training Time: 0:57:28\nEpoch = 4, Iteration = 1920/ 2220  ===> Average training loss = , 1.137, Training Time: 0:57:44\nEpoch = 4, Iteration = 1960/ 2220  ===> Average training loss = , 1.137, Training Time: 0:57:59\nEpoch = 4, Iteration = 2000/ 2220  ===> Average training loss = , 1.137, Training Time: 0:58:15\nEpoch = 4, Iteration = 2040/ 2220  ===> Average training loss = , 1.137, Training Time: 0:58:30\nEpoch = 4, Iteration = 2080/ 2220  ===> Average training loss = , 1.137, Training Time: 0:58:46\nEpoch = 4, Iteration = 2120/ 2220  ===> Average training loss = , 1.137, Training Time: 0:59:01\nEpoch = 4, Iteration = 2160/ 2220  ===> Average training loss = , 1.137, Training Time: 0:59:17\nEpoch = 4, Iteration = 2200/ 2220  ===> Average training loss = , 1.138, Training Time: 0:59:32\nEpoch = 4 ===> training_accuracy =0.906 \nWeighted F1 Score: 0.5790\n\u001b[1mEpoch = 4 ====> Accuracy On Validation Dataset=0.588\u001b[0m\nF1 Score (Class bloomz): 0.9033\nF1 Score (Class chatGPT): 0.6618\nF1 Score (Class cohere): 0.5190\nF1 Score (Class davinci): 0.2726\nF1 Score (Class dolly): 0.5751\nF1 Score (Class human): 0.5421\n\nEpoch = 5, Iteration = 40/ 2220  ===> Average training loss = , 1.145, Training Time: 1:00:43\nEpoch = 5, Iteration = 80/ 2220  ===> Average training loss = , 1.146, Training Time: 1:00:59\nEpoch = 5, Iteration = 120/ 2220  ===> Average training loss = , 1.143, Training Time: 1:01:15\nEpoch = 5, Iteration = 160/ 2220  ===> Average training loss = , 1.137, Training Time: 1:01:30\nEpoch = 5, Iteration = 200/ 2220  ===> Average training loss = , 1.133, Training Time: 1:01:46\nEpoch = 5, Iteration = 240/ 2220  ===> Average training loss = , 1.136, Training Time: 1:02:01\nEpoch = 5, Iteration = 280/ 2220  ===> Average training loss = , 1.137, Training Time: 1:02:16\nEpoch = 5, Iteration = 320/ 2220  ===> Average training loss = , 1.136, Training Time: 1:02:32\nEpoch = 5, Iteration = 360/ 2220  ===> Average training loss = , 1.134, Training Time: 1:02:47\nEpoch = 5, Iteration = 400/ 2220  ===> Average training loss = , 1.134, Training Time: 1:03:03\nEpoch = 5, Iteration = 440/ 2220  ===> Average training loss = , 1.134, Training Time: 1:03:18\nEpoch = 5, Iteration = 480/ 2220  ===> Average training loss = , 1.133, Training Time: 1:03:34\nEpoch = 5, Iteration = 520/ 2220  ===> Average training loss = , 1.130, Training Time: 1:03:49\nEpoch = 5, Iteration = 560/ 2220  ===> Average training loss = , 1.132, Training Time: 1:04:05\nEpoch = 5, Iteration = 600/ 2220  ===> Average training loss = , 1.131, Training Time: 1:04:20\nEpoch = 5, Iteration = 640/ 2220  ===> Average training loss = , 1.130, Training Time: 1:04:36\nEpoch = 5, Iteration = 680/ 2220  ===> Average training loss = , 1.130, Training Time: 1:04:51\nEpoch = 5, Iteration = 720/ 2220  ===> Average training loss = , 1.130, Training Time: 1:05:07\nEpoch = 5, Iteration = 760/ 2220  ===> Average training loss = , 1.131, Training Time: 1:05:22\nEpoch = 5, Iteration = 800/ 2220  ===> Average training loss = , 1.131, Training Time: 1:05:38\nEpoch = 5, Iteration = 840/ 2220  ===> Average training loss = , 1.130, Training Time: 1:05:53\nEpoch = 5, Iteration = 880/ 2220  ===> Average training loss = , 1.130, Training Time: 1:06:09\nEpoch = 5, Iteration = 920/ 2220  ===> Average training loss = , 1.129, Training Time: 1:06:24\nEpoch = 5, Iteration = 960/ 2220  ===> Average training loss = , 1.129, Training Time: 1:06:39\nEpoch = 5, Iteration = 1000/ 2220  ===> Average training loss = , 1.130, Training Time: 1:06:55\nEpoch = 5, Iteration = 1040/ 2220  ===> Average training loss = , 1.130, Training Time: 1:07:10\nEpoch = 5, Iteration = 1080/ 2220  ===> Average training loss = , 1.130, Training Time: 1:07:26\nEpoch = 5, Iteration = 1120/ 2220  ===> Average training loss = , 1.130, Training Time: 1:07:41\nEpoch = 5, Iteration = 1160/ 2220  ===> Average training loss = , 1.129, Training Time: 1:07:57\nEpoch = 5, Iteration = 1200/ 2220  ===> Average training loss = , 1.129, Training Time: 1:08:12\nEpoch = 5, Iteration = 1240/ 2220  ===> Average training loss = , 1.129, Training Time: 1:08:28\nEpoch = 5, Iteration = 1280/ 2220  ===> Average training loss = , 1.129, Training Time: 1:08:43\nEpoch = 5, Iteration = 1320/ 2220  ===> Average training loss = , 1.129, Training Time: 1:08:59\nEpoch = 5, Iteration = 1360/ 2220  ===> Average training loss = , 1.129, Training Time: 1:09:14\nEpoch = 5, Iteration = 1400/ 2220  ===> Average training loss = , 1.128, Training Time: 1:09:30\nEpoch = 5, Iteration = 1440/ 2220  ===> Average training loss = , 1.128, Training Time: 1:09:45\nEpoch = 5, Iteration = 1480/ 2220  ===> Average training loss = , 1.128, Training Time: 1:10:01\nEpoch = 5, Iteration = 1520/ 2220  ===> Average training loss = , 1.128, Training Time: 1:10:16\nEpoch = 5, Iteration = 1560/ 2220  ===> Average training loss = , 1.128, Training Time: 1:10:32\nEpoch = 5, Iteration = 1600/ 2220  ===> Average training loss = , 1.128, Training Time: 1:10:47\nEpoch = 5, Iteration = 1640/ 2220  ===> Average training loss = , 1.128, Training Time: 1:11:03\nEpoch = 5, Iteration = 1680/ 2220  ===> Average training loss = , 1.128, Training Time: 1:11:18\nEpoch = 5, Iteration = 1720/ 2220  ===> Average training loss = , 1.127, Training Time: 1:11:34\nEpoch = 5, Iteration = 1760/ 2220  ===> Average training loss = , 1.127, Training Time: 1:11:49\nEpoch = 5, Iteration = 1800/ 2220  ===> Average training loss = , 1.128, Training Time: 1:12:05\nEpoch = 5, Iteration = 1840/ 2220  ===> Average training loss = , 1.128, Training Time: 1:12:20\nEpoch = 5, Iteration = 1880/ 2220  ===> Average training loss = , 1.128, Training Time: 1:12:36\nEpoch = 5, Iteration = 1920/ 2220  ===> Average training loss = , 1.128, Training Time: 1:12:51\nEpoch = 5, Iteration = 1960/ 2220  ===> Average training loss = , 1.128, Training Time: 1:13:06\nEpoch = 5, Iteration = 2000/ 2220  ===> Average training loss = , 1.128, Training Time: 1:13:22\nEpoch = 5, Iteration = 2040/ 2220  ===> Average training loss = , 1.128, Training Time: 1:13:37\nEpoch = 5, Iteration = 2080/ 2220  ===> Average training loss = , 1.129, Training Time: 1:13:53\nEpoch = 5, Iteration = 2120/ 2220  ===> Average training loss = , 1.129, Training Time: 1:14:08\nEpoch = 5, Iteration = 2160/ 2220  ===> Average training loss = , 1.129, Training Time: 1:14:24\nEpoch = 5, Iteration = 2200/ 2220  ===> Average training loss = , 1.129, Training Time: 1:14:39\nEpoch = 5 ===> training_accuracy =0.915 \nWeighted F1 Score: 0.6043\n\u001b[1mEpoch = 5 ====> Accuracy On Validation Dataset=0.623\u001b[0m\nF1 Score (Class bloomz): 0.9698\nF1 Score (Class chatGPT): 0.7560\nF1 Score (Class cohere): 0.5174\nF1 Score (Class davinci): 0.1608\nF1 Score (Class dolly): 0.6626\nF1 Score (Class human): 0.5590\n\nEpoch = 6, Iteration = 40/ 2220  ===> Average training loss = , 1.157, Training Time: 1:15:51\nEpoch = 6, Iteration = 80/ 2220  ===> Average training loss = , 1.130, Training Time: 1:16:07\nEpoch = 6, Iteration = 120/ 2220  ===> Average training loss = , 1.121, Training Time: 1:16:23\nEpoch = 6, Iteration = 160/ 2220  ===> Average training loss = , 1.116, Training Time: 1:16:38\nEpoch = 6, Iteration = 200/ 2220  ===> Average training loss = , 1.111, Training Time: 1:16:54\nEpoch = 6, Iteration = 240/ 2220  ===> Average training loss = , 1.112, Training Time: 1:17:09\nEpoch = 6, Iteration = 280/ 2220  ===> Average training loss = , 1.112, Training Time: 1:17:25\nEpoch = 6, Iteration = 320/ 2220  ===> Average training loss = , 1.114, Training Time: 1:17:40\nEpoch = 6, Iteration = 360/ 2220  ===> Average training loss = , 1.116, Training Time: 1:17:55\nEpoch = 6, Iteration = 400/ 2220  ===> Average training loss = , 1.116, Training Time: 1:18:11\nEpoch = 6, Iteration = 440/ 2220  ===> Average training loss = , 1.115, Training Time: 1:18:26\nEpoch = 6, Iteration = 480/ 2220  ===> Average training loss = , 1.116, Training Time: 1:18:42\nEpoch = 6, Iteration = 520/ 2220  ===> Average training loss = , 1.117, Training Time: 1:18:57\nEpoch = 6, Iteration = 560/ 2220  ===> Average training loss = , 1.116, Training Time: 1:19:13\nEpoch = 6, Iteration = 600/ 2220  ===> Average training loss = , 1.116, Training Time: 1:19:28\nEpoch = 6, Iteration = 640/ 2220  ===> Average training loss = , 1.117, Training Time: 1:19:44\nEpoch = 6, Iteration = 680/ 2220  ===> Average training loss = , 1.117, Training Time: 1:19:59\nEpoch = 6, Iteration = 720/ 2220  ===> Average training loss = , 1.118, Training Time: 1:20:15\nEpoch = 6, Iteration = 760/ 2220  ===> Average training loss = , 1.117, Training Time: 1:20:30\nEpoch = 6, Iteration = 800/ 2220  ===> Average training loss = , 1.117, Training Time: 1:20:46\nEpoch = 6, Iteration = 840/ 2220  ===> Average training loss = , 1.118, Training Time: 1:21:01\nEpoch = 6, Iteration = 880/ 2220  ===> Average training loss = , 1.117, Training Time: 1:21:17\nEpoch = 6, Iteration = 920/ 2220  ===> Average training loss = , 1.116, Training Time: 1:21:32\nEpoch = 6, Iteration = 960/ 2220  ===> Average training loss = , 1.116, Training Time: 1:21:48\nEpoch = 6, Iteration = 1000/ 2220  ===> Average training loss = , 1.116, Training Time: 1:22:03\nEpoch = 6, Iteration = 1040/ 2220  ===> Average training loss = , 1.116, Training Time: 1:22:19\nEpoch = 6, Iteration = 1080/ 2220  ===> Average training loss = , 1.116, Training Time: 1:22:34\nEpoch = 6, Iteration = 1120/ 2220  ===> Average training loss = , 1.116, Training Time: 1:22:49\nEpoch = 6, Iteration = 1160/ 2220  ===> Average training loss = , 1.116, Training Time: 1:23:05\nEpoch = 6, Iteration = 1200/ 2220  ===> Average training loss = , 1.116, Training Time: 1:23:20\nEpoch = 6, Iteration = 1240/ 2220  ===> Average training loss = , 1.117, Training Time: 1:23:36\nEpoch = 6, Iteration = 1280/ 2220  ===> Average training loss = , 1.118, Training Time: 1:23:51\nEpoch = 6, Iteration = 1320/ 2220  ===> Average training loss = , 1.118, Training Time: 1:24:07\nEpoch = 6, Iteration = 1360/ 2220  ===> Average training loss = , 1.118, Training Time: 1:24:22\nEpoch = 6, Iteration = 1400/ 2220  ===> Average training loss = , 1.118, Training Time: 1:24:38\nEpoch = 6, Iteration = 1440/ 2220  ===> Average training loss = , 1.118, Training Time: 1:24:53\nEpoch = 6, Iteration = 1480/ 2220  ===> Average training loss = , 1.118, Training Time: 1:25:09\nEpoch = 6, Iteration = 1520/ 2220  ===> Average training loss = , 1.118, Training Time: 1:25:24\nEpoch = 6, Iteration = 1560/ 2220  ===> Average training loss = , 1.118, Training Time: 1:25:40\nEpoch = 6, Iteration = 1600/ 2220  ===> Average training loss = , 1.118, Training Time: 1:25:55\nEpoch = 6, Iteration = 1640/ 2220  ===> Average training loss = , 1.118, Training Time: 1:26:11\nEpoch = 6, Iteration = 1680/ 2220  ===> Average training loss = , 1.118, Training Time: 1:26:26\nEpoch = 6, Iteration = 1720/ 2220  ===> Average training loss = , 1.118, Training Time: 1:26:42\nEpoch = 6, Iteration = 1760/ 2220  ===> Average training loss = , 1.118, Training Time: 1:26:57\nEpoch = 6, Iteration = 1800/ 2220  ===> Average training loss = , 1.119, Training Time: 1:27:13\nEpoch = 6, Iteration = 1840/ 2220  ===> Average training loss = , 1.118, Training Time: 1:27:28\nEpoch = 6, Iteration = 1880/ 2220  ===> Average training loss = , 1.119, Training Time: 1:27:44\nEpoch = 6, Iteration = 1920/ 2220  ===> Average training loss = , 1.119, Training Time: 1:27:59\nEpoch = 6, Iteration = 1960/ 2220  ===> Average training loss = , 1.119, Training Time: 1:28:14\nEpoch = 6, Iteration = 2000/ 2220  ===> Average training loss = , 1.119, Training Time: 1:28:30\nEpoch = 6, Iteration = 2040/ 2220  ===> Average training loss = , 1.119, Training Time: 1:28:45\nEpoch = 6, Iteration = 2080/ 2220  ===> Average training loss = , 1.119, Training Time: 1:29:01\nEpoch = 6, Iteration = 2120/ 2220  ===> Average training loss = , 1.119, Training Time: 1:29:16\nEpoch = 6, Iteration = 2160/ 2220  ===> Average training loss = , 1.119, Training Time: 1:29:32\nEpoch = 6, Iteration = 2200/ 2220  ===> Average training loss = , 1.119, Training Time: 1:29:47\nEpoch = 6 ===> training_accuracy =0.925 \nWeighted F1 Score: 0.5099\n\u001b[1mEpoch = 6 ====> Accuracy On Validation Dataset=0.550\u001b[0m\nF1 Score (Class bloomz): 0.9606\nF1 Score (Class chatGPT): 0.4228\nF1 Score (Class cohere): 0.5111\nF1 Score (Class davinci): 0.0190\nF1 Score (Class dolly): 0.5000\nF1 Score (Class human): 0.6460\n\nEpoch = 7, Iteration = 40/ 2220  ===> Average training loss = , 1.135, Training Time: 1:30:59\nEpoch = 7, Iteration = 80/ 2220  ===> Average training loss = , 1.131, Training Time: 1:31:14\nEpoch = 7, Iteration = 120/ 2220  ===> Average training loss = , 1.118, Training Time: 1:31:30\nEpoch = 7, Iteration = 160/ 2220  ===> Average training loss = , 1.118, Training Time: 1:31:45\nEpoch = 7, Iteration = 200/ 2220  ===> Average training loss = , 1.119, Training Time: 1:32:00\nEpoch = 7, Iteration = 240/ 2220  ===> Average training loss = , 1.117, Training Time: 1:32:16\nEpoch = 7, Iteration = 280/ 2220  ===> Average training loss = , 1.114, Training Time: 1:32:31\nEpoch = 7, Iteration = 320/ 2220  ===> Average training loss = , 1.117, Training Time: 1:32:47\nEpoch = 7, Iteration = 360/ 2220  ===> Average training loss = , 1.120, Training Time: 1:33:02\nEpoch = 7, Iteration = 400/ 2220  ===> Average training loss = , 1.120, Training Time: 1:33:18\nEpoch = 7, Iteration = 440/ 2220  ===> Average training loss = , 1.121, Training Time: 1:33:33\nEpoch = 7, Iteration = 480/ 2220  ===> Average training loss = , 1.121, Training Time: 1:33:49\nEpoch = 7, Iteration = 520/ 2220  ===> Average training loss = , 1.122, Training Time: 1:34:04\nEpoch = 7, Iteration = 560/ 2220  ===> Average training loss = , 1.123, Training Time: 1:34:20\nEpoch = 7, Iteration = 600/ 2220  ===> Average training loss = , 1.123, Training Time: 1:34:35\nEpoch = 7, Iteration = 640/ 2220  ===> Average training loss = , 1.122, Training Time: 1:34:51\nEpoch = 7, Iteration = 680/ 2220  ===> Average training loss = , 1.121, Training Time: 1:35:06\nEpoch = 7, Iteration = 720/ 2220  ===> Average training loss = , 1.121, Training Time: 1:35:22\nEpoch = 7, Iteration = 760/ 2220  ===> Average training loss = , 1.123, Training Time: 1:35:37\nEpoch = 7, Iteration = 800/ 2220  ===> Average training loss = , 1.123, Training Time: 1:35:53\nEpoch = 7, Iteration = 840/ 2220  ===> Average training loss = , 1.123, Training Time: 1:36:08\nEpoch = 7, Iteration = 880/ 2220  ===> Average training loss = , 1.123, Training Time: 1:36:24\nEpoch = 7, Iteration = 920/ 2220  ===> Average training loss = , 1.122, Training Time: 1:36:39\nEpoch = 7, Iteration = 960/ 2220  ===> Average training loss = , 1.121, Training Time: 1:36:55\nEpoch = 7, Iteration = 1000/ 2220  ===> Average training loss = , 1.121, Training Time: 1:37:10\nEpoch = 7, Iteration = 1040/ 2220  ===> Average training loss = , 1.121, Training Time: 1:37:25\nEpoch = 7, Iteration = 1080/ 2220  ===> Average training loss = , 1.121, Training Time: 1:37:41\nEpoch = 7, Iteration = 1120/ 2220  ===> Average training loss = , 1.121, Training Time: 1:37:56\nEpoch = 7, Iteration = 1160/ 2220  ===> Average training loss = , 1.120, Training Time: 1:38:12\nEpoch = 7, Iteration = 1200/ 2220  ===> Average training loss = , 1.120, Training Time: 1:38:27\nEpoch = 7, Iteration = 1240/ 2220  ===> Average training loss = , 1.120, Training Time: 1:38:43\nEpoch = 7, Iteration = 1280/ 2220  ===> Average training loss = , 1.119, Training Time: 1:38:58\nEpoch = 7, Iteration = 1320/ 2220  ===> Average training loss = , 1.119, Training Time: 1:39:14\nEpoch = 7, Iteration = 1360/ 2220  ===> Average training loss = , 1.119, Training Time: 1:39:29\nEpoch = 7, Iteration = 1400/ 2220  ===> Average training loss = , 1.119, Training Time: 1:39:45\nEpoch = 7, Iteration = 1440/ 2220  ===> Average training loss = , 1.118, Training Time: 1:40:00\nEpoch = 7, Iteration = 1480/ 2220  ===> Average training loss = , 1.119, Training Time: 1:40:16\nEpoch = 7, Iteration = 1520/ 2220  ===> Average training loss = , 1.119, Training Time: 1:40:31\nEpoch = 7, Iteration = 1560/ 2220  ===> Average training loss = , 1.119, Training Time: 1:40:47\nEpoch = 7, Iteration = 1600/ 2220  ===> Average training loss = , 1.119, Training Time: 1:41:02\nEpoch = 7, Iteration = 1640/ 2220  ===> Average training loss = , 1.119, Training Time: 1:41:17\nEpoch = 7, Iteration = 1680/ 2220  ===> Average training loss = , 1.120, Training Time: 1:41:33\nEpoch = 7, Iteration = 1720/ 2220  ===> Average training loss = , 1.120, Training Time: 1:41:48\nEpoch = 7, Iteration = 1760/ 2220  ===> Average training loss = , 1.120, Training Time: 1:42:04\nEpoch = 7, Iteration = 1800/ 2220  ===> Average training loss = , 1.119, Training Time: 1:42:19\nEpoch = 7, Iteration = 1840/ 2220  ===> Average training loss = , 1.119, Training Time: 1:42:35\nEpoch = 7, Iteration = 1880/ 2220  ===> Average training loss = , 1.119, Training Time: 1:42:50\nEpoch = 7, Iteration = 1920/ 2220  ===> Average training loss = , 1.119, Training Time: 1:43:06\nEpoch = 7, Iteration = 1960/ 2220  ===> Average training loss = , 1.119, Training Time: 1:43:21\nEpoch = 7, Iteration = 2000/ 2220  ===> Average training loss = , 1.119, Training Time: 1:43:37\nEpoch = 7, Iteration = 2040/ 2220  ===> Average training loss = , 1.119, Training Time: 1:43:52\nEpoch = 7, Iteration = 2080/ 2220  ===> Average training loss = , 1.119, Training Time: 1:44:08\nEpoch = 7, Iteration = 2120/ 2220  ===> Average training loss = , 1.119, Training Time: 1:44:23\nEpoch = 7, Iteration = 2160/ 2220  ===> Average training loss = , 1.119, Training Time: 1:44:39\nEpoch = 7, Iteration = 2200/ 2220  ===> Average training loss = , 1.119, Training Time: 1:44:54\nEpoch = 7 ===> training_accuracy =0.925 \nWeighted F1 Score: 0.4967\n\u001b[1mEpoch = 7 ====> Accuracy On Validation Dataset=0.537\u001b[0m\nF1 Score (Class bloomz): 0.9506\nF1 Score (Class chatGPT): 0.3156\nF1 Score (Class cohere): 0.4804\nF1 Score (Class davinci): 0.1085\nF1 Score (Class dolly): 0.6019\nF1 Score (Class human): 0.5233\n\nEpoch = 8, Iteration = 40/ 2220  ===> Average training loss = , 1.132, Training Time: 1:46:05\nEpoch = 8, Iteration = 80/ 2220  ===> Average training loss = , 1.115, Training Time: 1:46:20\nEpoch = 8, Iteration = 120/ 2220  ===> Average training loss = , 1.109, Training Time: 1:46:36\nEpoch = 8, Iteration = 160/ 2220  ===> Average training loss = , 1.111, Training Time: 1:46:51\nEpoch = 8, Iteration = 200/ 2220  ===> Average training loss = , 1.108, Training Time: 1:47:07\nEpoch = 8, Iteration = 240/ 2220  ===> Average training loss = , 1.110, Training Time: 1:47:22\nEpoch = 8, Iteration = 280/ 2220  ===> Average training loss = , 1.108, Training Time: 1:47:38\nEpoch = 8, Iteration = 320/ 2220  ===> Average training loss = , 1.107, Training Time: 1:47:53\nEpoch = 8, Iteration = 360/ 2220  ===> Average training loss = , 1.107, Training Time: 1:48:09\nEpoch = 8, Iteration = 400/ 2220  ===> Average training loss = , 1.109, Training Time: 1:48:24\nEpoch = 8, Iteration = 440/ 2220  ===> Average training loss = , 1.110, Training Time: 1:48:40\nEpoch = 8, Iteration = 480/ 2220  ===> Average training loss = , 1.108, Training Time: 1:48:55\nEpoch = 8, Iteration = 520/ 2220  ===> Average training loss = , 1.108, Training Time: 1:49:11\nEpoch = 8, Iteration = 560/ 2220  ===> Average training loss = , 1.108, Training Time: 1:49:26\nEpoch = 8, Iteration = 600/ 2220  ===> Average training loss = , 1.107, Training Time: 1:49:42\nEpoch = 8, Iteration = 640/ 2220  ===> Average training loss = , 1.107, Training Time: 1:49:57\nEpoch = 8, Iteration = 680/ 2220  ===> Average training loss = , 1.106, Training Time: 1:50:13\nEpoch = 8, Iteration = 720/ 2220  ===> Average training loss = , 1.106, Training Time: 1:50:28\nEpoch = 8, Iteration = 760/ 2220  ===> Average training loss = , 1.106, Training Time: 1:50:44\nEpoch = 8, Iteration = 800/ 2220  ===> Average training loss = , 1.107, Training Time: 1:50:59\nEpoch = 8, Iteration = 840/ 2220  ===> Average training loss = , 1.107, Training Time: 1:51:15\nEpoch = 8, Iteration = 880/ 2220  ===> Average training loss = , 1.107, Training Time: 1:51:30\nEpoch = 8, Iteration = 920/ 2220  ===> Average training loss = , 1.107, Training Time: 1:51:46\nEpoch = 8, Iteration = 960/ 2220  ===> Average training loss = , 1.107, Training Time: 1:52:01\nEpoch = 8, Iteration = 1000/ 2220  ===> Average training loss = , 1.107, Training Time: 1:52:16\nEpoch = 8, Iteration = 1040/ 2220  ===> Average training loss = , 1.107, Training Time: 1:52:32\nEpoch = 8, Iteration = 1080/ 2220  ===> Average training loss = , 1.107, Training Time: 1:52:47\nEpoch = 8, Iteration = 1120/ 2220  ===> Average training loss = , 1.107, Training Time: 1:53:03\nEpoch = 8, Iteration = 1160/ 2220  ===> Average training loss = , 1.107, Training Time: 1:53:18\nEpoch = 8, Iteration = 1200/ 2220  ===> Average training loss = , 1.107, Training Time: 1:53:34\nEpoch = 8, Iteration = 1240/ 2220  ===> Average training loss = , 1.106, Training Time: 1:53:49\nEpoch = 8, Iteration = 1280/ 2220  ===> Average training loss = , 1.106, Training Time: 1:54:05\nEpoch = 8, Iteration = 1320/ 2220  ===> Average training loss = , 1.107, Training Time: 1:54:20\nEpoch = 8, Iteration = 1360/ 2220  ===> Average training loss = , 1.107, Training Time: 1:54:36\nEpoch = 8, Iteration = 1400/ 2220  ===> Average training loss = , 1.107, Training Time: 1:54:51\nEpoch = 8, Iteration = 1440/ 2220  ===> Average training loss = , 1.107, Training Time: 1:55:07\nEpoch = 8, Iteration = 1480/ 2220  ===> Average training loss = , 1.107, Training Time: 1:55:22\nEpoch = 8, Iteration = 1520/ 2220  ===> Average training loss = , 1.107, Training Time: 1:55:38\nEpoch = 8, Iteration = 1560/ 2220  ===> Average training loss = , 1.107, Training Time: 1:55:53\nEpoch = 8, Iteration = 1600/ 2220  ===> Average training loss = , 1.107, Training Time: 1:56:09\nEpoch = 8, Iteration = 1640/ 2220  ===> Average training loss = , 1.107, Training Time: 1:56:24\nEpoch = 8, Iteration = 1680/ 2220  ===> Average training loss = , 1.107, Training Time: 1:56:40\nEpoch = 8, Iteration = 1720/ 2220  ===> Average training loss = , 1.108, Training Time: 1:56:55\nEpoch = 8, Iteration = 1760/ 2220  ===> Average training loss = , 1.108, Training Time: 1:57:11\nEpoch = 8, Iteration = 1800/ 2220  ===> Average training loss = , 1.108, Training Time: 1:57:26\nEpoch = 8, Iteration = 1840/ 2220  ===> Average training loss = , 1.108, Training Time: 1:57:41\nEpoch = 8, Iteration = 1880/ 2220  ===> Average training loss = , 1.108, Training Time: 1:57:57\nEpoch = 8, Iteration = 1920/ 2220  ===> Average training loss = , 1.108, Training Time: 1:58:12\nEpoch = 8, Iteration = 1960/ 2220  ===> Average training loss = , 1.108, Training Time: 1:58:28\nEpoch = 8, Iteration = 2000/ 2220  ===> Average training loss = , 1.108, Training Time: 1:58:43\nEpoch = 8, Iteration = 2040/ 2220  ===> Average training loss = , 1.108, Training Time: 1:58:59\nEpoch = 8, Iteration = 2080/ 2220  ===> Average training loss = , 1.108, Training Time: 1:59:14\nEpoch = 8, Iteration = 2120/ 2220  ===> Average training loss = , 1.108, Training Time: 1:59:30\nEpoch = 8, Iteration = 2160/ 2220  ===> Average training loss = , 1.107, Training Time: 1:59:45\nEpoch = 8, Iteration = 2200/ 2220  ===> Average training loss = , 1.107, Training Time: 2:00:01\nEpoch = 8 ===> training_accuracy =0.936 \nWeighted F1 Score: 0.5335\n\u001b[1mEpoch = 8 ====> Accuracy On Validation Dataset=0.567\u001b[0m\nF1 Score (Class bloomz): 0.9479\nF1 Score (Class chatGPT): 0.3383\nF1 Score (Class cohere): 0.4951\nF1 Score (Class davinci): 0.1557\nF1 Score (Class dolly): 0.5427\nF1 Score (Class human): 0.7213\n\nEpoch = 9, Iteration = 40/ 2220  ===> Average training loss = , 1.129, Training Time: 2:01:12\nEpoch = 9, Iteration = 80/ 2220  ===> Average training loss = , 1.117, Training Time: 2:01:28\nEpoch = 9, Iteration = 120/ 2220  ===> Average training loss = , 1.111, Training Time: 2:01:43\nEpoch = 9, Iteration = 160/ 2220  ===> Average training loss = , 1.110, Training Time: 2:01:58\nEpoch = 9, Iteration = 200/ 2220  ===> Average training loss = , 1.110, Training Time: 2:02:14\nEpoch = 9, Iteration = 240/ 2220  ===> Average training loss = , 1.108, Training Time: 2:02:29\nEpoch = 9, Iteration = 280/ 2220  ===> Average training loss = , 1.106, Training Time: 2:02:45\nEpoch = 9, Iteration = 320/ 2220  ===> Average training loss = , 1.107, Training Time: 2:03:00\nEpoch = 9, Iteration = 360/ 2220  ===> Average training loss = , 1.105, Training Time: 2:03:16\nEpoch = 9, Iteration = 400/ 2220  ===> Average training loss = , 1.105, Training Time: 2:03:31\nEpoch = 9, Iteration = 440/ 2220  ===> Average training loss = , 1.104, Training Time: 2:03:47\nEpoch = 9, Iteration = 480/ 2220  ===> Average training loss = , 1.103, Training Time: 2:04:02\nEpoch = 9, Iteration = 520/ 2220  ===> Average training loss = , 1.102, Training Time: 2:04:18\nEpoch = 9, Iteration = 560/ 2220  ===> Average training loss = , 1.104, Training Time: 2:04:33\nEpoch = 9, Iteration = 600/ 2220  ===> Average training loss = , 1.105, Training Time: 2:04:49\nEpoch = 9, Iteration = 640/ 2220  ===> Average training loss = , 1.105, Training Time: 2:05:04\nEpoch = 9, Iteration = 680/ 2220  ===> Average training loss = , 1.105, Training Time: 2:05:20\nEpoch = 9, Iteration = 720/ 2220  ===> Average training loss = , 1.105, Training Time: 2:05:35\nEpoch = 9, Iteration = 760/ 2220  ===> Average training loss = , 1.105, Training Time: 2:05:51\nEpoch = 9, Iteration = 800/ 2220  ===> Average training loss = , 1.105, Training Time: 2:06:06\nEpoch = 9, Iteration = 840/ 2220  ===> Average training loss = , 1.104, Training Time: 2:06:22\nEpoch = 9, Iteration = 880/ 2220  ===> Average training loss = , 1.104, Training Time: 2:06:37\nEpoch = 9, Iteration = 920/ 2220  ===> Average training loss = , 1.104, Training Time: 2:06:53\nEpoch = 9, Iteration = 960/ 2220  ===> Average training loss = , 1.104, Training Time: 2:07:08\nEpoch = 9, Iteration = 1000/ 2220  ===> Average training loss = , 1.104, Training Time: 2:07:23\nEpoch = 9, Iteration = 1040/ 2220  ===> Average training loss = , 1.104, Training Time: 2:07:39\nEpoch = 9, Iteration = 1080/ 2220  ===> Average training loss = , 1.104, Training Time: 2:07:54\nEpoch = 9, Iteration = 1120/ 2220  ===> Average training loss = , 1.104, Training Time: 2:08:10\nEpoch = 9, Iteration = 1160/ 2220  ===> Average training loss = , 1.104, Training Time: 2:08:25\nEpoch = 9, Iteration = 1200/ 2220  ===> Average training loss = , 1.105, Training Time: 2:08:41\nEpoch = 9, Iteration = 1240/ 2220  ===> Average training loss = , 1.104, Training Time: 2:08:56\nEpoch = 9, Iteration = 1280/ 2220  ===> Average training loss = , 1.105, Training Time: 2:09:12\nEpoch = 9, Iteration = 1320/ 2220  ===> Average training loss = , 1.104, Training Time: 2:09:27\nEpoch = 9, Iteration = 1360/ 2220  ===> Average training loss = , 1.104, Training Time: 2:09:43\nEpoch = 9, Iteration = 1400/ 2220  ===> Average training loss = , 1.104, Training Time: 2:09:58\nEpoch = 9, Iteration = 1440/ 2220  ===> Average training loss = , 1.104, Training Time: 2:10:14\nEpoch = 9, Iteration = 1480/ 2220  ===> Average training loss = , 1.104, Training Time: 2:10:29\nEpoch = 9, Iteration = 1520/ 2220  ===> Average training loss = , 1.104, Training Time: 2:10:45\nEpoch = 9, Iteration = 1560/ 2220  ===> Average training loss = , 1.103, Training Time: 2:11:00\nEpoch = 9, Iteration = 1600/ 2220  ===> Average training loss = , 1.103, Training Time: 2:11:15\nEpoch = 9, Iteration = 1640/ 2220  ===> Average training loss = , 1.103, Training Time: 2:11:31\nEpoch = 9, Iteration = 1680/ 2220  ===> Average training loss = , 1.103, Training Time: 2:11:46\nEpoch = 9, Iteration = 1720/ 2220  ===> Average training loss = , 1.103, Training Time: 2:12:02\nEpoch = 9, Iteration = 1760/ 2220  ===> Average training loss = , 1.103, Training Time: 2:12:17\nEpoch = 9, Iteration = 1800/ 2220  ===> Average training loss = , 1.103, Training Time: 2:12:33\nEpoch = 9, Iteration = 1840/ 2220  ===> Average training loss = , 1.103, Training Time: 2:12:48\nEpoch = 9, Iteration = 1880/ 2220  ===> Average training loss = , 1.103, Training Time: 2:13:04\nEpoch = 9, Iteration = 1920/ 2220  ===> Average training loss = , 1.103, Training Time: 2:13:19\nEpoch = 9, Iteration = 1960/ 2220  ===> Average training loss = , 1.103, Training Time: 2:13:35\nEpoch = 9, Iteration = 2000/ 2220  ===> Average training loss = , 1.103, Training Time: 2:13:50\nEpoch = 9, Iteration = 2040/ 2220  ===> Average training loss = , 1.103, Training Time: 2:14:06\nEpoch = 9, Iteration = 2080/ 2220  ===> Average training loss = , 1.103, Training Time: 2:14:21\nEpoch = 9, Iteration = 2120/ 2220  ===> Average training loss = , 1.103, Training Time: 2:14:37\nEpoch = 9, Iteration = 2160/ 2220  ===> Average training loss = , 1.103, Training Time: 2:14:52\nEpoch = 9, Iteration = 2200/ 2220  ===> Average training loss = , 1.103, Training Time: 2:15:08\nEpoch = 9 ===> training_accuracy =0.940 \nWeighted F1 Score: 0.4256\n\u001b[1mEpoch = 9 ====> Accuracy On Validation Dataset=0.501\u001b[0m\nF1 Score (Class bloomz): 0.9311\nF1 Score (Class chatGPT): 0.0391\nF1 Score (Class cohere): 0.4638\nF1 Score (Class davinci): 0.0486\nF1 Score (Class dolly): 0.5395\nF1 Score (Class human): 0.5318\n\nEpoch = 10, Iteration = 40/ 2220  ===> Average training loss = , 1.149, Training Time: 2:16:19\nEpoch = 10, Iteration = 80/ 2220  ===> Average training loss = , 1.126, Training Time: 2:16:34\nEpoch = 10, Iteration = 120/ 2220  ===> Average training loss = , 1.122, Training Time: 2:16:50\nEpoch = 10, Iteration = 160/ 2220  ===> Average training loss = , 1.115, Training Time: 2:17:05\nEpoch = 10, Iteration = 200/ 2220  ===> Average training loss = , 1.112, Training Time: 2:17:21\nEpoch = 10, Iteration = 240/ 2220  ===> Average training loss = , 1.109, Training Time: 2:17:36\nEpoch = 10, Iteration = 280/ 2220  ===> Average training loss = , 1.109, Training Time: 2:17:52\nEpoch = 10, Iteration = 320/ 2220  ===> Average training loss = , 1.108, Training Time: 2:18:07\nEpoch = 10, Iteration = 360/ 2220  ===> Average training loss = , 1.105, Training Time: 2:18:23\nEpoch = 10, Iteration = 400/ 2220  ===> Average training loss = , 1.106, Training Time: 2:18:38\nEpoch = 10, Iteration = 440/ 2220  ===> Average training loss = , 1.105, Training Time: 2:18:54\nEpoch = 10, Iteration = 480/ 2220  ===> Average training loss = , 1.106, Training Time: 2:19:09\nEpoch = 10, Iteration = 520/ 2220  ===> Average training loss = , 1.107, Training Time: 2:19:24\nEpoch = 10, Iteration = 560/ 2220  ===> Average training loss = , 1.107, Training Time: 2:19:40\nEpoch = 10, Iteration = 600/ 2220  ===> Average training loss = , 1.107, Training Time: 2:19:55\nEpoch = 10, Iteration = 640/ 2220  ===> Average training loss = , 1.105, Training Time: 2:20:11\nEpoch = 10, Iteration = 680/ 2220  ===> Average training loss = , 1.104, Training Time: 2:20:26\nEpoch = 10, Iteration = 720/ 2220  ===> Average training loss = , 1.104, Training Time: 2:20:42\nEpoch = 10, Iteration = 760/ 2220  ===> Average training loss = , 1.103, Training Time: 2:20:57\nEpoch = 10, Iteration = 800/ 2220  ===> Average training loss = , 1.103, Training Time: 2:21:13\nEpoch = 10, Iteration = 840/ 2220  ===> Average training loss = , 1.103, Training Time: 2:21:28\nEpoch = 10, Iteration = 880/ 2220  ===> Average training loss = , 1.103, Training Time: 2:21:44\nEpoch = 10, Iteration = 920/ 2220  ===> Average training loss = , 1.103, Training Time: 2:21:59\nEpoch = 10, Iteration = 960/ 2220  ===> Average training loss = , 1.103, Training Time: 2:22:15\nEpoch = 10, Iteration = 1000/ 2220  ===> Average training loss = , 1.102, Training Time: 2:22:30\nEpoch = 10, Iteration = 1040/ 2220  ===> Average training loss = , 1.103, Training Time: 2:22:46\nEpoch = 10, Iteration = 1080/ 2220  ===> Average training loss = , 1.103, Training Time: 2:23:01\nEpoch = 10, Iteration = 1120/ 2220  ===> Average training loss = , 1.103, Training Time: 2:23:17\nEpoch = 10, Iteration = 1160/ 2220  ===> Average training loss = , 1.104, Training Time: 2:23:32\nEpoch = 10, Iteration = 1200/ 2220  ===> Average training loss = , 1.103, Training Time: 2:23:47\nEpoch = 10, Iteration = 1240/ 2220  ===> Average training loss = , 1.104, Training Time: 2:24:03\nEpoch = 10, Iteration = 1280/ 2220  ===> Average training loss = , 1.104, Training Time: 2:24:19\nEpoch = 10, Iteration = 1320/ 2220  ===> Average training loss = , 1.104, Training Time: 2:24:34\nEpoch = 10, Iteration = 1360/ 2220  ===> Average training loss = , 1.104, Training Time: 2:24:49\nEpoch = 10, Iteration = 1400/ 2220  ===> Average training loss = , 1.103, Training Time: 2:25:05\nEpoch = 10, Iteration = 1440/ 2220  ===> Average training loss = , 1.103, Training Time: 2:25:20\nEpoch = 10, Iteration = 1480/ 2220  ===> Average training loss = , 1.103, Training Time: 2:25:36\nEpoch = 10, Iteration = 1520/ 2220  ===> Average training loss = , 1.103, Training Time: 2:25:51\nEpoch = 10, Iteration = 1560/ 2220  ===> Average training loss = , 1.103, Training Time: 2:26:07\nEpoch = 10, Iteration = 1600/ 2220  ===> Average training loss = , 1.103, Training Time: 2:26:22\nEpoch = 10, Iteration = 1640/ 2220  ===> Average training loss = , 1.103, Training Time: 2:26:38\nEpoch = 10, Iteration = 1680/ 2220  ===> Average training loss = , 1.103, Training Time: 2:26:53\nEpoch = 10, Iteration = 1720/ 2220  ===> Average training loss = , 1.102, Training Time: 2:27:09\nEpoch = 10, Iteration = 1760/ 2220  ===> Average training loss = , 1.103, Training Time: 2:27:24\nEpoch = 10, Iteration = 1800/ 2220  ===> Average training loss = , 1.103, Training Time: 2:27:40\nEpoch = 10, Iteration = 1840/ 2220  ===> Average training loss = , 1.103, Training Time: 2:27:55\nEpoch = 10, Iteration = 1880/ 2220  ===> Average training loss = , 1.103, Training Time: 2:28:11\nEpoch = 10, Iteration = 1920/ 2220  ===> Average training loss = , 1.104, Training Time: 2:28:26\nEpoch = 10, Iteration = 1960/ 2220  ===> Average training loss = , 1.104, Training Time: 2:28:42\nEpoch = 10, Iteration = 2000/ 2220  ===> Average training loss = , 1.104, Training Time: 2:28:57\nEpoch = 10, Iteration = 2040/ 2220  ===> Average training loss = , 1.105, Training Time: 2:29:13\nEpoch = 10, Iteration = 2080/ 2220  ===> Average training loss = , 1.105, Training Time: 2:29:28\nEpoch = 10, Iteration = 2120/ 2220  ===> Average training loss = , 1.105, Training Time: 2:29:44\nEpoch = 10, Iteration = 2160/ 2220  ===> Average training loss = , 1.105, Training Time: 2:29:59\nEpoch = 10, Iteration = 2200/ 2220  ===> Average training loss = , 1.104, Training Time: 2:30:15\nEpoch = 10 ===> training_accuracy =0.939 \nWeighted F1 Score: 0.4901\n\u001b[1mEpoch = 10 ====> Accuracy On Validation Dataset=0.530\u001b[0m\nF1 Score (Class bloomz): 0.9774\nF1 Score (Class chatGPT): 0.4373\nF1 Score (Class cohere): 0.4838\nF1 Score (Class davinci): 0.0258\nF1 Score (Class dolly): 0.5466\nF1 Score (Class human): 0.4699\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### PLot Validation Accuracies and Weighted F1 Scores with Adapters","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10, 8))\n\n# Plot accuracy scores with lines and star markers\nax.plot(percentages, [100*i for i in accuracies], linestyle='-', marker='*', color='blue', label='Accuracy')\n\n# Plot F1 weighted scores with lines and star markers\nax.plot(percentages, [100*i for i in weighted_f1s], linestyle='--', marker='^', color='green', label='F1 Weighted')\n\n# Add labels, legend, and show the plot\nax.set_ylabel('Scores')\nax.set_xlabel('Percentage')\nax.legend()\nplt.title('Accuracy and F1 Weighted Scores by Percentages of training data for bert classifier')\nplt.grid(\"on\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T18:15:31.283946Z","iopub.execute_input":"2024-02-02T18:15:31.284609Z","iopub.status.idle":"2024-02-02T18:15:31.579504Z","shell.execute_reply.started":"2024-02-02T18:15:31.284574Z","shell.execute_reply":"2024-02-02T18:15:31.578556Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 1 Axes>","image/png":"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"},"metadata":{}}]}]}